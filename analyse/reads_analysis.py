#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ–‡ç« å‘å¸ƒå†å²æ•°æ®åˆ†æè„šæœ¬

è¿™ä¸ªè„šæœ¬ç”¨äºåˆ†ææ–‡ç« å‘å¸ƒå†å²æ•°æ®ï¼ŒåŒ…æ‹¬é˜…è¯»é‡ã€ç‚¹èµé‡ç­‰æŒ‡æ ‡çš„åˆ†æã€‚
"""

import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns
from datetime import datetime
import numpy as np

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

print("âœ… å¯¼å…¥åº“å®Œæˆ")

def load_publish_history():
    """å°è¯•ä»å¤šä¸ªå¯èƒ½çš„è·¯å¾„åŠ è½½æ–‡ç« å‘å¸ƒå†å²æ•°æ®"""
    
    # å¯èƒ½çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    possible_paths = [
        # ä»å½“å‰è„šæœ¬ç›®å½•çš„ç›¸å¯¹è·¯å¾„
        '../workspace/data/publish_history_for_calendar.csv',
        '../workspace/publish_history_for_calendar.csv',
        
        # ä»é¡¹ç›®æ ¹ç›®å½•çš„è·¯å¾„
        '../../workspace/data/publish_history_for_calendar.csv',
        '../../workspace/publish_history_for_calendar.csv',
        
        # ä»å½“å‰å·¥ä½œç›®å½•çš„è·¯å¾„
        'workspace/data/publish_history_for_calendar.csv',
        'workspace/publish_history_for_calendar.csv',
        
        # ç»å¯¹è·¯å¾„ï¼ˆåŸºäºé¡¹ç›®æ ¹ç›®å½•ï¼‰
        '/Users/xuchao/Projects/Auto-doc-streamlit/workspace/data/publish_history_for_calendar.csv',
        '/Users/xuchao/Projects/Auto-doc-streamlit/workspace/publish_history_for_calendar.csv'
    ]
    
    # å°è¯•è¯»å–æ–‡ä»¶
    for path in possible_paths:
        if os.path.exists(path):
            try:
                print(f"âœ… æˆåŠŸæ‰¾åˆ°æ–‡ä»¶: {path}")
                df = pd.read_csv(path, encoding='utf-8-sig')
                print(f"ğŸ“Š æˆåŠŸåŠ è½½æ•°æ®ï¼Œå…± {len(df)} æ¡è®°å½•")
                print(f"ğŸ“‹ æ•°æ®åˆ—å: {list(df.columns)}")
                return df, path
            except Exception as e:
                print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥ {path}: {str(e)}")
                continue
    
    # å¦‚æœæ‰€æœ‰è·¯å¾„éƒ½å¤±è´¥ï¼Œæ˜¾ç¤ºå½“å‰ç›®å½•ä¿¡æ¯
    print("âŒ æ— æ³•æ‰¾åˆ° publish_history_for_calendar.csv æ–‡ä»¶")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ“ å½“å‰è„šæœ¬ç›®å½•: {os.path.dirname(os.path.abspath(__file__))}")
    
    # åˆ—å‡ºå½“å‰ç›®å½•å†…å®¹
    print("\nğŸ“‚ å½“å‰ç›®å½•å†…å®¹:")
    try:
        for item in os.listdir('.'):
            if os.path.isdir(item):
                print(f"ğŸ“ {item}/")
            else:
                print(f"ğŸ“„ {item}")
    except Exception as e:
        print(f"æ— æ³•åˆ—å‡ºç›®å½•å†…å®¹: {e}")
    
    # å°è¯•åˆ—å‡ºä¸Šçº§ç›®å½•å†…å®¹
    try:
        parent_dir = os.path.dirname(os.path.abspath('.'))
        print(f"\nğŸ“‚ ä¸Šçº§ç›®å½• ({parent_dir}) å†…å®¹:")
        for item in os.listdir(parent_dir):
            if os.path.isdir(item):
                print(f"ğŸ“ {item}/")
            else:
                print(f"ğŸ“„ {item}")
    except Exception as e:
        print(f"æ— æ³•åˆ—å‡ºä¸Šçº§ç›®å½•å†…å®¹: {e}")
    
    return None, None

def analyze_data(df):
    """åˆ†ææ•°æ®çš„åŸºæœ¬ä¿¡æ¯"""
    if df is None:
        print("âŒ æ²¡æœ‰æ•°æ®å¯ä¾›åˆ†æ")
        return
    
    print("\nğŸ“Š æ•°æ®åŸºæœ¬ä¿¡æ¯:")
    print(f"æ•°æ®å½¢çŠ¶: {df.shape}")
    print(f"æ•°æ®åˆ—å: {list(df.columns)}")
    
    # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
    required_columns = ['æ ‡é¢˜', 'å‘å¸ƒæ—¶é—´', 'é˜…è¯»é‡', 'ç‚¹èµé‡', 'è¯„è®ºé‡', 'è´¦å·åç§°']
    missing_columns = [col for col in required_columns if col not in df.columns]
    
    if missing_columns:
        print(f"âš ï¸ ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_columns}")
    else:
        print("âœ… æ‰€æœ‰å¿…è¦çš„åˆ—éƒ½å­˜åœ¨")
    
    # æ•°æ®é¢„è§ˆ
    print("\nğŸ“‹ æ•°æ®å‰5è¡Œ:")
    print(df.head())
    
    # æ•°å€¼åˆ—ç»Ÿè®¡
    numeric_columns = df.select_dtypes(include=[np.number]).columns
    if len(numeric_columns) > 0:
        print("\nğŸ” æ•°å€¼åˆ—ç»Ÿè®¡æ‘˜è¦:")
        print(df[numeric_columns].describe())
    
    # è´¦å·åˆ†å¸ƒ
    if 'è´¦å·åç§°' in df.columns:
        print("\nğŸ“ˆ è´¦å·åˆ†å¸ƒ:")
        account_counts = df['è´¦å·åç§°'].value_counts()
        print(account_counts)
    
    # æ—¶é—´å¤„ç†
    if 'å‘å¸ƒæ—¶é—´' in df.columns:
        df['å‘å¸ƒæ—¶é—´'] = pd.to_datetime(df['å‘å¸ƒæ—¶é—´'], errors='coerce')
        df['å‘å¸ƒæ—¥æœŸ'] = df['å‘å¸ƒæ—¶é—´'].dt.date
        print(f"\nğŸ“… æ•°æ®æ—¶é—´èŒƒå›´: {df['å‘å¸ƒæ—¶é—´'].min()} åˆ° {df['å‘å¸ƒæ—¶é—´'].max()}")

def check_data_quality(df):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    if df is None:
        return
    
    print("\nğŸ” æ•°æ®è´¨é‡æ£€æŸ¥:")
    
    # æ£€æŸ¥ç¼ºå¤±å€¼
    print("\nğŸ“Š ç¼ºå¤±å€¼ç»Ÿè®¡:")
    missing_data = df.isnull().sum()
    missing_percentage = (missing_data / len(df)) * 100
    missing_df = pd.DataFrame({
        'ç¼ºå¤±æ•°é‡': missing_data,
        'ç¼ºå¤±ç™¾åˆ†æ¯”': missing_percentage
    })
    missing_rows = missing_df[missing_df['ç¼ºå¤±æ•°é‡'] > 0]
    if len(missing_rows) > 0:
        print(missing_rows)
    else:
        print("âœ… æ²¡æœ‰ç¼ºå¤±å€¼")
    
    # æ£€æŸ¥é‡å¤æ•°æ®
    print(f"\nğŸ”„ é‡å¤è¡Œæ•°é‡: {df.duplicated().sum()}")
    
    # æ£€æŸ¥æ•°æ®èŒƒå›´
    if 'é˜…è¯»é‡' in df.columns:
        print(f"\nğŸ“– é˜…è¯»é‡èŒƒå›´: {df['é˜…è¯»é‡'].min()} - {df['é˜…è¯»é‡'].max()}")
        print(f"ğŸ“– é˜…è¯»é‡ä¸­ä½æ•°: {df['é˜…è¯»é‡'].median()}")
        
    if 'ç‚¹èµé‡' in df.columns:
        print(f"ğŸ‘ ç‚¹èµé‡èŒƒå›´: {df['ç‚¹èµé‡'].min()} - {df['ç‚¹èµé‡'].max()}")
        print(f"ğŸ‘ ç‚¹èµé‡ä¸­ä½æ•°: {df['ç‚¹èµé‡'].median()}")
        
    if 'è¯„è®ºé‡' in df.columns:
        print(f"ğŸ’¬ è¯„è®ºé‡èŒƒå›´: {df['è¯„è®ºé‡'].min()} - {df['è¯„è®ºé‡'].max()}")
        print(f"ğŸ’¬ è¯„è®ºé‡ä¸­ä½æ•°: {df['è¯„è®ºé‡'].median()}")

def analyze_account_performance(df):
    """åˆ†æè´¦å·è¡¨ç°"""
    if df is None or 'è´¦å·åç§°' not in df.columns:
        print("âŒ æ— æ³•åˆ†æè´¦å·è¡¨ç°ï¼Œç¼ºå°‘å¿…è¦æ•°æ®")
        return
    
    print("\nğŸ“Š è´¦å·è¡¨ç°åˆ†æ:")
    
    # æŒ‰è´¦å·åˆ†ç»„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    account_stats = df.groupby('è´¦å·åç§°').agg({
        'æ ‡é¢˜': 'count',  # æ–‡ç« æ•°é‡
        'é˜…è¯»é‡': ['mean', 'sum', 'median'],  # é˜…è¯»é‡ç»Ÿè®¡
        'ç‚¹èµé‡': ['mean', 'sum', 'median'],  # ç‚¹èµé‡ç»Ÿè®¡
        'è¯„è®ºé‡': ['mean', 'sum', 'median']   # è¯„è®ºé‡ç»Ÿè®¡
    }).round(2)
    
    # é‡å‘½ååˆ—å
    account_stats.columns = [
        'æ–‡ç« æ•°é‡', 'å¹³å‡é˜…è¯»é‡', 'æ€»é˜…è¯»é‡', 'é˜…è¯»é‡ä¸­ä½æ•°',
        'å¹³å‡ç‚¹èµé‡', 'æ€»ç‚¹èµé‡', 'ç‚¹èµé‡ä¸­ä½æ•°',
        'å¹³å‡è¯„è®ºé‡', 'æ€»è¯„è®ºé‡', 'è¯„è®ºé‡ä¸­ä½æ•°'
    ]
    
    print("\nğŸ“ˆ è´¦å·ç»¼åˆè¡¨ç°:")
    print(account_stats)
    
    # æŒ‰æ€»é˜…è¯»é‡æ’åº
    print("\nğŸ† æŒ‰æ€»é˜…è¯»é‡æ’åºçš„è´¦å·:")
    top_reads = account_stats.sort_values('æ€»é˜…è¯»é‡', ascending=False)
    print(top_reads)
    
    # æŒ‰å¹³å‡é˜…è¯»é‡æ’åº
    print("\nğŸ“Š æŒ‰å¹³å‡é˜…è¯»é‡æ’åºçš„è´¦å·:")
    top_avg_reads = account_stats.sort_values('å¹³å‡é˜…è¯»é‡', ascending=False)
    print(top_avg_reads)

def analyze_time_trends(df):
    """åˆ†ææ—¶é—´è¶‹åŠ¿"""
    if df is None or 'å‘å¸ƒæ—¶é—´' not in df.columns:
        print("âŒ æ— æ³•åˆ†ææ—¶é—´è¶‹åŠ¿ï¼Œç¼ºå°‘å¿…è¦æ•°æ®")
        return
    
    print("\nğŸ“… æ—¶é—´è¶‹åŠ¿åˆ†æ:")
    
    # æŒ‰æ—¥æœŸåˆ†ç»„è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
    daily_stats = df.groupby('å‘å¸ƒæ—¥æœŸ').agg({
        'æ ‡é¢˜': 'count',  # æ–‡ç« æ•°é‡
        'é˜…è¯»é‡': 'sum',  # æ€»é˜…è¯»é‡
        'ç‚¹èµé‡': 'sum',  # æ€»ç‚¹èµé‡
        'è¯„è®ºé‡': 'sum'   # æ€»è¯„è®ºé‡
    }).reset_index()
    
    daily_stats.columns = ['æ—¥æœŸ', 'æ–‡ç« æ•°é‡', 'æ€»é˜…è¯»é‡', 'æ€»ç‚¹èµé‡', 'æ€»è¯„è®ºé‡']
    
    print("\nğŸ“Š æ¯æ—¥å‘å¸ƒç»Ÿè®¡:")
    print(daily_stats.head(10))
    
    # ç»˜åˆ¶æ—¶é—´è¶‹åŠ¿å›¾
    plt.figure(figsize=(15, 10))
    
    # å­å›¾1ï¼šæ–‡ç« æ•°é‡è¶‹åŠ¿
    plt.subplot(2, 2, 1)
    plt.plot(daily_stats['æ—¥æœŸ'], daily_stats['æ–‡ç« æ•°é‡'], marker='o', linewidth=2, markersize=4)
    plt.title('æ¯æ—¥æ–‡ç« å‘å¸ƒæ•°é‡è¶‹åŠ¿')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('æ–‡ç« æ•°é‡')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # å­å›¾2ï¼šé˜…è¯»é‡è¶‹åŠ¿
    plt.subplot(2, 2, 2)
    plt.plot(daily_stats['æ—¥æœŸ'], daily_stats['æ€»é˜…è¯»é‡'], marker='s', linewidth=2, markersize=4, color='orange')
    plt.title('æ¯æ—¥æ€»é˜…è¯»é‡è¶‹åŠ¿')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('æ€»é˜…è¯»é‡')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # å­å›¾3ï¼šç‚¹èµé‡è¶‹åŠ¿
    plt.subplot(2, 2, 3)
    plt.plot(daily_stats['æ—¥æœŸ'], daily_stats['æ€»ç‚¹èµé‡'], marker='^', linewidth=2, markersize=4, color='green')
    plt.title('æ¯æ—¥æ€»ç‚¹èµé‡è¶‹åŠ¿')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('æ€»ç‚¹èµé‡')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    # å­å›¾4ï¼šè¯„è®ºé‡è¶‹åŠ¿
    plt.subplot(2, 2, 4)
    plt.plot(daily_stats['æ—¥æœŸ'], daily_stats['æ€»è¯„è®ºé‡'], marker='d', linewidth=2, markersize=4, color='red')
    plt.title('æ¯æ—¥æ€»è¯„è®ºé‡è¶‹åŠ¿')
    plt.xlabel('æ—¥æœŸ')
    plt.ylabel('æ€»è¯„è®ºé‡')
    plt.xticks(rotation=45)
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def load_from_manual_path(file_path):
    """ä»æ‰‹åŠ¨æŒ‡å®šçš„è·¯å¾„åŠ è½½æ•°æ®"""
    try:
        if os.path.exists(file_path):
            df = pd.read_csv(file_path, encoding='utf-8-sig')
            print(f"âœ… æˆåŠŸä»æ‰‹åŠ¨è·¯å¾„åŠ è½½æ•°æ®: {file_path}")
            print(f"ğŸ“Š æ•°æ®å½¢çŠ¶: {df.shape}")
            return df
        else:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return None
    except Exception as e:
        print(f"âŒ è¯»å–æ–‡ä»¶å¤±è´¥: {str(e)}")
        return None

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹åˆ†ææ–‡ç« å‘å¸ƒå†å²æ•°æ®...")
    
    # åŠ è½½æ•°æ®
    df, file_path = load_publish_history()
    
    if df is not None:
        print(f"\nğŸ‰ æ•°æ®åŠ è½½æˆåŠŸï¼æ–‡ä»¶è·¯å¾„: {file_path}")
        
        # åˆ†ææ•°æ®
        analyze_data(df)
        check_data_quality(df)
        analyze_account_performance(df)
        analyze_time_trends(df)
        
    else:
        print("\nğŸ’¡ è¯·æ£€æŸ¥æ–‡ä»¶è·¯å¾„æˆ–æ‰‹åŠ¨æŒ‡å®šæ­£ç¡®çš„æ–‡ä»¶è·¯å¾„")
        print("\nğŸ“ å¸¸è§çš„æ–‡ä»¶è·¯å¾„:")
        print("1. ç›¸å¯¹è·¯å¾„: '../workspace/data/publish_history_for_calendar.csv'")
        print("2. ç»å¯¹è·¯å¾„: '/Users/xuchao/Projects/Auto-doc-streamlit/workspace/data/publish_history_for_calendar.csv'")
        print("3. å½“å‰ç›®å½•: './workspace/data/publish_history_for_calendar.csv'")
        
        print("\nğŸ’¡ å¦‚æœéœ€è¦æ‰‹åŠ¨æŒ‡å®šè·¯å¾„ï¼Œè¯·ä½¿ç”¨:")
        print("manual_df = load_from_manual_path('/path/to/your/publish_history_for_calendar.csv')")

if __name__ == "__main__":
    main()
