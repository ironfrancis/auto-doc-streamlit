import sys
import os
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
from core.utils.icon_library import get_icon
import numpy as np
from datetime import datetime, timedelta
import calendar

# ä½¿ç”¨ç®€åŒ–è·¯å¾„ç®¡ç†
from simple_paths import *

# å¯¼å…¥ä¾èµ–æ¨¡å—
try:
    from language_manager import init_language, get_text
except ImportError:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„æ›¿ä»£å‡½æ•°
    def init_language():
        return "zh"
    
    def get_text(key, lang="zh"):
        return key

# Using simple_paths for path management - get_json_data_dir is already imported

try:
    from utils.calendar_visualizer import CalendarVisualizer
except ImportError:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ›¿ä»£ç±»
    class CalendarVisualizer:
        def __init__(self, records, selected_channels, start_date, end_date):
            self.records = records
            self.selected_channels = selected_channels
            self.start_date = start_date
            self.end_date = end_date
        
        def create_heatmap_calendar(self):
            return None
        
        def create_monthly_calendar(self, year, month):
            return None
        
        def create_channel_timeline(self):
            return None
        
        def create_publish_pattern_analysis(self):
            return None

T = {
    "en": {
        "page_title": "Channel Publish History",
        "overview": "Publish Overview",
        "calendar_view": "Calendar View",
        "statistics": "Statistics",
        "detailed_records": "Detailed Records",
        "channel_filter": "Select Channel",
        "date_range": "Date Range",
        "all_channels": "All Channels",
        "total_published": "Total Published",
        "total_views": "Total Views",
        "total_likes": "Total Likes",
        "total_comments": "Total Comments",
        "total_shares": "Total Shares",
        "publish_frequency": "Publish Frequency",
        "performance_trend": "Performance Trend",
        "top_articles": "Top Articles",
        "article_id": "Article ID",
        "title": "Title",
        "publish_date": "Publish Date",
        "publish_time": "Publish Time",
        "status": "Status",
        "views": "Views",
        "likes": "Likes",
        "comments": "Comments",
        "shares": "Shares",
        "url": "URL",
        "tags": "Tags",
        "published": "Published",
        "draft": "Draft",
        "scheduled": "Scheduled",
        "no_data": "No Data",
        "export_data": "Export Data",
        "import_data": "Import Data",
        "add_record": "Add Record",
        "edit_record": "Edit Record",
        "delete_record": "Delete Record",
        "save": "Save",
        "cancel": "Cancel",
        "delete": "Delete",
        "confirm_delete": "Confirm Delete",
        "success": "Operation Successful",
        "error": "Operation Failed"
    }
}

# CSVæ•°æ®æ–‡ä»¶è·¯å¾„
CSV_PATH = os.path.join(WORKSPACE_DIR, "data", "publish_history.csv")

def load_csv_data():
    """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
    try:
        if os.path.exists(CSV_PATH):
            df = pd.read_csv(CSV_PATH, encoding='utf-8')
            
            # æ•°æ®é¢„å¤„ç†
            if 'å‘è¡¨æ—¶é—´' in df.columns:
                try:
                    df['å‘è¡¨æ—¶é—´'] = pd.to_datetime(df['å‘è¡¨æ—¶é—´'], errors='coerce')
                    df['publish_date'] = df['å‘è¡¨æ—¶é—´'].dt.strftime('%Y-%m-%d')
                    df['publish_date'] = df['publish_date'].fillna('')
                except Exception as e:
                    st.warning(f"æ—¥æœŸè½¬æ¢è­¦å‘Š: {e}")
                    # ä¿®å¤ï¼šç¡®ä¿publish_dateåˆ—å­˜åœ¨ä¸”ä¸ºSeriesç±»å‹
                    if 'publish_date' in df.columns:
                        df['publish_date'] = df['publish_date'].fillna('')
                    else:
                        df['publish_date'] = ''
            else:
                if 'publish_date' in df.columns:
                    df['publish_date'] = df['publish_date'].fillna('').astype(str)
                else:
                    df['publish_date'] = ''
            
            # è¿‡æ»¤æ‰æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸçš„è®°å½•
            df = df[df['publish_date'] != '']
            df = df[df['publish_date'] != 'nan']
            
            if 'publish_time' not in df.columns:
                df['publish_time'] = '12:00'
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…åŸæœ‰ç»“æ„
            df = df.rename(columns={
                'å†…å®¹æ ‡é¢˜': 'title',
                'æ€»é˜…è¯»äººæ•°': 'views',
                'æ€»é˜…è¯»æ¬¡æ•°': 'total_views',
                'æ€»åˆ†äº«äººæ•°': 'shares',
                'æ€»åˆ†äº«æ¬¡æ•°': 'total_shares',
                'é˜…è¯»åå…³æ³¨äººæ•°': 'followers_after_read',
                'é€è¾¾äººæ•°': 'delivered_count',
                'å…¬ä¼—å·æ¶ˆæ¯é˜…è¯»æ¬¡æ•°': 'official_account_reads',
                'é€è¾¾é˜…è¯»ç‡': 'delivery_read_rate',
                'é¦–æ¬¡åˆ†äº«æ¬¡æ•°': 'first_share_count',
                'åˆ†äº«äº§ç”Ÿé˜…è¯»æ¬¡æ•°': 'share_generated_reads',
                'é¦–æ¬¡åˆ†äº«ç‡': 'first_share_rate',
                'æ¯æ¬¡åˆ†äº«å¸¦æ¥é˜…è¯»æ¬¡æ•°': 'reads_per_share',
                'é˜…è¯»å®Œæˆç‡': 'read_completion_rate',
                'å†…å®¹url': 'url',
                'è´¦å·åç§°': 'channel_name'
            })
            
            # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
            numeric_columns = [
                'views', 'total_views', 'shares', 'total_shares', 'followers_after_read',
                'delivered_count', 'official_account_reads', 'delivery_read_rate',
                'first_share_count', 'share_generated_reads', 'first_share_rate',
                'reads_per_share', 'read_completion_rate'
            ]
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            # æ·»åŠ ç¼ºå¤±çš„åˆ—
            if 'likes' not in df.columns:
                df['likes'] = 0
            if 'comments' not in df.columns:
                df['comments'] = 0
            if 'status' not in df.columns:
                df['status'] = 'published'
            else:
                df['status'] = df['status'].fillna('published')
            
            if 'title' not in df.columns:
                df['title'] = 'æ— æ ‡é¢˜'
            else:
                df['title'] = df['title'].fillna('æ— æ ‡é¢˜')
            
            if 'url' not in df.columns:
                df['url'] = ''
            else:
                df['url'] = df['url'].fillna('')
            
            # ç”ŸæˆID
            if 'id' not in df.columns:
                df['id'] = range(1, len(df) + 1)
            else:
                df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
                if (df['id'] == 0).any():
                    df['id'] = range(1, len(df) + 1)
            
            # ç¡®ä¿channel_nameå­—æ®µå­˜åœ¨
            if 'channel_name' not in df.columns:
                df['channel_name'] = 'AGIè§‚å¯Ÿå®¤'
            else:
                df['channel_name'] = df['channel_name'].fillna('AGIè§‚å¯Ÿå®¤')
            
            return df.to_dict('records')
        else:
            st.warning(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {CSV_PATH}")
            return []
    except Exception as e:
        st.error(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return []

def create_engagement_analysis(records):
    """åˆ›å»ºç”¨æˆ·å‚ä¸åº¦åˆ†æå›¾è¡¨"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    
    # è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡
    df['engagement_rate'] = (df['shares'] + df['followers_after_read']) / df['views'].replace(0, 1) * 100
    df['share_efficiency'] = df['share_generated_reads'] / df['total_shares'].replace(0, 1)
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("é˜…è¯»å®Œæˆç‡åˆ†å¸ƒ", "é€è¾¾é˜…è¯»ç‡åˆ†å¸ƒ", "åˆ†äº«æ•ˆç‡", "å‚ä¸åº¦åˆ†æ"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # é˜…è¯»å®Œæˆç‡åˆ†å¸ƒ
    fig.add_trace(
        go.Histogram(x=df['read_completion_rate'], name="é˜…è¯»å®Œæˆç‡", nbinsx=20),
        row=1, col=1
    )
    
    # é€è¾¾é˜…è¯»ç‡åˆ†å¸ƒ
    fig.add_trace(
        go.Histogram(x=df['delivery_read_rate'], name="é€è¾¾é˜…è¯»ç‡", nbinsx=20),
        row=1, col=2
    )
    
    # åˆ†äº«æ•ˆç‡æ•£ç‚¹å›¾
    fig.add_trace(
        go.Scatter(x=df['total_shares'], y=df['share_efficiency'], 
                   mode='markers', name="åˆ†äº«æ•ˆç‡"),
        row=2, col=1
    )
    
    # å‚ä¸åº¦åˆ†æ
    fig.add_trace(
        go.Scatter(x=df['views'], y=df['engagement_rate'], 
                   mode='markers', name="å‚ä¸åº¦"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="ç”¨æˆ·å‚ä¸åº¦åˆ†æ")
    return fig

def create_channel_performance_dashboard(records):
    """åˆ›å»ºé¢‘é“è¡¨ç°ä»ªè¡¨æ¿"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    
    # æŒ‰é¢‘é“èšåˆæ•°æ®
    channel_stats = df.groupby('channel_name').agg({
        'views': ['mean', 'sum', 'count'],
        'shares': ['mean', 'sum'],
        'read_completion_rate': 'mean',
        'delivery_read_rate': 'mean',
        'share_generated_reads': 'sum',
        'followers_after_read': 'sum'
    }).round(2)
    
    # é‡å‘½ååˆ—
    channel_stats.columns = [
        'å¹³å‡é˜…è¯»äººæ•°', 'æ€»é˜…è¯»äººæ•°', 'æ–‡ç« æ•°é‡',
        'å¹³å‡åˆ†äº«äººæ•°', 'æ€»åˆ†äº«äººæ•°',
        'å¹³å‡é˜…è¯»å®Œæˆç‡', 'å¹³å‡é€è¾¾é˜…è¯»ç‡',
        'åˆ†äº«äº§ç”Ÿé˜…è¯»æ€»æ•°', 'é˜…è¯»åå…³æ³¨æ€»æ•°'
    ]
    
    # åˆ›å»ºä»ªè¡¨æ¿å›¾è¡¨
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("å„é¢‘é“æ–‡ç« æ•°é‡", "å„é¢‘é“å¹³å‡é˜…è¯»äººæ•°", "å„é¢‘é“å¹³å‡é˜…è¯»å®Œæˆç‡", "å„é¢‘é“åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°"),
        specs=[[{"type": "bar"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}]]
    )
    
    # æ–‡ç« æ•°é‡
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['æ–‡ç« æ•°é‡'], name="æ–‡ç« æ•°é‡"),
        row=1, col=1
    )
    
    # å¹³å‡é˜…è¯»äººæ•°
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['å¹³å‡é˜…è¯»äººæ•°'], name="å¹³å‡é˜…è¯»äººæ•°"),
        row=1, col=2
    )
    
    # å¹³å‡é˜…è¯»å®Œæˆç‡
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['å¹³å‡é˜…è¯»å®Œæˆç‡'], name="å¹³å‡é˜…è¯»å®Œæˆç‡"),
        row=2, col=1
    )
    
    # åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['åˆ†äº«äº§ç”Ÿé˜…è¯»æ€»æ•°'], name="åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="é¢‘é“è¡¨ç°ä»ªè¡¨æ¿")
    return fig, channel_stats

def create_trend_analysis(records):
    """åˆ›å»ºè¶‹åŠ¿åˆ†æå›¾è¡¨"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    
    # æŒ‰æ—¥æœŸèšåˆ
    daily_stats = df.groupby('publish_date').agg({
        'views': 'sum',
        'shares': 'sum',
        'read_completion_rate': 'mean',
        'delivery_read_rate': 'mean',
        'share_generated_reads': 'sum',
        'followers_after_read': 'sum'
    }).reset_index()
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("é˜…è¯»äººæ•°è¶‹åŠ¿", "åˆ†äº«äººæ•°è¶‹åŠ¿", "é˜…è¯»å®Œæˆç‡è¶‹åŠ¿", "é€è¾¾é˜…è¯»ç‡è¶‹åŠ¿"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # é˜…è¯»äººæ•°è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['views'], 
                   mode='lines+markers', name="é˜…è¯»äººæ•°"),
        row=1, col=1
    )
    
    # åˆ†äº«äººæ•°è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['shares'], 
                   mode='lines+markers', name="åˆ†äº«äººæ•°"),
        row=1, col=2
    )
    
    # é˜…è¯»å®Œæˆç‡è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['read_completion_rate'], 
                   mode='lines+markers', name="é˜…è¯»å®Œæˆç‡"),
        row=2, col=1
    )
    
    # é€è¾¾é˜…è¯»ç‡è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['delivery_read_rate'], 
                   mode='lines+markers', name="é€è¾¾é˜…è¯»ç‡"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="è¶‹åŠ¿åˆ†æ")
    return fig

def create_heatmap_analysis(records):
    """åˆ›å»ºçƒ­åŠ›å›¾åˆ†æ"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    df['weekday'] = df['publish_date'].dt.day_name()
    df['hour'] = df['publish_date'].dt.hour
    
    # æŒ‰æ˜ŸæœŸå’Œå°æ—¶åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
    
    # å‘å¸ƒé¢‘ç‡çƒ­åŠ›å›¾
    publish_heatmap = df.groupby(['weekday', 'hour']).size().unstack(fill_value=0)
    publish_heatmap = publish_heatmap.reindex(weekday_order)
    publish_heatmap.index = weekday_cn
    
    fig = go.Figure(data=go.Heatmap(
        z=publish_heatmap.values,
        x=publish_heatmap.columns,
        y=publish_heatmap.index,
        colorscale='Viridis',
        text=publish_heatmap.values,
        texttemplate="%{text}",
        textfont={"size": 10},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title="å‘å¸ƒæ—¶é—´çƒ­åŠ›å›¾",
        xaxis_title="å°æ—¶",
        yaxis_title="æ˜ŸæœŸ",
        height=400
    )
    
    return fig

# ==================== æ²³æµå›¾å¯è§†åŒ–å‡½æ•° ====================

def prepare_flow_data(records, time_granularity='daily', metric='views'):
    """å‡†å¤‡æ²³æµå›¾æ•°æ®"""
    if not records:
        return pd.DataFrame()
    
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ ¹æ®æ—¶é—´ç²’åº¦åˆ†ç»„
    if time_granularity == 'daily':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.date
    elif time_granularity == 'weekly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('W').dt.start_time.dt.date
    elif time_granularity == 'monthly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('M').dt.start_time.dt.date
    
    # æŒ‰æ—¶é—´å’Œè´¦å·åˆ†ç»„èšåˆæ•°æ®
    flow_data = df.groupby(['æ—¶é—´åˆ†ç»„', 'channel_name'])[metric].sum().reset_index()
    
    # åˆ›å»ºé€è§†è¡¨
    pivot_data = flow_data.pivot(index='æ—¶é—´åˆ†ç»„', columns='channel_name', values=metric).fillna(0)
    
    return pivot_data

def create_area_chart(records, metric='views', time_granularity='daily'):
    """åˆ›å»ºé¢ç§¯å›¾ï¼ˆæ²³æµå›¾çš„å¦ä¸€ç§å½¢å¼ï¼‰"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    pivot_data = prepare_flow_data(records, time_granularity, metric)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºé¢ç§¯å›¾
    fig = go.Figure()
    
    # ä¸ºæ¯ä¸ªè´¦å·æ·»åŠ é¢ç§¯
    for account in pivot_data.columns:
        fig.add_trace(go.Scatter(
            x=pivot_data.index,
            y=pivot_data[account],
            mode='lines',
            fill='tonexty' if account != pivot_data.columns[0] else 'tozeroy',
            name=account,
            stackgroup='one',
            line=dict(width=0.5)
        ))
    
    fig.update_layout(
        title=f"{metric}é¢ç§¯å›¾ - {time_granularity}æ•°æ®",
        xaxis_title="æ—¶é—´",
        yaxis_title=metric,
        height=500,
        hovermode='x unified'
    )
    
    return fig

def create_stream_chart(records, metric='views', time_granularity='daily'):
    """åˆ›å»ºæµå›¾ï¼ˆStream Chartï¼‰"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    pivot_data = prepare_flow_data(records, time_granularity, metric)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºæµå›¾
    fig = go.Figure()
    
    # ä¸ºæ¯ä¸ªè´¦å·æ·»åŠ æµ
    for account in pivot_data.columns:
        fig.add_trace(go.Scatter(
            x=pivot_data.index,
            y=pivot_data[account],
            mode='lines',
            fill='tonexty' if account != pivot_data.columns[0] else 'tozeroy',
            name=account,
            stackgroup='one',
            line=dict(width=0.5, shape='spline'),
            hovertemplate=f'<b>{account}</b><br>' +
                         'æ—¶é—´: %{x}<br>' +
                         f'{metric}: %{{y}}<br>' +
                         '<extra></extra>'
        ))
    
    fig.update_layout(
        title=f"{metric}æµå›¾ - {time_granularity}æ•°æ®",
        xaxis_title="æ—¶é—´",
        yaxis_title=metric,
        height=500,
        hovermode='x unified',
        showlegend=True
    )
    
    return fig

def create_ridge_plot(records, metric='views', time_granularity='daily'):
    """åˆ›å»ºå±±è„Šå›¾ï¼ˆRidge Plotï¼‰"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    pivot_data = prepare_flow_data(records, time_granularity, metric)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºå­å›¾
    accounts = pivot_data.columns
    fig = make_subplots(
        rows=len(accounts), 
        cols=1,
        subplot_titles=accounts,
        vertical_spacing=0.02
    )
    
    # ä¸ºæ¯ä¸ªè´¦å·åˆ›å»ºå±±è„Šå›¾
    for i, account in enumerate(accounts, 1):
        fig.add_trace(
            go.Scatter(
                x=pivot_data.index,
                y=pivot_data[account],
                mode='lines',
                fill='tozeroy',
                name=account,
                line=dict(width=2),
                showlegend=False
            ),
            row=i, col=1
        )
    
    fig.update_layout(
        title=f"{metric}å±±è„Šå›¾ - {time_granularity}æ•°æ®",
        height=200 * len(accounts),
        showlegend=False
    )
    
    return fig

def create_advanced_stream_chart(records, metric='views', time_granularity='daily', smoothing=True):
    """åˆ›å»ºé«˜çº§æµå›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ ¹æ®æ—¶é—´ç²’åº¦åˆ†ç»„
    if time_granularity == 'daily':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.date
    elif time_granularity == 'weekly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('W').dt.start_time.dt.date
    elif time_granularity == 'monthly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('M').dt.start_time.dt.date
    
    # æŒ‰æ—¶é—´å’Œè´¦å·åˆ†ç»„èšåˆæ•°æ®
    flow_data = df.groupby(['æ—¶é—´åˆ†ç»„', 'channel_name'])[metric].sum().reset_index()
    
    # åˆ›å»ºé€è§†è¡¨
    pivot_data = flow_data.pivot(index='æ—¶é—´åˆ†ç»„', columns='channel_name', values=metric).fillna(0)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºæµå›¾
    fig = go.Figure()
    
    # ä¸ºæ¯ä¸ªè´¦å·æ·»åŠ æµ
    for i, account in enumerate(pivot_data.columns):
        # è®¡ç®—ç´¯ç§¯å€¼ç”¨äºå †å 
        if i == 0:
            y_values = pivot_data[account].values
        else:
            y_values = pivot_data[pivot_data.columns[:i+1]].sum(axis=1).values
        
        # æ·»åŠ å¡«å……åŒºåŸŸ
        fig.add_trace(go.Scatter(
            x=pivot_data.index,
            y=y_values,
            mode='lines',
            fill='tonexty' if i > 0 else 'tozeroy',
            name=account,
            line=dict(width=0.5, shape='spline' if smoothing else 'linear'),
            hovertemplate=f'<b>{account}</b><br>' +
                         'æ—¶é—´: %{x}<br>' +
                         f'{metric}: %{{y}}<br>' +
                         '<extra></extra>',
            stackgroup='one'
        ))
    
    fig.update_layout(
        title=f"{metric}é«˜çº§æµå›¾ - {time_granularity}æ•°æ®",
        xaxis_title="æ—¶é—´",
        yaxis_title=metric,
        height=600,
        hovermode='x unified',
        showlegend=True,
        template='plotly_white'
    )
    
    return fig

def create_parallel_categories_diagram(records, metric='views'):
    """åˆ›å»ºå¹³è¡Œç±»åˆ«å›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ·»åŠ æ—¶é—´ç»´åº¦
    df['å¹´ä»½'] = df['publish_date'].dt.year
    df['æœˆä»½'] = df['publish_date'].dt.month
    df['å­£åº¦'] = df['publish_date'].dt.quarter
    
    # æŒ‰å­£åº¦å’Œè´¦å·åˆ†ç»„
    quarterly_data = df.groupby(['å¹´ä»½', 'å­£åº¦', 'channel_name'])[metric].sum().reset_index()
    quarterly_data['æ—¶é—´æ ‡ç­¾'] = quarterly_data['å¹´ä»½'].astype(str) + 'Q' + quarterly_data['å­£åº¦'].astype(str)
    
    # åˆ›å»ºå¹³è¡Œç±»åˆ«å›¾
    fig = go.Figure(data=go.Parcats(
        dimensions=[
            {'label': 'æ—¶é—´', 'values': quarterly_data['æ—¶é—´æ ‡ç­¾']},
            {'label': 'è´¦å·', 'values': quarterly_data['channel_name']}
        ],
        counts=quarterly_data[metric].values,
        line={'color': quarterly_data[metric], 'colorscale': 'Viridis'}
    ))
    
    fig.update_layout(
        title=f"{metric}å¹³è¡Œç±»åˆ«å›¾",
        height=500
    )
    
    return fig

def create_treemap_chart(records, metric='views'):
    """åˆ›å»ºæ ‘çŠ¶å›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æŒ‰è´¦å·åˆ†ç»„
    account_data = df.groupby('channel_name')[metric].sum().reset_index()
    
    # åˆ›å»ºæ ‘çŠ¶å›¾
    fig = go.Figure(go.Treemap(
        labels=account_data['channel_name'],
        values=account_data[metric],
        parents=[''] * len(account_data),
        textinfo="label+value+percent parent"
    ))
    
    fig.update_layout(
        title=f"{metric}æ ‘çŠ¶å›¾",
        height=500
    )
    
    return fig

def create_icicle_chart(records, metric='views'):
    """åˆ›å»ºå†°æŸ±å›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ·»åŠ æ—¶é—´ç»´åº¦
    df['å¹´ä»½'] = df['publish_date'].dt.year
    df['æœˆä»½'] = df['publish_date'].dt.month
    
    # æŒ‰å¹´ä»½ã€æœˆä»½ã€è´¦å·åˆ†ç»„
    hierarchical_data = df.groupby(['å¹´ä»½', 'æœˆä»½', 'channel_name'])[metric].sum().reset_index()
    
    # åˆ›å»ºå±‚æ¬¡ç»“æ„æ•°æ®
    icicle_data = []
    for _, row in hierarchical_data.iterrows():
        # å¹´ä»½èŠ‚ç‚¹
        year_id = f"year_{row['å¹´ä»½']}"
        icicle_data.append({
            'ids': year_id,
            'labels': str(row['å¹´ä»½']),
            'parents': '',
            'values': hierarchical_data[hierarchical_data['å¹´ä»½'] == row['å¹´ä»½']][metric].sum()
        })
        
        # æœˆä»½èŠ‚ç‚¹
        month_id = f"month_{row['å¹´ä»½']}_{row['æœˆä»½']}"
        icicle_data.append({
            'ids': month_id,
            'labels': f"{row['å¹´ä»½']}-{row['æœˆä»½']:02d}",
            'parents': year_id,
            'values': hierarchical_data[(hierarchical_data['å¹´ä»½'] == row['å¹´ä»½']) & 
                                      (hierarchical_data['æœˆä»½'] == row['æœˆä»½'])][metric].sum()
        })
        
        # è´¦å·èŠ‚ç‚¹
        account_id = f"account_{row['å¹´ä»½']}_{row['æœˆä»½']}_{row['channel_name']}"
        icicle_data.append({
            'ids': account_id,
            'labels': row['channel_name'],
            'parents': month_id,
            'values': row[metric]
        })
    
    # åˆ›å»ºå†°æŸ±å›¾
    fig = go.Figure(go.Icicle(
        ids=[d['ids'] for d in icicle_data],
        labels=[d['labels'] for d in icicle_data],
        parents=[d['parents'] for d in icicle_data],
        values=[d['values'] for d in icicle_data],
        branchvalues="total"
    ))
    
    fig.update_layout(
        title=f"{metric}å†°æŸ±å›¾",
        height=600
    )
    
    return fig

def create_river_flow_chart(records, metric='views', time_granularity='daily', flow_type='stacked'):
    """åˆ›å»ºæ²³æµå›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ ¹æ®æ—¶é—´ç²’åº¦åˆ†ç»„
    if time_granularity == 'daily':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.date
    elif time_granularity == 'weekly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('W').dt.start_time.dt.date
    elif time_granularity == 'monthly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('M').dt.start_time.dt.date
    
    # æŒ‰æ—¶é—´å’Œè´¦å·åˆ†ç»„èšåˆæ•°æ®
    flow_data = df.groupby(['æ—¶é—´åˆ†ç»„', 'channel_name'])[metric].sum().reset_index()
    
    # åˆ›å»ºé€è§†è¡¨
    pivot_data = flow_data.pivot(index='æ—¶é—´åˆ†ç»„', columns='channel_name', values=metric).fillna(0)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºæ²³æµå›¾
    fig = go.Figure()
    
    if flow_type == 'stacked':
        # å †å æ²³æµå›¾
        for i, account in enumerate(pivot_data.columns):
            # è®¡ç®—ç´¯ç§¯å€¼ç”¨äºå †å 
            if i == 0:
                y_values = pivot_data[account].values
            else:
                y_values = pivot_data[pivot_data.columns[:i+1]].sum(axis=1).values
            
            # æ·»åŠ å¡«å……åŒºåŸŸ
            fig.add_trace(go.Scatter(
                x=pivot_data.index,
                y=y_values,
                mode='lines',
                fill='tonexty' if i > 0 else 'tozeroy',
                name=account,
                line=dict(width=0.5, shape='spline'),
                hovertemplate=f'<b>{account}</b><br>' +
                             'æ—¶é—´: %{x}<br>' +
                             f'{metric}: %{{y}}<br>' +
                             '<extra></extra>',
                stackgroup='one'
            ))
    
    elif flow_type == 'separate':
        # åˆ†ç¦»æ²³æµå›¾
        for account in pivot_data.columns:
            fig.add_trace(go.Scatter(
                x=pivot_data.index,
                y=pivot_data[account].values,
                mode='lines+markers',
                name=account,
                line=dict(width=2, shape='spline'),
                marker=dict(size=4),
                hovertemplate=f'<b>{account}</b><br>' +
                             'æ—¶é—´: %{x}<br>' +
                             f'{metric}: %{{y}}<br>' +
                             '<extra></extra>'
            ))
    
    elif flow_type == 'normalized':
        # æ ‡å‡†åŒ–æ²³æµå›¾
        # è®¡ç®—æ¯ä¸ªæ—¶é—´ç‚¹çš„æ€»å’Œ
        total_values = pivot_data.sum(axis=1)
        
        for i, account in enumerate(pivot_data.columns):
            # è®¡ç®—ç™¾åˆ†æ¯”
            percentage_values = (pivot_data[account] / total_values * 100).fillna(0)
            
            # è®¡ç®—ç´¯ç§¯ç™¾åˆ†æ¯”
            if i == 0:
                y_values = percentage_values.values
            else:
                y_values = (pivot_data[pivot_data.columns[:i+1]] / total_values * 100).sum(axis=1).values
            
            fig.add_trace(go.Scatter(
                x=pivot_data.index,
                y=y_values,
                mode='lines',
                fill='tonexty' if i > 0 else 'tozeroy',
                name=account,
                line=dict(width=0.5, shape='spline'),
                hovertemplate=f'<b>{account}</b><br>' +
                             'æ—¶é—´: %{x}<br>' +
                             f'{metric}: %{{y:.1f}}%<br>' +
                             '<extra></extra>',
                stackgroup='one'
            ))
    
    fig.update_layout(
        title=f"{metric}æ²³æµå›¾ - {time_granularity}æ•°æ® ({flow_type})",
        xaxis_title="æ—¶é—´",
        yaxis_title=metric if flow_type != 'normalized' else "ç™¾åˆ†æ¯” (%)",
        height=600,
        hovermode='x unified',
        showlegend=True,
        template='plotly_white'
    )
    
    return fig

def create_ridge_flow_chart(records, metric='views', time_granularity='daily'):
    """åˆ›å»ºå±±è„Šæµå›¾"""
    if not records:
        return None
    
    # å‡†å¤‡æ•°æ®
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'], errors='coerce')
    df = df.dropna(subset=['publish_date'])
    
    # æ ¹æ®æ—¶é—´ç²’åº¦åˆ†ç»„
    if time_granularity == 'daily':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.date
    elif time_granularity == 'weekly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('W').dt.start_time.dt.date
    elif time_granularity == 'monthly':
        df['æ—¶é—´åˆ†ç»„'] = df['publish_date'].dt.to_period('M').dt.start_time.dt.date
    
    # æŒ‰æ—¶é—´å’Œè´¦å·åˆ†ç»„èšåˆæ•°æ®
    flow_data = df.groupby(['æ—¶é—´åˆ†ç»„', 'channel_name'])[metric].sum().reset_index()
    
    # åˆ›å»ºé€è§†è¡¨
    pivot_data = flow_data.pivot(index='æ—¶é—´åˆ†ç»„', columns='channel_name', values=metric).fillna(0)
    
    if pivot_data.empty:
        return None
    
    # åˆ›å»ºå­å›¾
    accounts = pivot_data.columns
    fig = make_subplots(
        rows=len(accounts), 
        cols=1,
        subplot_titles=accounts,
        vertical_spacing=0.02
    )
    
    # ä¸ºæ¯ä¸ªè´¦å·åˆ›å»ºå±±è„Šå›¾
    for i, account in enumerate(accounts, 1):
        fig.add_trace(
            go.Scatter(
                x=pivot_data.index,
                y=pivot_data[account],
                mode='lines',
                fill='tozeroy',
                name=account,
                line=dict(width=2, shape='spline'),
                showlegend=False
            ),
            row=i, col=1
        )
    
    fig.update_layout(
        title=f"{metric}å±±è„Šæµå›¾ - {time_granularity}æ•°æ®",
        height=200 * len(accounts),
        showlegend=False
    )
    
    return fig

def create_monthly_calendar(records, year, month, selected_channels):
    """åˆ›å»ºæœˆåº¦æ—¥å†è§†å›¾"""
    if not records:
        return None
    
    # è¿‡æ»¤æŒ‡å®šå¹´æœˆçš„æ•°æ®
    filtered_data = []
    for record in records:
        if record.get("channel_name") in selected_channels:
            try:
                publish_date = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                if publish_date.year == year and publish_date.month == month:
                    filtered_data.append(record)
            except (ValueError, TypeError):
                continue
    
    if not filtered_data:
        return None
    
    # åˆ›å»ºæ—¥å†æ•°æ®
    df = pd.DataFrame(filtered_data)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    
    # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
    daily_stats = df.groupby('publish_date').agg({
        'views': 'sum',
        'shares': 'sum',
        'title': lambda x: list(x)
    }).reset_index()
    
    # åˆ›å»ºæ—¥å†HTML
    cal = calendar.monthcalendar(year, month)
    month_name = calendar.month_name[month]
    
    # ä½¿ç”¨Streamlitçš„HTMLç»„ä»¶
    html_content = f"""
    <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;">
        <h2 style="text-align: center; color: #333;">{year}å¹´{month}æœˆå‘å¸ƒæ—¥å†</h2>
        <table style="width: 100%; border-collapse: collapse; border: 1px solid #ddd;">
            <thead>
                <tr>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨ä¸€</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨äºŒ</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨ä¸‰</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨å››</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨äº”</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨å…­</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨æ—¥</th>
                </tr>
            </thead>
            <tbody>
    """
    
    for week in cal:
        html_content += "<tr>"
        for day in week:
            if day == 0:
                html_content += '<td style="border: 1px solid #ddd; padding: 8px; background-color: #f9f9f9;">&nbsp;</td>'
            else:
                # æŸ¥æ‰¾å½“å¤©çš„å‘å¸ƒè®°å½•
                day_date = datetime(year, month, day)
                day_records = daily_stats[daily_stats['publish_date'].dt.date == day_date.date()]
                
                if not day_records.empty:
                    # æœ‰å‘å¸ƒè®°å½•
                    total_views = day_records['views'].sum()
                    total_shares = day_records['shares'].sum()
                    article_count = len(day_records)
                    
                    html_content += f"""
                    <td style="border: 1px solid #ddd; padding: 8px; background-color: #e8f5e8; position: relative;">
                        <div style="font-weight: bold; color: #2d5a2d;">{day}</div>
                        <div style="font-size: 12px; color: #666;">
                            ğŸ“ {article_count}ç¯‡<br>
                            ğŸ‘€ {total_views:,}<br>
                            ğŸ“¤ {total_shares:,}
                        </div>
                    </td>
                    """
                else:
                    # æ— å‘å¸ƒè®°å½•
                    html_content += f'<td style="border: 1px solid #ddd; padding: 8px;">{day}</td>'
        html_content += "</tr>"
    
    html_content += """
            </tbody>
        </table>
    </div>
    """
    
    return html_content

def create_timeline_view(records, selected_channels):
    """åˆ›å»ºæ—¶é—´çº¿è§†å›¾"""
    if not records:
        return None
    
    # è¿‡æ»¤æ•°æ®
    filtered_data = []
    for record in records:
        if record.get("channel_name") in selected_channels:
            filtered_data.append(record)
    
    if not filtered_data:
        return None
    
    df = pd.DataFrame(filtered_data)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    df = df.sort_values('publish_date')
    
    # åˆ›å»ºæ—¶é—´çº¿å›¾è¡¨
    fig = go.Figure()
    
    # ä¸ºæ¯ä¸ªé¢‘é“åˆ›å»ºä¸åŒçš„é¢œè‰²
    channels = df['channel_name'].unique()
    colors = px.colors.qualitative.Set3[:len(channels)]
    
    for i, channel in enumerate(channels):
        channel_data = df[df['channel_name'] == channel]
        
        fig.add_trace(go.Scatter(
            x=channel_data['publish_date'],
            y=channel_data['views'],
            mode='markers+lines',
            name=channel,
            marker=dict(size=8, color=colors[i]),
            hovertemplate='<b>%{text}</b><br>' +
                         'æ—¥æœŸ: %{x}<br>' +
                         'é˜…è¯»äººæ•°: %{y:,}<br>' +
                         'åˆ†äº«äººæ•°: %{customdata}<br>' +
                         '<extra></extra>',
            text=channel_data['title'],
            customdata=channel_data['shares']
        ))
    
    fig.update_layout(
        title="å‘å¸ƒæ—¶é—´çº¿",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="é˜…è¯»äººæ•°",
        height=500,
        hovermode='closest'
    )
    
    return fig

st.set_page_config(page_title="é¢‘é“å‘å¸ƒå†å²", layout="wide")
st.title(f"é¢‘é“å‘å¸ƒå†å² - æ•°æ®å¯è§†åŒ–åˆ†æ")

# æ·»åŠ åˆ·æ–°æŒ‰é’®
col1, col2, col3 = st.columns([1, 1, 1])
with col1:
    if st.button(f"åˆ·æ–°æ•°æ®", help="ä»CSVæ–‡ä»¶é‡æ–°åŠ è½½æœ€æ–°æ•°æ®"):
        st.rerun()
with col2:
    # æ˜¾ç¤ºæ•°æ®æ–‡ä»¶ä¿¡æ¯
    if os.path.exists(CSV_PATH):
        file_size = os.path.getsize(CSV_PATH)
        file_time = datetime.fromtimestamp(os.path.getmtime(CSV_PATH))
        st.info(f"ğŸ“ æ•°æ®æ–‡ä»¶: {file_size:,} å­—èŠ‚ | æ›´æ–°æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        st.warning(f"æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
with col3:
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    all_records_temp = load_csv_data()
    st.metric(f"æ€»è®°å½•æ•°", len(all_records_temp))

def get_all_records():
    """è·å–æ‰€æœ‰å‘å¸ƒè®°å½•"""
    return load_csv_data()

# åŠ è½½æ•°æ®
all_records = get_all_records()

# è·å–æ‰€æœ‰é¢‘é“åç§°
all_channels = []
if all_records:
    for record in all_records:
        if "channel_name" in record and record["channel_name"]:
            all_channels.append(record["channel_name"])
    all_channels = list(set(all_channels))

# ä¾§è¾¹æ è¿‡æ»¤å™¨
with st.sidebar:
    st.subheader(f"é¢‘é“ç­›é€‰")
    selected_channels = st.multiselect(
        "é€‰æ‹©é¢‘é“",
        all_channels,
        default=all_channels
    )
    
    st.subheader(f"æ—¥æœŸèŒƒå›´")
    # è·å–æ•°æ®ä¸­çš„æ—¥æœŸèŒƒå›´
    if all_records:
        dates = []
        for record in all_records:
            if "publish_date" in record and record["publish_date"]:
                try:
                    if isinstance(record["publish_date"], str) and record["publish_date"].strip():
                        date_obj = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                        dates.append(date_obj)
                except (ValueError, TypeError):
                    continue
        
        if dates:
            min_date = min(dates).date()
            max_date = max(dates).date()
        else:
            min_date = datetime.now().date() - timedelta(days=30)
            max_date = datetime.now().date()
    else:
        min_date = datetime.now().date() - timedelta(days=30)
        max_date = datetime.now().date()
    
    start_date = st.date_input("å¼€å§‹æ—¥æœŸ", min_date)
    end_date = st.date_input("ç»“æŸæ—¥æœŸ", max_date)

# è¿‡æ»¤æ•°æ®
filtered_records = []
for record in all_records:
    if ("channel_name" in record and record["channel_name"] in selected_channels and
        "publish_date" in record and record["publish_date"]):
        try:
            publish_date = datetime.strptime(record["publish_date"], "%Y-%m-%d").date()
            if start_date <= publish_date <= end_date:
                filtered_records.append(record)
        except (ValueError, TypeError):
            continue

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
    f"æ¦‚è§ˆä»ªè¡¨æ¿", 
    "è¶‹åŠ¿åˆ†æ", 
    "å‚ä¸åº¦åˆ†æ",
    f"æ—¶é—´åˆ†æ",
    f"å‘å¸ƒæ—¥å†",
    f"è¯¦ç»†è®°å½•",
    f"é«˜çº§åˆ†æ",
    "æ²³æµå›¾å¯è§†åŒ–"
])

with tab1:
    st.subheader(f"æ¦‚è§ˆä»ªè¡¨æ¿")
    
    if filtered_records:
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_published = len([r for r in filtered_records if r["status"] == "published"])
        total_views = sum(r.get("views", 0) for r in filtered_records)
        total_shares = sum(r.get("shares", 0) for r in filtered_records)
        avg_read_completion = np.mean([r.get("read_completion_rate", 0) for r in filtered_records])
        avg_delivery_read_rate = np.mean([r.get("delivery_read_rate", 0) for r in filtered_records])
        
        # æ˜¾ç¤ºç»Ÿè®¡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric(f"æ€»å‘å¸ƒæ•°", total_published)
        with col2:
            st.metric("ğŸ‘€ æ€»é˜…è¯»äººæ•°", f"{total_views:,}")
        with col3:
            st.metric("ğŸ“¤ æ€»åˆ†äº«äººæ•°", f"{total_shares:,}")
        with col4:
            st.metric(f"å¹³å‡é˜…è¯»å®Œæˆç‡", f"{avg_read_completion:.1f}%")
        
        # é¢‘é“è¡¨ç°ä»ªè¡¨æ¿
        dashboard_fig, channel_stats = create_channel_performance_dashboard(filtered_records)
        if dashboard_fig:
            st.plotly_chart(dashboard_fig, use_container_width=True)
        
        # æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡è¡¨æ ¼
        if channel_stats is not None:
            st.subheader(f"é¢‘é“è¯¦ç»†ç»Ÿè®¡")
            st.dataframe(channel_stats, use_container_width=True)
        
        # çƒ­é—¨æ–‡ç« 
        st.subheader("ğŸ”¥ çƒ­é—¨æ–‡ç«  TOP 10")
        top_articles = sorted(filtered_records, key=lambda x: x.get("views", 0), reverse=True)[:10]
        
        for i, article in enumerate(top_articles, 1):
            with st.expander(f"#{i} {article.get('title', 'æ— æ ‡é¢˜')} ({article.get('channel_name', 'æœªçŸ¥é¢‘é“')})"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.write(f"**é˜…è¯»äººæ•°:** {article.get('views', 0):,}")
                with col2:
                    st.write(f"**åˆ†äº«äººæ•°:** {article.get('shares', 0):,}")
                with col3:
                    st.write(f"**é˜…è¯»å®Œæˆç‡:** {article.get('read_completion_rate', 0):.1f}%")
                with col4:
                    st.write(f"**å‘å¸ƒæ—¥æœŸ:** {article.get('publish_date', '')}")
                
                if article.get('url'):
                    st.write(f"**é“¾æ¥:** {article['url']}")
    else:
        st.info("æš‚æ— æ•°æ®")

with tab2:
    st.subheader("ğŸ“ˆ è¶‹åŠ¿åˆ†æ")
    
    if filtered_records:
        # è¶‹åŠ¿åˆ†æå›¾è¡¨
        trend_fig = create_trend_analysis(filtered_records)
        if trend_fig:
            st.plotly_chart(trend_fig, use_container_width=True)
        
        # æœˆåº¦ç»Ÿè®¡
        st.subheader(f"æœˆåº¦ç»Ÿè®¡")
        df_monthly = pd.DataFrame(filtered_records)
        df_monthly['publish_date'] = pd.to_datetime(df_monthly['publish_date'])
        df_monthly['month'] = df_monthly['publish_date'].dt.to_period('M')
        
        monthly_stats = df_monthly.groupby('month').agg({
            'views': 'sum',
            'shares': 'sum',
            'read_completion_rate': 'mean',
            'delivery_read_rate': 'mean'
        }).reset_index()
        
        monthly_stats['month'] = monthly_stats['month'].astype(str)
        
        fig_monthly = make_subplots(
            rows=1, cols=2,
            subplot_titles=("æœˆåº¦é˜…è¯»äººæ•°", "æœˆåº¦åˆ†äº«äººæ•°"),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        fig_monthly.add_trace(
            go.Bar(x=monthly_stats['month'], y=monthly_stats['views'], name="é˜…è¯»äººæ•°"),
            row=1, col=1
        )
        
        fig_monthly.add_trace(
            go.Bar(x=monthly_stats['month'], y=monthly_stats['shares'], name="åˆ†äº«äººæ•°"),
            row=1, col=2
        )
        
        fig_monthly.update_layout(height=400, title_text="æœˆåº¦è¶‹åŠ¿")
        st.plotly_chart(fig_monthly, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab3:
    st.subheader("ğŸ¯ ç”¨æˆ·å‚ä¸åº¦åˆ†æ")
    
    if filtered_records:
        # å‚ä¸åº¦åˆ†æå›¾è¡¨
        engagement_fig = create_engagement_analysis(filtered_records)
        if engagement_fig:
            st.plotly_chart(engagement_fig, use_container_width=True)
        
        # åˆ†äº«æ•ˆç‡åˆ†æ
        st.subheader("ğŸ“¤ åˆ†äº«æ•ˆç‡åˆ†æ")
        df_share = pd.DataFrame(filtered_records)
        
        # è®¡ç®—åˆ†äº«ç›¸å…³æŒ‡æ ‡
        df_share['share_efficiency'] = df_share['share_generated_reads'] / df_share['total_shares'].replace(0, 1)
        df_share['share_engagement'] = df_share['shares'] / df_share['views'].replace(0, 1) * 100
        
        fig_share = make_subplots(
            rows=1, cols=2,
            subplot_titles=("åˆ†äº«æ•ˆç‡åˆ†å¸ƒ", "åˆ†äº«å‚ä¸åº¦åˆ†å¸ƒ"),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        fig_share.add_trace(
            go.Histogram(x=df_share['share_efficiency'], name="åˆ†äº«æ•ˆç‡", nbinsx=20),
            row=1, col=1
        )
        
        fig_share.add_trace(
            go.Histogram(x=df_share['share_engagement'], name="åˆ†äº«å‚ä¸åº¦", nbinsx=20),
            row=1, col=2
        )
        
        fig_share.update_layout(height=400, title_text="åˆ†äº«æ•ˆç‡åˆ†æ")
        st.plotly_chart(fig_share, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab4:
    st.subheader(f"æ—¶é—´åˆ†æ")
    
    if filtered_records:
        # å‘å¸ƒæ—¶é—´çƒ­åŠ›å›¾
        heatmap_fig = create_heatmap_analysis(filtered_records)
        if heatmap_fig:
            st.plotly_chart(heatmap_fig, use_container_width=True)
        
        # æ˜ŸæœŸå‘å¸ƒé¢‘ç‡
        st.subheader(f"æ˜ŸæœŸå‘å¸ƒé¢‘ç‡")
        df_weekday = pd.DataFrame(filtered_records)
        df_weekday['publish_date'] = pd.to_datetime(df_weekday['publish_date'])
        df_weekday['weekday'] = df_weekday['publish_date'].dt.day_name()
        
        weekday_counts = df_weekday['weekday'].value_counts()
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        
        weekday_counts = weekday_counts.reindex(weekday_order)
        weekday_counts.index = weekday_cn
        
        fig_weekday = px.bar(
            x=weekday_counts.index, 
            y=weekday_counts.values,
            title="å„æ˜ŸæœŸå‘å¸ƒæ–‡ç« æ•°é‡",
            labels={'x': 'æ˜ŸæœŸ', 'y': 'æ–‡ç« æ•°é‡'}
        )
        st.plotly_chart(fig_weekday, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab5:
    st.subheader(f"å‘å¸ƒæ—¥å†")
    
    if filtered_records:
        # é€‰æ‹©æ—¥å†è§†å›¾ç±»å‹
        calendar_type = st.selectbox(
            "é€‰æ‹©æ—¥å†è§†å›¾ç±»å‹",
            ["æœˆåº¦æ—¥å†", "æ—¶é—´çº¿è§†å›¾"],
            index=0
        )
        
        if calendar_type == "æœˆåº¦æ—¥å†":
            st.subheader(f"æœˆåº¦å‘å¸ƒæ—¥å†")
            
            # è·å–æ•°æ®ä¸­çš„å¹´ä»½èŒƒå›´
            if filtered_records:
                dates = []
                for record in filtered_records:
                    if "publish_date" in record and record["publish_date"]:
                        try:
                            if isinstance(record["publish_date"], str) and record["publish_date"].strip():
                                date_obj = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                                dates.append(date_obj)
                        except (ValueError, TypeError):
                            continue
                
                if dates:
                    years = sorted(list(set(date.year for date in dates)))
                else:
                    years = [datetime.now().year]
                current_year = datetime.now().year
                
                # å¦‚æœæ•°æ®ä¸­æ²¡æœ‰å½“å‰å¹´ä»½ï¼Œæ·»åŠ å½“å‰å¹´ä»½
                if current_year not in years:
                    years.append(current_year)
                    years.sort()
                
                # é»˜è®¤é€‰æ‹©å½“å‰å¹´ä»½
                default_year_index = years.index(current_year) if current_year in years else 0
                
                col1, col2 = st.columns(2)
                with col1:
                    year = st.selectbox("é€‰æ‹©å¹´ä»½", years, index=default_year_index)
                with col2:
                    month = st.selectbox("é€‰æ‹©æœˆä»½", range(1, 13), index=datetime.now().month-1)
                
                calendar_html = create_monthly_calendar(filtered_records, year, month, selected_channels)
                if calendar_html:
                    # ä½¿ç”¨Streamlitçš„HTMLç»„ä»¶æ˜¾ç¤ºæ—¥å†
                    st.components.v1.html(calendar_html, height=600)
                else:
                    st.info("è¯¥æœˆä»½æš‚æ— å‘å¸ƒè®°å½•")
            else:
                # æ²¡æœ‰æ•°æ®æ—¶ï¼Œæ˜¾ç¤ºå½“å‰å¹´æœˆ
                col1, col2 = st.columns(2)
                with col1:
                    year = st.selectbox("é€‰æ‹©å¹´ä»½", [datetime.now().year], index=0)
                with col2:
                    month = st.selectbox("é€‰æ‹©æœˆä»½", range(1, 13), index=datetime.now().month-1)
                
                st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ·»åŠ å‘å¸ƒè®°å½•")
        
        elif calendar_type == "æ—¶é—´çº¿è§†å›¾":
            st.subheader("ğŸ“ˆ å‘å¸ƒæ—¶é—´çº¿")
            timeline_fig = create_timeline_view(filtered_records, selected_channels)
            if timeline_fig:
                st.plotly_chart(timeline_fig, use_container_width=True)
            else:
                st.info("æš‚æ— æ•°æ®ç”Ÿæˆæ—¶é—´çº¿")
    else:
        st.info("æš‚æ— æ•°æ®")

with tab6:
    st.subheader(f"è¯¦ç»†è®°å½•")
    
    if filtered_records:
        # åˆ›å»ºæ•°æ®è¡¨æ ¼
        df_records = pd.DataFrame(filtered_records)
        
        # é€‰æ‹©æ˜¾ç¤ºçš„åˆ—
        display_columns = [
            "id", "channel_name", "title", "publish_date", 
            "views", "shares", "read_completion_rate", "delivery_read_rate",
            "share_generated_reads", "followers_after_read"
        ]
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        available_columns = [col for col in display_columns if col in df_records.columns]
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.dataframe(
            df_records[available_columns],
            use_container_width=True
        )
        
        # å¯¼å‡ºåŠŸèƒ½
        if st.button(f"å¯¼å‡ºæ•°æ®"):
            csv = df_records.to_csv(index=False)
            st.download_button(
                label="ä¸‹è½½CSVæ–‡ä»¶",
                data=csv,
                file_name=f"channel_publish_history_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    else:
        st.info("æš‚æ— æ•°æ®")

with tab7:
    st.subheader(f"é«˜çº§åˆ†æ")
    
    if filtered_records:
        # ç›¸å…³æ€§åˆ†æ
        st.subheader(f"æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ")
        df_corr = pd.DataFrame(filtered_records)
        
        # é€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ
        numeric_columns = [
            'views', 'shares', 'read_completion_rate', 'delivery_read_rate',
            'share_generated_reads', 'followers_after_read', 'total_views', 'total_shares'
        ]
        
        available_numeric = [col for col in numeric_columns if col in df_corr.columns]
        
        if len(available_numeric) > 1:
            correlation_matrix = df_corr[available_numeric].corr()
            
            fig_corr = px.imshow(
                correlation_matrix,
                title="æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale='RdBu',
                aspect="auto"
            )
            st.plotly_chart(fig_corr, use_container_width=True)
        
        # åˆ†å¸ƒåˆ†æ
        st.subheader("ğŸ“ˆ æŒ‡æ ‡åˆ†å¸ƒåˆ†æ")
        if filtered_records:
            df_dist = pd.DataFrame(filtered_records)
            
            # é€‰æ‹©è¦åˆ†æçš„æŒ‡æ ‡
            metrics_to_analyze = ['views', 'shares', 'read_completion_rate', 'delivery_read_rate']
            available_metrics = [m for m in metrics_to_analyze if m in df_dist.columns]
            
            if available_metrics:
                fig_dist = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=available_metrics,
                    specs=[[{"secondary_y": False}, {"secondary_y": False}],
                           [{"secondary_y": False}, {"secondary_y": False}]]
                )
                
                for i, metric in enumerate(available_metrics):
                    row = (i // 2) + 1
                    col = (i % 2) + 1
                    
                    fig_dist.add_trace(
                        go.Histogram(x=df_dist[metric], name=metric, nbinsx=20),
                        row=row, col=col
                    )
                
                fig_dist.update_layout(height=500, title_text="æŒ‡æ ‡åˆ†å¸ƒåˆ†æ")
                st.plotly_chart(fig_dist, use_container_width=True)
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        st.subheader(f"å¼‚å¸¸å€¼æ£€æµ‹")
        if filtered_records:
            df_outlier = pd.DataFrame(filtered_records)
            
            # æ£€æµ‹é˜…è¯»äººæ•°çš„å¼‚å¸¸å€¼
            if 'views' in df_outlier.columns:
                Q1 = df_outlier['views'].quantile(0.25)
                Q3 = df_outlier['views'].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df_outlier[(df_outlier['views'] < lower_bound) | (df_outlier['views'] > upper_bound)]
                
                if not outliers.empty:
                    st.warning(f"å‘ç° {len(outliers)} ä¸ªé˜…è¯»äººæ•°å¼‚å¸¸å€¼")
                    st.dataframe(outliers[['title', 'channel_name', 'views', 'publish_date']], use_container_width=True)
                else:
                    st.success("æœªå‘ç°é˜…è¯»äººæ•°å¼‚å¸¸å€¼")
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab8:
    st.subheader("ğŸŒŠ æ²³æµå›¾å¯è§†åŒ–")
    
    if filtered_records:
        # ä¾§è¾¹æ æ§åˆ¶é¢æ¿
        with st.sidebar:
            st.header("ğŸ›ï¸ æ²³æµå›¾æ§åˆ¶é¢æ¿")
            
            # å›¾è¡¨ç±»åˆ«é€‰æ‹©
            chart_category = st.selectbox(
                "å›¾è¡¨ç±»åˆ«",
                ["åŸºç¡€å›¾è¡¨", "é«˜çº§å›¾è¡¨", "ä¸“ä¸šæ²³æµå›¾"],
                index=0
            )
            
            # æ—¶é—´ç²’åº¦é€‰æ‹©
            time_granularity = st.selectbox(
                "æ—¶é—´ç²’åº¦",
                ["daily", "weekly", "monthly"],
                index=0,
                format_func=lambda x: {"daily": "æ—¥", "weekly": "å‘¨", "monthly": "æœˆ"}[x]
            )
            
            # æŒ‡æ ‡é€‰æ‹©
            available_metrics = ['views', 'shares', 'read_completion_rate', 'delivery_read_rate']
            metric = st.selectbox(
                "é€‰æ‹©æŒ‡æ ‡",
                available_metrics,
                index=0,
                format_func=lambda x: {
                    'views': 'é˜…è¯»äººæ•°',
                    'shares': 'åˆ†äº«äººæ•°', 
                    'read_completion_rate': 'é˜…è¯»å®Œæˆç‡',
                    'delivery_read_rate': 'é€è¾¾é˜…è¯»ç‡'
                }[x]
            )
            
            # é«˜çº§é€‰é¡¹
            if chart_category == "é«˜çº§å›¾è¡¨":
                st.header(f"é«˜çº§é€‰é¡¹")
                smoothing = st.checkbox("å¯ç”¨å¹³æ»‘æ›²çº¿", value=True)
            
            # æ²³æµå›¾ç±»å‹é€‰æ‹©
            if chart_category == "ä¸“ä¸šæ²³æµå›¾":
                st.header("ğŸŒŠ æ²³æµå›¾ç±»å‹")
                flow_type = st.selectbox(
                    "æ²³æµå›¾ç±»å‹",
                    ["stacked", "separate", "normalized"],
                    index=0,
                    format_func=lambda x: {
                        "stacked": "å †å æ²³æµå›¾",
                        "separate": "åˆ†ç¦»æ²³æµå›¾", 
                        "normalized": "æ ‡å‡†åŒ–æ²³æµå›¾"
                    }[x]
                )
        
        # å›¾è¡¨ç±»å‹é€‰æ‹©
        st.header(f"å¯è§†åŒ–å›¾è¡¨")
        
        # æ ¹æ®å›¾è¡¨ç±»åˆ«æ˜¾ç¤ºä¸åŒçš„é€‰é¡¹
        if chart_category == "åŸºç¡€å›¾è¡¨":
            chart_type = st.selectbox(
                "é€‰æ‹©å›¾è¡¨ç±»å‹",
                [
                    "é¢ç§¯å›¾ (Area Chart)",
                    "æµå›¾ (Stream Chart)", 
                    "å±±è„Šå›¾ (Ridge Plot)"
                ],
                index=0
            )
            
            # æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹æ˜¾ç¤ºç›¸åº”çš„å›¾è¡¨
            if chart_type == "é¢ç§¯å›¾ (Area Chart)":
                fig = create_area_chart(filtered_records, metric, time_granularity)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆé¢ç§¯å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "æµå›¾ (Stream Chart)":
                fig = create_stream_chart(filtered_records, metric, time_granularity)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆæµå›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "å±±è„Šå›¾ (Ridge Plot)":
                fig = create_ridge_plot(filtered_records, metric, time_granularity)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆå±±è„Šå›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        
        elif chart_category == "é«˜çº§å›¾è¡¨":
            chart_type = st.selectbox(
                "é€‰æ‹©å›¾è¡¨ç±»å‹",
                [
                    "é«˜çº§æµå›¾ (Advanced Stream Chart)",
                    "å¹³è¡Œç±»åˆ«å›¾ (Parallel Categories)",
                    "æ ‘çŠ¶å›¾ (Treemap)",
                    "å†°æŸ±å›¾ (Icicle Chart)"
                ],
                index=0
            )
            
            # æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹æ˜¾ç¤ºç›¸åº”çš„å›¾è¡¨
            if chart_type == "é«˜çº§æµå›¾ (Advanced Stream Chart)":
                fig = create_advanced_stream_chart(filtered_records, metric, time_granularity, smoothing)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆé«˜çº§æµå›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "å¹³è¡Œç±»åˆ«å›¾ (Parallel Categories)":
                fig = create_parallel_categories_diagram(filtered_records, metric)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆå¹³è¡Œç±»åˆ«å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "æ ‘çŠ¶å›¾ (Treemap)":
                fig = create_treemap_chart(filtered_records, metric)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆæ ‘çŠ¶å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "å†°æŸ±å›¾ (Icicle Chart)":
                fig = create_icicle_chart(filtered_records, metric)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆå†°æŸ±å›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        
        elif chart_category == "ä¸“ä¸šæ²³æµå›¾":
            chart_type = st.selectbox(
                "é€‰æ‹©å›¾è¡¨ç±»å‹",
                [
                    "æ²³æµå›¾ (River Flow Chart)",
                    "å±±è„Šæµå›¾ (Ridge Flow Chart)"
                ],
                index=0
            )
            
            # æ ¹æ®é€‰æ‹©çš„å›¾è¡¨ç±»å‹æ˜¾ç¤ºç›¸åº”çš„å›¾è¡¨
            if chart_type == "æ²³æµå›¾ (River Flow Chart)":
                fig = create_river_flow_chart(filtered_records, metric, time_granularity, flow_type)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆæ²³æµå›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
            
            elif chart_type == "å±±è„Šæµå›¾ (Ridge Flow Chart)":
                fig = create_ridge_flow_chart(filtered_records, metric, time_granularity)
                if fig:
                    st.plotly_chart(fig, use_container_width=True)
                else:
                    st.warning("æ— æ³•ç”Ÿæˆå±±è„Šæµå›¾ï¼Œè¯·æ£€æŸ¥æ•°æ®")
        
        # ä½¿ç”¨è¯´æ˜
        with st.expander(f"ä½¿ç”¨è¯´æ˜"):
            st.markdown("""
            ### å›¾è¡¨ç±»åˆ«è¯´æ˜
            
            #### åŸºç¡€å›¾è¡¨
            - **é¢ç§¯å›¾**: æ˜¾ç¤ºä¸åŒè´¦å·çš„æŒ‡æ ‡éšæ—¶é—´å˜åŒ–çš„è¶‹åŠ¿ï¼Œé€‚åˆè§‚å¯Ÿæ•´ä½“è¶‹åŠ¿
            - **æµå›¾**: ç±»ä¼¼é¢ç§¯å›¾ï¼Œä½†ä½¿ç”¨å¹³æ»‘æ›²çº¿ï¼Œè§†è§‰æ•ˆæœæ›´æŸ”å’Œ
            - **å±±è„Šå›¾**: æ¯ä¸ªè´¦å·ç‹¬ç«‹æ˜¾ç¤ºï¼Œé€‚åˆå¯¹æ¯”ä¸åŒè´¦å·çš„è¡¨ç°
            
            #### é«˜çº§å›¾è¡¨
            - **é«˜çº§æµå›¾**: ä½¿ç”¨å¹³æ»‘æ›²çº¿å’Œå †å æ˜¾ç¤ºï¼Œè§†è§‰æ•ˆæœæ›´ä½³
            - **å¹³è¡Œç±»åˆ«å›¾**: æ˜¾ç¤ºä¸åŒç»´åº¦ä¹‹é—´çš„å…³ç³»ï¼Œé€‚åˆåˆ†ææ•°æ®æµå‘
            - **æ ‘çŠ¶å›¾**: ç”¨çŸ©å½¢å¤§å°è¡¨ç¤ºæ•°å€¼ï¼Œé€‚åˆå¿«é€Ÿæ¯”è¾ƒ
            - **å†°æŸ±å›¾**: å±‚æ¬¡åŒ–æ˜¾ç¤ºæ•°æ®ï¼Œä½¿ç”¨çŸ©å½¢å¸ƒå±€
            
            #### ä¸“ä¸šæ²³æµå›¾
            - **æ²³æµå›¾**: ç»å…¸çš„æ²³æµå›¾ï¼Œæ”¯æŒå †å ã€åˆ†ç¦»ã€æ ‡å‡†åŒ–ä¸‰ç§æ¨¡å¼
            - **å±±è„Šæµå›¾**: æ¯ä¸ªè´¦å·ç‹¬ç«‹æ˜¾ç¤ºï¼Œé€‚åˆå¯¹æ¯”åˆ†æ
            
            ### æ“ä½œæç¤º
            
            1. ä½¿ç”¨ä¾§è¾¹æ é€‰æ‹©å›¾è¡¨ç±»åˆ«å’Œå…·ä½“ç±»å‹
            2. è°ƒæ•´æ—¶é—´ç²’åº¦ã€æŒ‡æ ‡å’Œè´¦å·ç­›é€‰
            3. å¯ä»¥è®¾ç½®æ—¶é—´èŒƒå›´æ¥èšç„¦ç‰¹å®šæ—¶æœŸçš„æ•°æ®
            4. ä¸åŒå›¾è¡¨ç±»å‹é€‚åˆä¸åŒçš„åˆ†æéœ€æ±‚
            5. é¼ æ ‡æ‚¬åœå¯ä»¥æŸ¥çœ‹è¯¦ç»†æ•°å€¼
            """)
    else:
        st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ·»åŠ å‘å¸ƒè®°å½•")