import sys
import os
import json
import datetime
import subprocess
from pathlib import Path
from concurrent.futures import ThreadPoolExecutor, as_completed
import time
import threading
import asyncio
from typing import AsyncIterator, Optional

# ä½¿ç”¨ç®€åŒ–è·¯å¾„ç®¡ç†
from simple_paths import *

import streamlit as st
from language_manager import init_language, get_text, get_language
# Using simple_paths for path management - get_static_dir, get_md_review_dir, get_json_data_dir are already imported
import requests
try:
    import httpx
except ImportError:
    httpx = None
    st.warning("âš ï¸ éœ€è¦å®‰è£… httpx ä»¥æ”¯æŒå¼‚æ­¥æµå¼è¾“å‡º: pip install httpx")
from core.utils.theme_loader import load_anthropic_theme
from core.utils.icon_library import get_icon

# å¤šè¯­è¨€æ–‡æœ¬å®šä¹‰
T = {
    "zh": {
        "page_title": "AI Content Creation and Transcription",
        "select_channel": "é€‰æ‹©é¢‘é“",
        "transcribe_btn": "AIè½¬å†™",
        "success": "è½¬å†™æˆåŠŸï¼",
        "md_preview": "Markdowné¢„è§ˆ",
        "md_newtab": "åœ¨æ–°æ ‡ç­¾é¡µä¸­æ‰“å¼€"
    },
    "en": {
        "page_title": "AI Content Creation and Transcription",
        "select_channel": "Select Channel",
        "transcribe_btn": "AI Transcribe",
        "success": "Transcription successful!",
        "md_preview": "Markdown Preview",
        "md_newtab": "Open in new tab"
    }
}

HISTORY_PATH = Path(get_json_data_dir()) / "md_transcribe_history.json"

def save_transcribe_history(channel, input_type, input_content, md_result, extra=None):
    record = {
        "id": datetime.datetime.now().strftime("%Y%m%d%H%M%S%f"),
        "channel": channel,
        "input_type": input_type,
        "input_content": input_content,
        "md_result": md_result,
        "created_at": datetime.datetime.now().isoformat(),
        "extra": extra or {}
    }
    if os.path.exists(HISTORY_PATH):
        with open(HISTORY_PATH, "r", encoding="utf-8") as f:
            history = json.load(f)
    else:
        history = []
    history.append(record)
    with open(HISTORY_PATH, "w", encoding="utf-8") as f:
        json.dump(history, f, ensure_ascii=False, indent=2)

# åˆå§‹åŒ–è¯­è¨€è®¾ç½®
init_language()

st.set_page_config(page_title="AI Transcription", layout="wide")

# åŠ è½½ä¸»é¢˜
load_anthropic_theme()

st.title("Creation and Transcription")

STATIC_DIR = get_static_dir()
# ä½¿ç”¨ç®€åŒ–è·¯å¾„ç®¡ç†
CHANNELS_PATH = os.path.join(CONFIG_DIR, "channels_v3.json")
ENDPOINTS_PATH = os.path.join(CONFIG_DIR, "llm_endpoints.json")
os.makedirs(STATIC_DIR, exist_ok=True)

# è¯»å–é¢‘é“
if os.path.exists(CHANNELS_PATH):
    try:
        with open(CHANNELS_PATH, "r", encoding="utf-8") as f:
            channels_data = json.load(f)
            channels = channels_data.get("channels", [])
    except json.JSONDecodeError as e:
        st.error(f"é¢‘é“é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}")
        channels = []
    except Exception as e:
        st.error(f"åŠ è½½é¢‘é“é…ç½®å¤±è´¥: {e}")
        channels = []
else:
    st.error(f"é¢‘é“é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {CHANNELS_PATH}")
    channels = []

# ç°åœ¨æ‰€æœ‰é¢‘é“éƒ½ä½¿ç”¨ç»Ÿä¸€çš„æ‰å¹³ç»“æ„
channel_names = [c.get("name", f'é¢‘é“ {idx}') for idx, c in enumerate(channels)] if channels else []
# é¢‘é“å’Œç«¯ç‚¹é€‰æ‹©åŒä¸€è¡Œï¼ˆæ”¹ä¸ºä¸‰åˆ—ï¼‰
sel_col1, sel_col2, sel_col3 = st.columns([1, 1, 1])

with sel_col1:
    selected_channel = st.selectbox(get_text("select_channel"), ["-"] + channel_names, key="channel_selector")

# è·å–é¢‘é“å¯¹è±¡ï¼ˆç°åœ¨ç»Ÿä¸€ä½¿ç”¨æ‰å¹³ç»“æ„ï¼‰
channel_obj = next((c for c in channels if c.get("name") == selected_channel), None)

# è¯»å–LLMç«¯ç‚¹
if os.path.exists(ENDPOINTS_PATH):
    with open(ENDPOINTS_PATH, "r", encoding="utf-8") as f:
        endpoints = json.load(f)
else:
    endpoints = []

endpoint_names = [ep["name"] for ep in endpoints] if endpoints else []

with sel_col2:
    # è”åŠ¨ï¼šé¢‘é“æŒ‡å®šç«¯ç‚¹ä¼˜å…ˆé€‰ä¸­
    if endpoint_names:
        if channel_obj and channel_obj.get("llm_endpoint") in endpoint_names:
            endpoint_index = endpoint_names.index(channel_obj["llm_endpoint"])
        else:
            endpoint_index = 0
        selected_endpoint = st.selectbox("é€‰æ‹©LLMç«¯ç‚¹", endpoint_names, index=endpoint_index, key="endpoint_selector")
    else:
        st.error(f"æ²¡æœ‰æ‰¾åˆ°å¯ç”¨çš„LLMç«¯ç‚¹")
        selected_endpoint = ""

with sel_col3:
    # å¹¶å‘ç«¯ç‚¹å¤šé€‰æ¡†
    if endpoint_names:
        # è·å–é¢‘é“ç»‘å®šçš„å¹¶å‘ç«¯ç‚¹åˆ—è¡¨
        default_concurrent_endpoints = []
        if channel_obj:
            concurrent_endpoints_config = channel_obj.get("concurrent_endpoints", [])
            # åªé€‰æ‹©åœ¨å½“å‰å¯ç”¨ç«¯ç‚¹åˆ—è¡¨ä¸­çš„ç«¯ç‚¹
            default_concurrent_endpoints = [ep for ep in concurrent_endpoints_config if ep in endpoint_names]
        
        selected_concurrent_endpoints = st.multiselect(
            "å¹¶å‘ç«¯ç‚¹ï¼ˆå¤šé€‰ï¼‰",
            endpoint_names,
            default=default_concurrent_endpoints,
            key="concurrent_endpoints_selector",
            help="é€‰æ‹©å¤šä¸ªç«¯ç‚¹è¿›è¡Œå¹¶å‘è½¬å†™"
        )

    else:
        selected_concurrent_endpoints = []

# ============================================================================
# å¹¶å‘å†å²ç®¡ç†å‡½æ•°
# ============================================================================

def get_concurrent_history_dir():
    """è·å–å¹¶å‘å†å²ç›®å½•"""
    history_dir = os.path.join(get_workspace_dir(), "concurrent_history")
    os.makedirs(history_dir, exist_ok=True)
    return history_dir


def save_concurrent_history(task_id, channel, results, saved_files):
    """
    ä¿å­˜å¹¶å‘è½¬å†™å†å²åˆ° JSON æ–‡ä»¶
    
    å‚æ•°:
        task_id: ä»»åŠ¡IDï¼ˆæ—¶é—´æˆ³ï¼‰
        channel: é¢‘é“åç§°
        results: ç»“æœå­—å…¸
        saved_files: ä¿å­˜çš„æ–‡ä»¶åˆ—è¡¨
    """
    history_dir = get_concurrent_history_dir()
    
    # æ„å»ºå…ƒæ•°æ®
    metadata = {
        "id": task_id,
        "channel": channel,
        "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        "results": []
    }
    
    # æ·»åŠ æ¯ä¸ªç«¯ç‚¹çš„ç»“æœä¿¡æ¯ï¼ˆåªä¿å­˜å¿…è¦ä¿¡æ¯ï¼Œä¸ä¿å­˜å†…å®¹ï¼‰
    for ep_name, result_data in results.items():
        result_info = {
            "endpoint": ep_name,
            "success": result_data["success"],
            "elapsed": result_data["elapsed"],
            "file_path": None  # åˆå§‹åŒ–ä¸º None
        }
        
        # å¦‚æœæˆåŠŸï¼Œæ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶è·¯å¾„
        if result_data["success"]:
            for saved_ep, saved_path in saved_files:
                if saved_ep == ep_name:
                    result_info["file_path"] = saved_path
                    break
        else:
            # å¤±è´¥æ—¶ä¿å­˜é”™è¯¯ä¿¡æ¯
            result_info["error"] = result_data["result"]
        
        metadata["results"].append(result_info)
    
    # ç»Ÿè®¡ä¿¡æ¯
    success_count = sum(1 for r in results.values() if r["success"])
    metadata["statistics"] = {
        "total": len(results),
        "success": success_count,
        "failed": len(results) - success_count,
        "avg_time": sum(r["elapsed"] for r in results.values()) / len(results) if results else 0
    }
    
    # ä¿å­˜åˆ° JSON æ–‡ä»¶
    json_path = os.path.join(history_dir, f"{task_id}_{channel.replace('/', '_').replace(' ', '_')}.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(metadata, f, ensure_ascii=False, indent=2)
    
    return json_path


def load_concurrent_history_list():
    """
    åŠ è½½å¹¶å‘å†å²è®°å½•åˆ—è¡¨
    
    è¿”å›:
        åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« (display_name, file_path, metadata)
    """
    history_dir = get_concurrent_history_dir()
    history_files = sorted(
        [f for f in os.listdir(history_dir) if f.endswith('.json')],
        reverse=True  # æœ€æ–°çš„åœ¨å‰
    )
    
    history_list = []
    for filename in history_files:
        file_path = os.path.join(history_dir, filename)
        try:
            with open(file_path, "r", encoding="utf-8") as f:
                metadata = json.load(f)
            
            # æ„å»ºæ˜¾ç¤ºåç§°
            timestamp = metadata.get("timestamp", "æœªçŸ¥æ—¶é—´")
            channel = metadata.get("channel", "æœªçŸ¥é¢‘é“")
            stats = metadata.get("statistics", {})
            total = stats.get("total", 0)
            success = stats.get("success", 0)
            
            display_name = f"{timestamp} | {channel} | {success}/{total} æˆåŠŸ"
            history_list.append((display_name, file_path, metadata))
        except Exception as e:
            # å¿½ç•¥æŸåçš„æ–‡ä»¶
            continue
    
    return history_list


def load_concurrent_history(file_path):
    """
    ä» JSON æ–‡ä»¶åŠ è½½å¹¶å‘å†å²
    
    è¿”å›:
        metadata å­—å…¸
    """
    with open(file_path, "r", encoding="utf-8") as f:
        return json.load(f)

# ============================================================================
# è¾“å…¥åŒº
# ============================================================================

# è¾“å…¥åŒºå †å 
md_input = st.text_area("Markdown", height=200, key="md_input_1_Creation")
text_input = st.text_area("Text", height=100, key="text_input_1_Creation")
link_input = st.text_area("Link", height=60, key="link_input_1_Creation")

# AIè½¬å†™æŒ‰é’® - ç¾åŒ–æ ·å¼
st.markdown("""
<style>
    /* è½¬å†™æŒ‰é’®åŒºåŸŸæ ·å¼ */
    .transcribe-section {
        margin: 30px 0 20px 0;
        padding: 20px;
        background: linear-gradient(135deg, #FAFAF8 0%, #F5F1E8 100%);
        border-radius: 16px;
        border: 1px solid rgba(0, 0, 0, 0.06);
    }
    
    /* è‡ªå®šä¹‰è½¬å†™æŒ‰é’®æ ·å¼ - ä½¿ç”¨æ›´å¼ºçš„é€‰æ‹©å™¨ */
    div[data-testid="stButton"] > button[kind="primary"],
    button[data-testid="stBaseButton-primary"] {
        background: linear-gradient(135deg, #E8957B 0%, #D97A5E 100%) !important;
        color: white !important;
        border: none !important;
        border-radius: 12px !important;
        padding: 24px 56px !important;
        font-size: 18px !important;
        font-weight: 600 !important;
        letter-spacing: 0.5px !important;
        box-shadow: 0 4px 12px rgba(233, 149, 123, 0.3) !important;
        transition: all 0.3s cubic-bezier(0.4, 0, 0.2, 1) !important;
        width: 100% !important;
        height: auto !important;
        cursor: pointer !important;
        position: relative !important;
        overflow: hidden !important;
        min-height: 60px !important;
        max-height: none !important;
    }
    
    /* ç¡®ä¿æŒ‰é’®å†…éƒ¨çš„å†…å®¹ä¹Ÿç»Ÿä¸€ */
    button[data-testid="stBaseButton-primary"] div[data-testid="stMarkdownContainer"],
    button[data-testid="stBaseButton-primary"] div[data-testid="stMarkdownContainer"] p {
        margin: 0 !important;
        padding: 0 !important;
        line-height: 1 !important;
    }
    
    div[data-testid="stButton"] > button[kind="primary"]:hover,
    button[data-testid="stBaseButton-primary"]:hover {
        transform: translateY(-3px) !important;
        box-shadow: 0 8px 24px rgba(233, 149, 123, 0.45) !important;
        background: linear-gradient(135deg, #D97A5E 0%, #C86A4E 100%) !important;
    }
    
    div[data-testid="stButton"] > button[kind="primary"]:active,
    button[data-testid="stBaseButton-primary"]:active {
        transform: translateY(-1px) !important;
        box-shadow: 0 2px 8px rgba(233, 149, 123, 0.35) !important;
    }
    
    /* æŒ‰é’®å›¾æ ‡æ ·å¼ */
    div[data-testid="stButton"] > button[kind="primary"] svg,
    button[data-testid="stBaseButton-primary"] svg {
        vertical-align: middle !important;
        margin-right: 8px !important;
        filter: drop-shadow(0 2px 4px rgba(0, 0, 0, 0.1)) !important;
    }
    
    /* ç¦ç”¨çŠ¶æ€æ ·å¼ - ä¿æŒç›¸åŒçš„å°ºå¯¸ */
    div[data-testid="stButton"] > button[kind="primary"]:disabled,
    button[data-testid="stBaseButton-primary"]:disabled {
        background: linear-gradient(135deg, #D4C5B0 0%, #C4B19D 100%) !important;
        cursor: not-allowed !important;
        opacity: 0.65 !important;
        transform: none !important;
        /* ç¡®ä¿ç¦ç”¨çŠ¶æ€ä¸‹å°ºå¯¸ä¸å˜ */
        padding: 24px 56px !important;
        min-height: 60px !important;
        max-height: none !important;
        height: auto !important;
        font-size: 18px !important;
        font-weight: 600 !important;
    }
</style>
""", unsafe_allow_html=True)

# åˆ›å»ºæŒ‰é’®å®¹å™¨ï¼ˆä¸¤ä¸ªæŒ‰é’®å¹¶æ’ï¼‰
col_left, col_btn1, col_btn2, col_right = st.columns([1, 1.2, 1.2, 1])

with col_btn1:
    # æ™®é€šAIè½¬å†™æŒ‰é’®
    button_label = "AIè½¬å†™"
    transcribe_clicked = st.button(button_label, key="transcribe_main_button", type="primary", use_container_width=True)

with col_btn2:
    # å¹¶å‘è½¬å†™æŒ‰é’®
    concurrent_transcribe_clicked = st.button(
        "å¹¶å‘è½¬å†™", 
        key="concurrent_transcribe_button", 
        type="primary", 
        use_container_width=True,
        disabled=(not selected_concurrent_endpoints),  # å¦‚æœæ²¡æœ‰é€‰æ‹©å¹¶å‘ç«¯ç‚¹åˆ™ç¦ç”¨
        help="ä½¿ç”¨å¤šä¸ªç«¯ç‚¹åŒæ—¶è¿›è¡Œè½¬å†™" if selected_concurrent_endpoints else "è¯·å…ˆåœ¨å³ä¾§é€‰æ‹©å¹¶å‘ç«¯ç‚¹"
    )

# æŒ‰é’®ä¸‹æ–¹æ·»åŠ ç•™ç™½
st.markdown("<br>", unsafe_allow_html=True)

# ============================================================================
# æ ¸å¿ƒæŠ½è±¡å‡½æ•°ï¼šç»Ÿä¸€çš„ LLM ç«¯ç‚¹è°ƒç”¨
# ============================================================================

async def call_single_llm_endpoint_stream(endpoint_config, prompt, timeout=180, stream_container=None):
    """
    å¼‚æ­¥æµå¼ LLM ç«¯ç‚¹è°ƒç”¨å‡½æ•°
    
    å‚æ•°:
        endpoint_config: ç«¯ç‚¹é…ç½®å­—å…¸
        prompt: æç¤ºè¯å†…å®¹
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        stream_container: Streamlit å®¹å™¨å¯¹è±¡ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºæµå¼è¾“å‡ºï¼ˆå¯é€‰ï¼‰
    
    è¿”å›:
        (success: bool, result: str, elapsed_time: float)
        - success: æ˜¯å¦æˆåŠŸ
        - result: æˆåŠŸæ—¶è¿”å› markdown å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯ä¿¡æ¯
        - elapsed_time: è¯·æ±‚è€—æ—¶ï¼ˆç§’ï¼‰
    """
    if httpx is None:
        raise ImportError("éœ€è¦å®‰è£… httpx: pip install httpx")
    
    start_time = time.time()
    full_result = ""
    
    try:
        api_type = endpoint_config.get("api_type", "")
        api_url = endpoint_config.get("api_url", "").strip()
        api_key = endpoint_config.get("api_key", "")
        model = endpoint_config.get("model", "")
        is_openai = endpoint_config.get("is_openai_compatible", False)
        temperature = endpoint_config.get("temperature", 0.7)
        
        # æ„å»ºè¯·æ±‚å‚æ•°
        if is_openai:
            headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature,
                "stream": True  # å¯ç”¨æµå¼è¾“å‡º
            }
            api_type_flag = "openai"
            
        elif api_type == "Magic":
            # Magic API æ”¯æŒä¸¤ç§æ ¼å¼
            if "api/chat" in api_url:
                # æ–°ç‰ˆæœ¬ Magic APIï¼ˆä¸æ”¯æŒæµå¼ï¼Œéœ€è¦å›é€€åˆ°åŒæ­¥æ¨¡å¼ï¼‰
                elapsed = time.time() - start_time
                raise ValueError("æ–°ç‰ˆæœ¬ Magic API ä¸æ”¯æŒæµå¼è¾“å‡ºï¼Œè¯·ä½¿ç”¨åŒæ­¥æ¨¡å¼")
            else:
                # æ—§ç‰ˆæœ¬ Magic API (OpenAI å…¼å®¹)
                headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                data = {
                    "model": model if model else "magic-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå†™ä½œåŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "stream": True,  # å¯ç”¨æµå¼è¾“å‡º
                    "max_tokens": 4000
                }
                api_type_flag = "magic_openai"
        else:
            elapsed = time.time() - start_time
            return (False, f"ä¸æ”¯æŒçš„ API ç±»å‹: {api_type}", elapsed)
        
        # ä½¿ç”¨ httpx è¿›è¡Œå¼‚æ­¥æµå¼è¯·æ±‚
        async with httpx.AsyncClient(timeout=timeout) as client:
            async with client.stream("POST", api_url, headers=headers, json=data) as response:
                if response.status_code != 200:
                    error_text = await response.aread()
                    elapsed = time.time() - start_time
                    return (False, f"HTTP {response.status_code}: {error_text[:200].decode('utf-8', errors='ignore')}", elapsed)
                
                # å¤„ç†æµå¼å“åº”
                buffer = ""
                async for chunk in response.aiter_bytes():
                    if chunk:
                        buffer += chunk.decode('utf-8', errors='ignore')
                        
                        # å¤„ç† SSE æ ¼å¼çš„æ•°æ®ï¼ˆæ¯è¡Œä¸€ä¸ª JSON å¯¹è±¡ï¼‰
                        lines = buffer.split('\n')
                        buffer = lines[-1]  # ä¿ç•™æœ€åä¸å®Œæ•´çš„è¡Œ
                        
                        for line in lines[:-1]:
                            line = line.strip()
                            if not line or line.startswith(':'):
                                continue
                            
                            # å¤„ç† data: å‰ç¼€
                            if line.startswith('data: '):
                                line = line[6:]
                            
                            if line == '[DONE]':
                                continue
                            
                            try:
                                json_data = json.loads(line)
                                
                                # è§£æ OpenAI æ ¼å¼
                                if "choices" in json_data and len(json_data["choices"]) > 0:
                                    delta = json_data["choices"][0].get("delta", {})
                                    content = delta.get("content", "")
                                    if content:
                                        full_result += content
                                        if stream_container:
                                            # å®æ—¶æ›´æ–°æµå¼è¾“å‡º
                                            stream_container.markdown(full_result)
                                            # ä½¿ç”¨å¼‚æ­¥å»¶è¿Ÿä»¥ç¡®ä¿ UI æ›´æ–°
                                            await asyncio.sleep(0.01)
                                
                                # è§£æ Magic API æ ¼å¼ï¼ˆå¦‚æœæ”¯æŒæµå¼ï¼‰
                                elif "data" in json_data:
                                    # Magic API æµå¼æ ¼å¼å¯èƒ½ä¸åŒï¼Œéœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´
                                    pass
                                    
                            except json.JSONDecodeError:
                                continue
        
        elapsed = time.time() - start_time
        return (True, full_result, elapsed)
    
    except httpx.TimeoutException:
        elapsed = time.time() - start_time
        return (False, f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰", elapsed)
    except httpx.ConnectError:
        elapsed = time.time() - start_time
        return (False, "è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API åœ°å€", elapsed)
    except httpx.RequestError as e:
        elapsed = time.time() - start_time
        return (False, f"è¯·æ±‚å¼‚å¸¸: {str(e)}", elapsed)
    except Exception as e:
        elapsed = time.time() - start_time
        return (False, f"æœªçŸ¥é”™è¯¯: {str(e)}", elapsed)


def call_single_llm_endpoint(endpoint_config, prompt, timeout=180, use_stream=False, stream_container=None):
    """
    ç»Ÿä¸€çš„ LLM ç«¯ç‚¹è°ƒç”¨å‡½æ•°ï¼ˆæ”¯æŒåŒæ­¥å’Œå¼‚æ­¥æµå¼ä¸¤ç§æ¨¡å¼ï¼‰
    
    å‚æ•°:
        endpoint_config: ç«¯ç‚¹é…ç½®å­—å…¸
        prompt: æç¤ºè¯å†…å®¹
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡ºï¼ˆé»˜è®¤ Falseï¼Œä¿æŒå‘åå…¼å®¹ï¼‰
        stream_container: Streamlit å®¹å™¨å¯¹è±¡ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºæµå¼è¾“å‡ºï¼ˆä»…å½“ use_stream=True æ—¶æœ‰æ•ˆï¼‰
    
    è¿”å›:
        (success: bool, result: str, elapsed_time: float)
        - success: æ˜¯å¦æˆåŠŸ
        - result: æˆåŠŸæ—¶è¿”å› markdown å†…å®¹ï¼Œå¤±è´¥æ—¶è¿”å›é”™è¯¯ä¿¡æ¯
        - elapsed_time: è¯·æ±‚è€—æ—¶ï¼ˆç§’ï¼‰
    """
    if use_stream and httpx is not None:
        # ä½¿ç”¨å¼‚æ­¥æµå¼æ¨¡å¼
        try:
            # åœ¨ Streamlit ä¸­è¿è¡Œå¼‚æ­¥å‡½æ•°
            # å°è¯•è·å–ç°æœ‰äº‹ä»¶å¾ªç¯ï¼Œå¦‚æœæ²¡æœ‰åˆ™åˆ›å»ºæ–°çš„
            try:
                loop = asyncio.get_event_loop()
                if loop.is_closed():
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
            except RuntimeError:
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
            
            # è¿è¡Œå¼‚æ­¥å‡½æ•°
            result = loop.run_until_complete(
                call_single_llm_endpoint_stream(endpoint_config, prompt, timeout, stream_container)
            )
            return result
        except Exception as e:
            # å¦‚æœå¼‚æ­¥æ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼
            st.warning(f"æµå¼è¾“å‡ºå¤±è´¥ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼: {str(e)}")
    
    # åŒæ­¥æ¨¡å¼ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
    start_time = time.time()
    
    try:
        api_type = endpoint_config.get("api_type", "")
        api_url = endpoint_config.get("api_url", "").strip()
        api_key = endpoint_config.get("api_key", "")
        model = endpoint_config.get("model", "")
        is_openai = endpoint_config.get("is_openai_compatible", False)
        temperature = endpoint_config.get("temperature", 0.7)
        
        # æ ¹æ® API ç±»å‹æ„å»ºè¯·æ±‚
        if is_openai:
            headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
            data = {
                "model": model,
                "messages": [{"role": "user", "content": prompt}],
                "temperature": temperature
            }
            resp = requests.post(api_url, headers=headers, json=data, timeout=timeout)
            
        elif api_type == "Magic":
            # Magic API æ”¯æŒä¸¤ç§æ ¼å¼
            if "api/chat" in api_url:
                # æ–°ç‰ˆæœ¬ Magic API
                headers = {"api-key": api_key, "Content-Type": "application/json"}
                data = {
                    "message": prompt,
                    "conversation_id": "",
                    "model": model if model else "magic-chat"
                }
            else:
                # æ—§ç‰ˆæœ¬ Magic API (OpenAI å…¼å®¹)
                headers = {"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"}
                data = {
                    "model": model if model else "magic-chat",
                    "messages": [
                        {"role": "system", "content": "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIå†™ä½œåŠ©æ‰‹ã€‚"},
                        {"role": "user", "content": prompt}
                    ],
                    "temperature": temperature,
                    "stream": False,
                    "max_tokens": 4000
                }
            resp = requests.post(api_url, headers=headers, json=data, timeout=timeout)
        else:
            elapsed = time.time() - start_time
            return (False, f"ä¸æ”¯æŒçš„ API ç±»å‹: {api_type}", elapsed)
        
        elapsed = time.time() - start_time
        
        # è§£æå“åº”
        if resp.status_code == 200:
            try:
                result = resp.json()
                # å°è¯•è§£æ Magic API æ ¼å¼
                if "data" in result and "messages" in result["data"] and result["data"]["messages"]:
                    md_result = result["data"]["messages"][0]["message"]["content"]
                # å°è¯•è§£æ OpenAI æ ¼å¼
                else:
                    md_result = result["choices"][0]["message"]["content"]
                return (True, md_result, elapsed)
            except Exception as e:
                return (False, f"è§£æå“åº”å¤±è´¥: {str(e)}\nå“åº”å†…å®¹: {resp.text[:200]}", elapsed)
        else:
            return (False, f"HTTP {resp.status_code}: {resp.text[:200]}", elapsed)
    
    except requests.exceptions.Timeout:
        elapsed = time.time() - start_time
        return (False, f"è¯·æ±‚è¶…æ—¶ï¼ˆ{timeout}ç§’ï¼‰", elapsed)
    except requests.exceptions.ConnectionError:
        elapsed = time.time() - start_time
        return (False, "è¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œæˆ– API åœ°å€", elapsed)
    except requests.exceptions.RequestException as e:
        elapsed = time.time() - start_time
        return (False, f"è¯·æ±‚å¼‚å¸¸: {str(e)}", elapsed)
    except Exception as e:
        elapsed = time.time() - start_time
        return (False, f"æœªçŸ¥é”™è¯¯: {str(e)}", elapsed)


def extract_input_content(md_input, text_input, link_input):
    """
    ä»è¾“å…¥æ¡†æå–å’Œæ•´åˆå†…å®¹
    
    å‚æ•°:
        md_input: Markdown è¾“å…¥
        text_input: æ–‡æœ¬è¾“å…¥
        link_input: é“¾æ¥è¾“å…¥
    
    è¿”å›:
        æ•´åˆåçš„è¾“å…¥å†…å®¹å­—ç¬¦ä¸²
    """
    input_parts = []
    if md_input.strip():
        input_parts.append(f"é‡‡é›†åˆ°çš„æ–‡ç« :{md_input.strip()}\n")
    if text_input.strip():
        input_parts.append(f"ç”¨æˆ·çš„æƒ³æ³•æˆ–çµæ„Ÿ:{text_input.strip()}\n")
    if link_input.strip():
        try:
            from gzh_url2md import fetch_and_convert_to_md
            md_content = fetch_and_convert_to_md(link_input.strip())
            if md_content:
                input_parts.append(f"åŸæ–‡é“¾æ¥[Link]\n{link_input.strip()}\n\nè§£æåçš„Markdownå†…å®¹:\n{md_content}")
            else:
                input_parts.append(f"åŸæ–‡é“¾æ¥[Link]\n{link_input.strip()}\n\nè§£æå¤±è´¥ï¼Œè¯·æ£€æŸ¥é“¾æ¥æ˜¯å¦æ­£ç¡®")
        except Exception as e:
            input_parts.append(f"åŸæ–‡é“¾æ¥[Link]\n{link_input.strip()}\n\nè§£æç½‘é¡µå†…å®¹æ—¶å‡ºé”™: {str(e)}")
    return "\n\n".join(input_parts)


def build_full_prompt(channel_obj, selected_channel, input_content):
    """
    æ„å»ºå®Œæ•´çš„æç¤ºè¯
    
    å‚æ•°:
        channel_obj: é¢‘é“å¯¹è±¡
        selected_channel: é€‰ä¸­çš„é¢‘é“åç§°
        input_content: è¾“å…¥å†…å®¹
    
    è¿”å›:
        å®Œæ•´çš„æç¤ºè¯å­—ç¬¦ä¸²
    """
    prompt_parts = [f"# é¢‘é“ä¿¡æ¯\né¢‘é“ï¼š{selected_channel}"]
    
    # æ·»åŠ é¢‘é“æè¿°
    channel_description = channel_obj.get("description", "") if channel_obj else ""
    if channel_description:
        prompt_parts.append(f"# é¢‘é“æè¿°\n{channel_description}")
    
    # æ·»åŠ å½“å‰æ—¶é—´
    current_time = datetime.datetime.now().strftime("%Yå¹´%mæœˆ%dæ—¥ %H:%M")
    prompt_parts.append(f"# å½“å‰æ—¶é—´\nç°åœ¨æ˜¯ï¼š{current_time}")
    
    # æ·»åŠ å†…å®¹è§„åˆ™
    if channel_obj:
        content_rules = channel_obj.get("content_rules", {})
        if content_rules:
            prompt_parts.append("# å†…å®¹è§„èŒƒè¦æ±‚")
            
            # ç›®æ ‡å—ä¼—
            target_audience = content_rules.get("target_audience", "")
            if target_audience:
                prompt_parts.append(f"**ç›®æ ‡å—ä¼—:** {target_audience}")
            
            # å†™ä½œé£æ ¼
            writing_style = content_rules.get("writing_style", {})
            if writing_style:
                prompt_parts.append("**å†™ä½œé£æ ¼è¦æ±‚:**")
                if writing_style.get("title"):
                    prompt_parts.append(f"- æ ‡é¢˜é£æ ¼: {writing_style['title']}")
                if writing_style.get("tone"):
                    prompt_parts.append(f"- å†™ä½œè¯­æ°”: {writing_style['tone']}")
                if writing_style.get("depth"):
                    prompt_parts.append(f"- å†…å®¹æ·±åº¦: {writing_style['depth']}")
            
            # æŠ€æœ¯è§„åˆ™
            technical_rules = content_rules.get("technical_rules", [])
            if technical_rules:
                prompt_parts.append("**æŠ€æœ¯è¦æ±‚:**")
                for rule in technical_rules:
                    prompt_parts.append(f"- {rule}")
    
    # æ·»åŠ å¤„ç†å†…å®¹
    prompt_parts.append(f"# å¤„ç†å†…å®¹\n{input_content}")
    
    return "\n\n".join(prompt_parts)

# ============================================================================
# æ™®é€šè½¬å†™é€»è¾‘ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
# ============================================================================

if transcribe_clicked:
    if not (md_input.strip() or text_input.strip() or link_input.strip()):
        st.warning("è¯·è‡³å°‘è¾“å…¥ä¸€é¡¹å†…å®¹ï¼" if get_language()=="zh" else "Please input at least one field!")
    else:
        # æå–è¾“å…¥å†…å®¹ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
        input_content = extract_input_content(md_input, text_input, link_input)
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
        full_prompt = build_full_prompt(channel_obj, selected_channel, input_content)
        
        # è¯»å–ç«¯ç‚¹é…ç½®
        ep = next((e for e in endpoints if e["name"] == selected_endpoint), None)
        if not ep:
            st.error("æœªæ‰¾åˆ°æ‰€é€‰LLMç«¯ç‚¹é…ç½®ï¼")
        else:
            # åˆ›å»ºæµå¼è¾“å‡ºå®¹å™¨
            stream_container = st.empty()
            stream_container.info(f"ğŸ”„ æ­£åœ¨è¿æ¥ {selected_endpoint}...")
            
            # è°ƒç”¨ç»Ÿä¸€çš„ç«¯ç‚¹å‡½æ•°ï¼ˆå¯ç”¨æµå¼è¾“å‡ºï¼‰
            success, result, elapsed = call_single_llm_endpoint(
                ep, full_prompt, timeout=180, 
                use_stream=True, 
                stream_container=stream_container
            )
            
            # æ¸…ç†æµå¼è¾“å‡ºå®¹å™¨
            stream_container.empty()
            
            if success:
                # è½¬å†™æˆåŠŸ
                md_result = result
                st.session_state["ai_md_result"] = md_result
                md_path = os.path.join(STATIC_DIR, "preview.md")
                with open(md_path, "w", encoding="utf-8") as f:
                    f.write(md_result)
                
                # ä¿å­˜å†å²
                save_transcribe_history(selected_channel, "single", input_content, md_result, 
                                      extra={"endpoint": selected_endpoint, "elapsed": elapsed})
                
                # ä¿å­˜åˆ°æœ¬åœ°md_reviewç›®å½•
                from datetime import datetime
                safe_channel = selected_channel.replace("/", "_").replace(" ", "_")
                ts = datetime.now().strftime("%Y%m%d_%H%M%S")
                md_review_dir = get_md_review_dir()
                os.makedirs(md_review_dir, exist_ok=True)
                safe_endpoint = selected_endpoint.replace("/", "_").replace(" ", "_").replace(":", "_")
                local_md_path = os.path.join(md_review_dir, f"{ts}_{safe_channel}_{safe_endpoint}.md")
                with open(local_md_path, "w", encoding="utf-8") as f:
                    f.write(md_result)
                
                # ç”¨Typoraæ‰“å¼€
                try:
                    subprocess.Popen(["open", "-a", "Typora", local_md_path])
                except Exception as e:
                    st.info(f"æ— æ³•è‡ªåŠ¨æ‰“å¼€Typora: {e}")
                
                st.success(get_text("success"))
                
                # è‡ªåŠ¨åˆ‡æ¢åˆ°æ–°ç”Ÿæˆçš„æ–‡ç« é¢„è§ˆ
                # æ–‡ä»¶ååº”è¯¥æ˜¯ {ts}_{safe_channel}_{safe_endpoint}.md
                new_article_name = f"{ts}_{safe_channel}_{safe_endpoint}.md"
                st.session_state["current_md_file"] = new_article_name
                st.session_state["current_md_path"] = local_md_path
                st.session_state["auto_select_triggered"] = True  # æ ‡è®°å·²è§¦å‘è‡ªåŠ¨é€‰æ‹©
                
                # æ˜¾ç¤ºæˆåŠŸä¿¡æ¯å’Œé¢„è§ˆæç¤º
                st.success(f"âœ… è½¬å†™æˆåŠŸï¼æ–‡ç« å·²ä¿å­˜ä¸º: {new_article_name}")
                st.info(f"â±ï¸ è€—æ—¶: {elapsed:.2f}ç§’")
                
                # å»¶è¿Ÿä¸€ä¸‹å†åˆ·æ–°ï¼Œç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
                time.sleep(0.5)
                st.rerun()
            else:
                # è½¬å†™å¤±è´¥
                st.error(f"âŒ AIè½¬å†™å¤±è´¥\n\n**é”™è¯¯ä¿¡æ¯:** {result}\n\n**ç«¯ç‚¹:** {selected_endpoint}\n**è€—æ—¶:** {elapsed:.2f}ç§’")

# ============================================================================
# å¹¶å‘è½¬å†™åŒ…è£…å™¨å‡½æ•°
# ============================================================================

async def concurrent_call_wrapper_async(endpoint_name, endpoint_config, prompt, timeout=180, stream_container=None):
    """
    å¼‚æ­¥å¹¶å‘è°ƒç”¨çš„åŒ…è£…å™¨å‡½æ•°
    ç›´æ¥è°ƒç”¨å¼‚æ­¥æµå¼å‡½æ•°ï¼Œè¿”å›å¸¦ç«¯ç‚¹åç§°çš„ç»“æœ
    
    å‚æ•°:
        endpoint_name: ç«¯ç‚¹åç§°
        endpoint_config: ç«¯ç‚¹é…ç½®å­—å…¸
        prompt: æç¤ºè¯å†…å®¹
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        stream_container: Streamlit å®¹å™¨å¯¹è±¡ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºæµå¼è¾“å‡º
    
    è¿”å›:
        (endpoint_name, success, result, elapsed_time)
    """
    if httpx is None:
        # å¦‚æœ httpx ä¸å¯ç”¨ï¼Œå›é€€åˆ°åŒæ­¥æ¨¡å¼
        success, result, elapsed = call_single_llm_endpoint(endpoint_config, prompt, timeout, use_stream=False)
    else:
        success, result, elapsed = await call_single_llm_endpoint_stream(
            endpoint_config, prompt, timeout, stream_container
        )
    return (endpoint_name, success, result, elapsed)


def concurrent_call_wrapper(endpoint_name, endpoint_config, prompt, timeout=180, use_stream=False, stream_container=None):
    """
    å¹¶å‘è°ƒç”¨çš„åŒ…è£…å™¨å‡½æ•°ï¼ˆåŒæ­¥ç‰ˆæœ¬ï¼Œç”¨äºçº¿ç¨‹æ± ï¼‰
    è°ƒç”¨æ ¸å¿ƒçš„ call_single_llm_endpoint å‡½æ•°ï¼Œå¹¶è¿”å›å¸¦ç«¯ç‚¹åç§°çš„ç»“æœ
    
    å‚æ•°:
        endpoint_name: ç«¯ç‚¹åç§°
        endpoint_config: ç«¯ç‚¹é…ç½®å­—å…¸
        prompt: æç¤ºè¯å†…å®¹
        timeout: è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
        use_stream: æ˜¯å¦ä½¿ç”¨æµå¼è¾“å‡º
        stream_container: Streamlit å®¹å™¨å¯¹è±¡ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºæµå¼è¾“å‡º
    
    è¿”å›:
        (endpoint_name, success, result, elapsed_time)
    """
    success, result, elapsed = call_single_llm_endpoint(
        endpoint_config, prompt, timeout, 
        use_stream=use_stream, 
        stream_container=stream_container
    )
    return (endpoint_name, success, result, elapsed)

# ============================================================================
# å¹¶å‘è½¬å†™é€»è¾‘ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
# ============================================================================

if concurrent_transcribe_clicked:
    if not (md_input.strip() or text_input.strip() or link_input.strip()):
        st.warning("è¯·è‡³å°‘è¾“å…¥ä¸€é¡¹å†…å®¹ï¼" if get_language()=="zh" else "Please input at least one field!")
    elif not selected_concurrent_endpoints:
        st.error("è¯·å…ˆé€‰æ‹©å¹¶å‘ç«¯ç‚¹ï¼")
    else:
        st.markdown("### âš¡ å¹¶å‘è½¬å†™è¿›è¡Œä¸­...")
        
        # æå–è¾“å…¥å†…å®¹ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
        input_content = extract_input_content(md_input, text_input, link_input)
        
        # æ„å»ºå®Œæ•´çš„æç¤ºè¯ï¼ˆä½¿ç”¨æŠ½è±¡å‡½æ•°ï¼‰
        full_prompt = build_full_prompt(channel_obj, selected_channel, input_content)
        
        # å‡†å¤‡ç«¯ç‚¹é…ç½®
        endpoint_configs = {}
        for ep_name in selected_concurrent_endpoints:
            ep = next((e for e in endpoints if e["name"] == ep_name), None)
            if ep:
                endpoint_configs[ep_name] = ep
        
        if not endpoint_configs:
            st.error("æœªæ‰¾åˆ°ä»»ä½•æœ‰æ•ˆçš„ç«¯ç‚¹é…ç½®ï¼")
        else:
            # æ˜¾ç¤ºå¹¶å‘ä¿¡æ¯
            st.info(f"ğŸš€ æ­£åœ¨å¹¶å‘è°ƒç”¨ {len(endpoint_configs)} ä¸ªç«¯ç‚¹...")
            
            # åˆ›å»ºè¿›åº¦æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            
            # ä¸ºæ¯ä¸ªç«¯ç‚¹åˆ›å»ºç‹¬ç«‹çš„æµå¼è¾“å‡ºå®¹å™¨
            stream_containers = {}
            for ep_name in endpoint_configs.keys():
                stream_containers[ep_name] = st.empty()
                stream_containers[ep_name].info(f"ğŸ”„ æ­£åœ¨è¿æ¥ {ep_name}...")
            
            # åˆ›å»ºç»“æœå®¹å™¨
            results = {}
            saved_files = []
            # ä½¿ç”¨å­—å…¸å­˜å‚¨è®¡æ•°å™¨ï¼Œé¿å… nonlocal ä½œç”¨åŸŸé—®é¢˜
            counters = {
                "completed_count": 0,
                "success_count": 0,
                "failed_count": 0
            }
            
            # å‡†å¤‡ä¿å­˜ç›®å½•å’ŒåŸºç¡€æ—¶é—´æˆ³
            base_ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
            safe_channel = selected_channel.replace("/", "_").replace(" ", "_")
            md_review_dir = get_md_review_dir()
            os.makedirs(md_review_dir, exist_ok=True)
            
            # ä½¿ç”¨ asyncio æ‰§è¡Œå¹¶å‘å¼‚æ­¥è¯·æ±‚ï¼ˆæ›´é€‚åˆæµå¼è¾“å‡ºï¼‰
            async def run_concurrent_transcribe():
                """å¼‚æ­¥æ‰§è¡Œå¹¶å‘è½¬å†™"""
                # åˆ›å»ºæ‰€æœ‰å¼‚æ­¥ä»»åŠ¡
                tasks = [
                    concurrent_call_wrapper_async(
                        ep_name,
                        ep_config,
                        full_prompt,
                        180,  # timeout
                        stream_containers[ep_name]  # stream_container
                    )
                    for ep_name, ep_config in endpoint_configs.items()
                ]
                
                # ä½¿ç”¨ asyncio.as_completed æ¥å®æ—¶å¤„ç†å®Œæˆçš„ä»»åŠ¡
                completed_tasks = []
                for coro in asyncio.as_completed(tasks):
                    try:
                        result = await coro
                        completed_tasks.append(result)
                        
                        endpoint_name, success, result_text, elapsed = result
                        results[endpoint_name] = {
                            "success": success,
                            "result": result_text,
                            "elapsed": elapsed
                        }
                        
                        # æ¸…ç†è¯¥ç«¯ç‚¹çš„æµå¼è¾“å‡ºå®¹å™¨
                        if endpoint_name in stream_containers:
                            stream_containers[endpoint_name].empty()
                        
                        counters["completed_count"] = len(completed_tasks)
                        
                        # å¦‚æœæˆåŠŸï¼Œç«‹å³ä¿å­˜å¹¶æ‰“å¼€æ–‡ä»¶
                        if success:
                            counters["success_count"] += 1
                            # ä¸ºæ¯ä¸ªç«¯ç‚¹æ·»åŠ åºå·ï¼Œé¿å…æ—¶é—´æˆ³å†²çª
                            ts = f"{base_ts}_{counters['completed_count']}"
                            safe_endpoint = endpoint_name.replace("/", "_").replace(" ", "_").replace(":", "_")
                            local_md_path = os.path.join(md_review_dir, f"{ts}_{safe_channel}_{safe_endpoint}.md")
                            
                            # ä¿å­˜æ–‡ä»¶
                            with open(local_md_path, "w", encoding="utf-8") as f:
                                f.write(result_text)
                            
                            # ä¿å­˜å†å²
                            save_transcribe_history(selected_channel, "concurrent", input_content, result_text, 
                                                   extra={"endpoint": endpoint_name, "elapsed": elapsed})
                            
                            # ç«‹å³æ‰“å¼€æ–‡ä»¶ï¼Œä¸ç­‰å¾…å…¶ä»–ç«¯ç‚¹
                            try:
                                subprocess.Popen(["open", local_md_path])
                                status_text.text(f"âœ… {endpoint_name} å®Œæˆå¹¶å·²æ‰“å¼€ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                            except Exception as e:
                                status_text.text(f"âœ… {endpoint_name} å®Œæˆ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                            
                            saved_files.append((endpoint_name, local_md_path))
                        else:
                            counters["failed_count"] += 1
                            status_text.text(f"âŒ {endpoint_name} å¤±è´¥ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        progress = counters["completed_count"] / len(endpoint_configs)
                        progress_bar.progress(progress)
                        
                    except Exception as e:
                        st.error(f"å¤„ç†ä»»åŠ¡æ—¶å‡ºé”™: {str(e)}")
            
            # è¿è¡Œå¼‚æ­¥å¹¶å‘è½¬å†™
            try:
                # è·å–æˆ–åˆ›å»ºäº‹ä»¶å¾ªç¯
                try:
                    loop = asyncio.get_event_loop()
                    if loop.is_closed():
                        loop = asyncio.new_event_loop()
                        asyncio.set_event_loop(loop)
                except RuntimeError:
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                
                # è¿è¡Œå¼‚æ­¥å‡½æ•°
                loop.run_until_complete(run_concurrent_transcribe())
            except Exception as e:
                st.error(f"å¹¶å‘è½¬å†™æ‰§è¡Œå¤±è´¥: {str(e)}")
                # å¦‚æœå¼‚æ­¥æ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°çº¿ç¨‹æ± æ¨¡å¼
                st.warning("å¼‚æ­¥æ¨¡å¼å¤±è´¥ï¼Œå›é€€åˆ°çº¿ç¨‹æ± æ¨¡å¼...")
                with ThreadPoolExecutor(max_workers=len(endpoint_configs)) as executor:
                    future_to_endpoint = {
                        executor.submit(
                            concurrent_call_wrapper, 
                            ep_name, 
                            ep_config, 
                            full_prompt,
                            180,
                            True,
                            stream_containers[ep_name]
                        ): ep_name
                        for ep_name, ep_config in endpoint_configs.items()
                    }
                    
                    for future in as_completed(future_to_endpoint):
                        endpoint_name, success, result_text, elapsed = future.result()
                        results[endpoint_name] = {
                            "success": success,
                            "result": result_text,
                            "elapsed": elapsed
                        }
                        
                        if endpoint_name in stream_containers:
                            stream_containers[endpoint_name].empty()
                        
                        counters["completed_count"] += 1
                        
                        if success:
                            counters["success_count"] += 1
                            ts = f"{base_ts}_{counters['completed_count']}"
                            safe_endpoint = endpoint_name.replace("/", "_").replace(" ", "_").replace(":", "_")
                            local_md_path = os.path.join(md_review_dir, f"{ts}_{safe_channel}_{safe_endpoint}.md")
                            
                            with open(local_md_path, "w", encoding="utf-8") as f:
                                f.write(result_text)
                            
                            save_transcribe_history(selected_channel, "concurrent", input_content, result_text, 
                                                   extra={"endpoint": endpoint_name, "elapsed": elapsed})
                            
                            try:
                                subprocess.Popen(["open", local_md_path])
                                status_text.text(f"âœ… {endpoint_name} å®Œæˆå¹¶å·²æ‰“å¼€ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                            except Exception:
                                status_text.text(f"âœ… {endpoint_name} å®Œæˆ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                            
                            saved_files.append((endpoint_name, local_md_path))
                        else:
                            counters["failed_count"] += 1
                            status_text.text(f"âŒ {endpoint_name} å¤±è´¥ ({elapsed:.2f}ç§’) | è¿›åº¦: {counters['completed_count']}/{len(endpoint_configs)}")
                        
                        progress = counters["completed_count"] / len(endpoint_configs)
                        progress_bar.progress(progress)
                        time.sleep(0.3)
            
            # å®Œæˆåæ¸…é™¤è¿›åº¦æ˜¾ç¤º
            progress_bar.empty()
            status_text.empty()
            
            # ä¿å­˜å¹¶å‘å†å²åˆ° JSON æ–‡ä»¶
            save_concurrent_history(base_ts, selected_channel, results, saved_files)
            
            # ä¿å­˜åˆ° session_state ä»¥ä¾¿åœ¨å¯¹æ¯”åŒºæ˜¾ç¤º
            st.session_state["current_concurrent_results"] = {
                "task_id": base_ts,
                "channel": selected_channel,
                "timestamp": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "results": results,
                "saved_files": saved_files,
                "statistics": {
                    "total": len(results),
                    "success": counters["success_count"],
                    "failed": counters["failed_count"]
                }
            }
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            if saved_files:
                st.success(f"ğŸ‰ å¹¶å‘è½¬å†™å®Œæˆï¼å·²è‡ªåŠ¨ä¿å­˜å¹¶æ‰“å¼€ {len(saved_files)} ä¸ªæˆåŠŸçš„ç»“æœ")
            
            # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
            col_stat1, col_stat2, col_stat3 = st.columns(3)
            with col_stat1:
                st.metric("æ€»ç«¯ç‚¹æ•°", len(results))
            with col_stat2:
                st.metric("æˆåŠŸ", counters["success_count"], delta=counters["success_count"], delta_color="normal")
            with col_stat3:
                st.metric("å¤±è´¥", counters["failed_count"], delta=counters["failed_count"] if counters["failed_count"] > 0 else None, delta_color="inverse")
            
            # å¹¶å‘è½¬å†™å®Œæˆåï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ°å¯¹æ¯”åŒº
            st.session_state["show_concurrent_compare"] = True

# ============================================================================
# å¹¶å‘ç»“æœå¯¹æ¯”åŒºï¼ˆç‹¬ç«‹ã€å¯æŠ˜å ï¼‰
# ============================================================================

def render_concurrent_results(results_data, key_prefix="current"):
    """
    æ¸²æŸ“å¹¶å‘ç»“æœå¯¹æ¯”
    
    å‚æ•°:
        results_data: åŒ…å« results å’Œ saved_files çš„å­—å…¸
        key_prefix: æŒ‰é’®keyçš„å‰ç¼€ï¼Œé¿å…é‡å¤
    """
    results = results_data.get("results", {})
    saved_files = results_data.get("saved_files", [])
    
    if not results:
        st.info("æš‚æ— å¹¶å‘ç»“æœ")
        return
    
    # æ ¹æ®ç«¯ç‚¹æ•°é‡å†³å®šåˆ—æ•°ï¼ˆæœ€å¤š4åˆ—ï¼Œæœ€å°‘2åˆ—ï¼‰
    num_endpoints = len(results)
    num_columns = min(max(2, num_endpoints), 4)
    
    # åˆ›å»ºå¹¶æ’çš„åˆ—å¸ƒå±€
    result_columns = st.columns(num_columns)
    
    # å°†ç»“æœåˆ†é…åˆ°å„åˆ—ä¸­
    for idx, (ep_name, result_data) in enumerate(results.items()):
        col_idx = idx % num_columns
        
        with result_columns[col_idx]:
            # å¡ç‰‡æ ·å¼çš„å®¹å™¨
            status_icon = "âœ…" if result_data["success"] else "âŒ"
            status_color = "#28a745" if result_data["success"] else "#dc3545"
            elapsed_time = f"{result_data['elapsed']:.2f}ç§’"
            
            # ä½¿ç”¨è‡ªå®šä¹‰æ ·å¼çš„å®¹å™¨
            st.markdown(f"""
            <div style="
                border: 2px solid {status_color};
                border-radius: 10px;
                padding: 15px;
                margin-bottom: 20px;
                background-color: rgba(255, 255, 255, 0.05);
            ">
                <h4 style="margin: 0 0 10px 0; color: {status_color};">
                    {status_icon} {ep_name}
                </h4>
                <p style="margin: 0; font-size: 0.9em; color: #888;">
                    â±ï¸ {elapsed_time}
                </p>
            </div>
            """, unsafe_allow_html=True)
            
            if result_data["success"]:
                # æ˜¾ç¤ºæˆåŠŸçš„è½¬å†™ç»“æœ
                with st.container():
                    # ç›´æ¥æ˜¾ç¤ºå®Œæ•´å†…å®¹ï¼Œä¸å†ä½¿ç”¨æŠ˜å å—
                    st.markdown(result_data["result"])
                    
                    # æ·»åŠ æ‰“å¼€æŒ‰é’®
                    # æ‰¾åˆ°è¯¥ç«¯ç‚¹å¯¹åº”çš„å·²ä¿å­˜æ–‡ä»¶
                    saved_file_path = None
                    for saved_ep, saved_path in saved_files:
                        if saved_ep == ep_name:
                            saved_file_path = saved_path
                            break
                    
                    if saved_file_path:
                        if st.button(f"ğŸ“‚ æ‰“å¼€æ–‡ä»¶", key=f"{key_prefix}_open_{ep_name}_{idx}", use_container_width=True):
                            # ç”¨ç³»ç»Ÿé»˜è®¤åº”ç”¨æ‰“å¼€å·²ä¿å­˜çš„æ–‡ä»¶
                            try:
                                subprocess.Popen(["open", saved_file_path])
                                st.success(f"âœ… å·²æ‰“å¼€æ–‡ä»¶ï¼")
                            except Exception as e:
                                st.error(f"æ— æ³•æ‰“å¼€æ–‡ä»¶: {e}")
            else:
                # æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
                st.error(f"**é”™è¯¯:**\n{result_data['result']}")


# æ£€æŸ¥æ˜¯å¦æœ‰å¹¶å‘ç»“æœæˆ–å†å²è®°å½•
history_list = load_concurrent_history_list()
has_current_results = "current_concurrent_results" in st.session_state
has_history = len(history_list) > 0

# å¦‚æœæœ‰å½“å‰ç»“æœæˆ–å†å²è®°å½•ï¼Œæ˜¾ç¤ºå¯¹æ¯”åŒº
if has_current_results or has_history:
    st.markdown("---")
    st.markdown("## å¹¶å‘ç»“æœå¯¹æ¯”åŒº")
    
    # å†³å®šé»˜è®¤æ˜¾ç¤ºå“ªä¸ªTabï¼ˆå¦‚æœåˆšæ‰§è¡Œå®Œå¹¶å‘è½¬å†™ï¼Œæ˜¾ç¤ºå½“å‰ç»“æœï¼›å¦åˆ™æ˜¾ç¤ºå†å²ï¼‰
    if has_current_results and st.session_state.get("show_concurrent_compare", False):
        # åˆšæ‰§è¡Œå®Œå¹¶å‘è½¬å†™ï¼Œé»˜è®¤æ˜¾ç¤ºå½“å‰ç»“æœ
        default_tab_index = 0
        # æ¸…é™¤æ ‡è®°ï¼Œé¿å…ä¸‹æ¬¡åˆ·æ–°æ—¶è¿˜é»˜è®¤æ˜¾ç¤ºå½“å‰ç»“æœ
        if "show_concurrent_compare" in st.session_state:
            del st.session_state["show_concurrent_compare"]
    else:
        # å¦åˆ™é»˜è®¤æ˜¾ç¤ºå†å²å¯¹æ¯”
        default_tab_index = 1 if has_history and not has_current_results else 0
    
    # åˆ›å»ºæ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ¯ å½“å‰ç»“æœ", "ğŸ“š å†å²å¯¹æ¯”"])
    
    with tab1:
        # æ˜¾ç¤ºå½“å‰å¹¶å‘ç»“æœ
        if "current_concurrent_results" in st.session_state:
            current_data = st.session_state["current_concurrent_results"]
            
            # æ˜¾ç¤ºä¿¡æ¯
            col_info1, col_info2, col_info3 = st.columns(3)
            with col_info1:
                st.info(f"**é¢‘é“:** {current_data['channel']}")
            with col_info2:
                st.info(f"**æ—¶é—´:** {current_data['timestamp']}")
            with col_info3:
                stats = current_data['statistics']
                st.info(f"**ç»“æœ:** {stats['success']}/{stats['total']} æˆåŠŸ")
            
            st.markdown("---")
            
            # æ¸²æŸ“ç»“æœ
            render_concurrent_results(current_data, key_prefix="current")
        else:
            st.info("æš‚æ— å½“å‰å¹¶å‘ç»“æœï¼Œè¯·å…ˆæ‰§è¡Œå¹¶å‘è½¬å†™")
    
    with tab2:
        # æ˜¾ç¤ºå†å²å¯¹æ¯”
        st.markdown("### é€‰æ‹©å†å²è®°å½•")
        
        # ä½¿ç”¨å·²åŠ è½½çš„å†å²åˆ—è¡¨ï¼ˆé¿å…é‡å¤åŠ è½½ï¼‰
        if history_list:
            # åˆ›å»ºä¸‹æ‹‰é€‰æ‹©æ¡†
            history_options = ["è¯·é€‰æ‹©å†å²è®°å½•..."] + [item[0] for item in history_list]
            selected_history = st.selectbox(
                "å†å²å¹¶å‘ç»“æœ",
                history_options,
                key="history_selector"
            )
            
            if selected_history and selected_history != "è¯·é€‰æ‹©å†å²è®°å½•...":
                # æ‰¾åˆ°å¯¹åº”çš„å†å²è®°å½•
                selected_idx = history_options.index(selected_history) - 1
                history_file_path = history_list[selected_idx][1]
                history_metadata = history_list[selected_idx][2]
                
                # æ˜¾ç¤ºå†å²ä¿¡æ¯
                col_h1, col_h2, col_h3 = st.columns(3)
                with col_h1:
                    st.info(f"**é¢‘é“:** {history_metadata['channel']}")
                with col_h2:
                    st.info(f"**æ—¶é—´:** {history_metadata['timestamp']}")
                with col_h3:
                    stats = history_metadata['statistics']
                    st.info(f"**ç»“æœ:** {stats['success']}/{stats['total']} æˆåŠŸ")
                
                st.markdown("---")
                
                # ä»å†å²å…ƒæ•°æ®é‡å»ºç»“æœæ•°æ®ç»“æ„
                history_results = {}
                history_saved_files = []
                
                for result_info in history_metadata['results']:
                    ep_name = result_info['endpoint']
                    
                    if result_info['success']:
                        # æˆåŠŸçš„ç»“æœ - ä»æ–‡ä»¶è¯»å–å†…å®¹
                        file_path = result_info.get('file_path')
                        if file_path and os.path.exists(file_path):
                            try:
                                with open(file_path, 'r', encoding='utf-8') as f:
                                    content = f.read()
                                history_results[ep_name] = {
                                    "success": True,
                                    "result": content,
                                    "elapsed": result_info['elapsed']
                                }
                                history_saved_files.append((ep_name, file_path))
                            except Exception as e:
                                history_results[ep_name] = {
                                    "success": False,
                                    "result": f"æ— æ³•è¯»å–æ–‡ä»¶: {e}",
                                    "elapsed": result_info['elapsed']
                                }
                        else:
                            history_results[ep_name] = {
                                "success": False,
                                "result": "æ–‡ä»¶ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤",
                                "elapsed": result_info['elapsed']
                            }
                    else:
                        # å¤±è´¥çš„ç»“æœ
                        history_results[ep_name] = {
                            "success": False,
                            "result": result_info.get('error', 'æœªçŸ¥é”™è¯¯'),
                            "elapsed": result_info['elapsed']
                        }
                
                # æ¸²æŸ“å†å²ç»“æœ
                history_data = {
                    "results": history_results,
                    "saved_files": history_saved_files
                }
                render_concurrent_results(history_data, key_prefix=f"history_{selected_idx}")
        else:
            st.info("æš‚æ— å†å²è®°å½•ï¼Œæ‰§è¡Œå¹¶å‘è½¬å†™åä¼šè‡ªåŠ¨ä¿å­˜")

# ============================================================================
# æ¿å—åˆ†éš”ï¼šMDå®¡æ ¸ä¸HTMLé¢„è§ˆ
# ============================================================================

# æ·»åŠ è§†è§‰åˆ†éš”
st.markdown("---")
st.markdown("<br>", unsafe_allow_html=True)

# å¯¼å…¥MDé¢„è§ˆæ‰€éœ€çš„æ¨¡å—
from md_utils import md_to_html
import streamlit.components.v1 as components
from datetime import datetime

# å¤šè¯­è¨€æ–‡æœ¬
T = {
    "zh": {
        "page_title": "æœ¬åœ°MDå®¡æ ¸ä¸HTMLé¢„è§ˆ",
        "select_md": "é€‰æ‹©Markdownæ–‡ä»¶ï¼š",
        "edit": "ç¼–è¾‘Markdownå†…å®¹ï¼š",
        "select_template": "é€‰æ‹©HTMLæ¨¡æ¿",
        "font_size": "Markdownå­—å·ï¼ˆpxï¼‰",
        "html_height": "HTMLé¢„è§ˆé«˜åº¦ï¼ˆpxï¼‰",
        "html_preview": "HTMLé¢„è§ˆ",
        "get_language()": "è¯­è¨€",
    }
}

st.title("ğŸ“ MDå®¡æ ¸ä¸HTMLé¢„è§ˆ")

# è¯»å–æ‰€æœ‰mdæ–‡ä»¶ï¼ˆåŒ…æ‹¬workspaceå’Œlegacyç›®å½•ï¼‰
def get_all_md_files():
    """è·å–æ‰€æœ‰markdownæ–‡ä»¶ï¼ŒåŒ…æ‹¬workspaceå’Œlegacyç›®å½•"""
    all_files = []
    
    # ä½¿ç”¨ç®€åŒ–è·¯å¾„ç®¡ç†
    project_root = PROJECT_ROOT
    
    # ä»workspaceç›®å½•è¯»å–
    workspace_md_dir = get_md_review_dir()
    if os.path.exists(workspace_md_dir):
        try:
            workspace_files = [f for f in os.listdir(workspace_md_dir) if f.endswith('.md')]
            for f in workspace_files:
                all_files.append({
                    'name': f,
                    'path': os.path.join(workspace_md_dir, f),
                    'source': 'workspace'
                })
        except Exception as e:
            st.warning(f"è¯»å–workspaceç›®å½•å¤±è´¥: {e}")
    
    # ä»legacyç›®å½•è¯»å–
    legacy_md_dir = os.path.join(project_root, "app", "md_review")
    if os.path.exists(legacy_md_dir):
        try:
            legacy_files = [f for f in os.listdir(legacy_md_dir) if f.endswith('.md')]
            for f in legacy_files:
                # é¿å…é‡å¤æ–‡ä»¶å
                if not any(item['name'] == f for item in all_files):
                    all_files.append({
                        'name': f,
                        'path': os.path.join(legacy_md_dir, f),
                        'source': 'legacy'
                    })
        except Exception as e:
            st.warning(f"è¯»å–legacyç›®å½•å¤±è´¥: {e}")
    
    # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„åœ¨å‰é¢
    try:
        all_files.sort(key=lambda x: os.path.getmtime(x['path']), reverse=True)
    except Exception as e:
        st.warning(f"æ–‡ä»¶æ’åºå¤±è´¥: {e}")
    
    return all_files

# è·å–æ‰€æœ‰markdownæ–‡ä»¶
md_files_data = get_all_md_files()
md_files = [f['name'] for f in md_files_data]


# æ˜¾ç¤ºæ–‡ä»¶ç»Ÿè®¡ä¿¡æ¯
if md_files_data:
    workspace_count = len([f for f in md_files_data if f['source'] == 'workspace'])
    legacy_count = len([f for f in md_files_data if f['source'] == 'legacy'])
    
    col_stats1, col_stats2, col_stats3 = st.columns(3)
    with col_stats1:
        st.metric("æ€»æ–‡ä»¶æ•°", len(md_files_data))
    with col_stats2:
        st.metric("Workspaceç›®å½•", workspace_count, delta=f"+{workspace_count}")
    with col_stats3:
        st.metric("Legacyç›®å½•", legacy_count, delta=f"+{legacy_count}")
    
    # æ˜¾ç¤ºç›®å½•è·¯å¾„ä¿¡æ¯
    current_file_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file_dir)))
else:
    st.warning("æœªæ‰¾åˆ°ä»»ä½•Markdownæ–‡ä»¶")
    
    # æ˜¾ç¤ºè°ƒè¯•ä¿¡æ¯
    current_file_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(current_file_dir)))
    
    with st.expander(f"è°ƒè¯•ä¿¡æ¯"):
        st.write("**æ£€æŸ¥çš„ç›®å½•:**")
        workspace_md_dir = get_md_review_dir()
        legacy_md_dir = os.path.join(project_root, "app", "md_review")
        
        st.write(f"1. Workspaceç›®å½•: {workspace_md_dir}")
        st.write(f"   - å­˜åœ¨: {os.path.exists(workspace_md_dir)}")
        if os.path.exists(workspace_md_dir):
            try:
                files = os.listdir(workspace_md_dir)
                md_files = [f for f in files if f.endswith('.md')]
                st.write(f"   - æ€»æ–‡ä»¶æ•°: {len(files)}")
                st.write(f"   - MDæ–‡ä»¶æ•°: {len(md_files)}")
            except Exception as e:
                st.error(f"   - è¯»å–å¤±è´¥: {e}")
        
        st.write(f"2. Legacyç›®å½•: {legacy_md_dir}")
        st.write(f"   - å­˜åœ¨: {os.path.exists(legacy_md_dir)}")
        if os.path.exists(legacy_md_dir):
            try:
                files = os.listdir(legacy_md_dir)
                md_files = [f for f in files if f.endswith('.md')]
                st.write(f"   - MDæ–‡ä»¶æ•°: {len(md_files)}")
            except Exception as e:
                st.error(f"   - è¯»å–å¤±è´¥: {e}")

# è·¯å¾„é…ç½®
STATIC_DIR = get_static_dir()
TEMPLATE_DIR = "static/templates"
MD_DIR = get_md_review_dir()
os.makedirs(STATIC_DIR, exist_ok=True)
os.makedirs(MD_DIR, exist_ok=True)

# åˆå§‹åŒ–å˜é‡ï¼Œé¿å…ä½œç”¨åŸŸé—®é¢˜
selected = None
edited = ""
selected_file_data = None

# é¡µé¢å·¦å³åˆ†æ ï¼ˆå®¡æ ¸åŒºå’Œé¢„è§ˆåŒºç”¨åˆ†å‰²çº¿åˆ†éš”ï¼‰
col1, col_divider, col2 = st.columns([10, 0.5, 10])

# åœ¨ä¸­é—´åˆ—æ˜¾ç¤ºåˆ†å‰²çº¿
with col_divider:
    st.markdown("""
        <div style="
            width: 1px;
            height: 100vh;
            background: linear-gradient(to bottom, 
                transparent 0%, 
                #E0E0E0 10%, 
                #E0E0E0 90%, 
                transparent 100%);
            margin: 0 auto;
        "></div>
    """, unsafe_allow_html=True)

# å·¦ä¾§ï¼šé€‰æ‹©/ç¼–è¾‘/é¢„è§ˆMarkdown
with col1:
    if md_files:
        # æ·»åŠ é»˜è®¤é€‰é¡¹ï¼Œé¿å…è‡ªåŠ¨åŠ è½½ç¬¬ä¸€ä¸ªæ–‡ä»¶
        file_options = ["--- è¯·é€‰æ‹©Markdownæ–‡ä»¶ ---"] + md_files
        
        # å¦‚æœ session_state ä¸­æœ‰æŒ‡å®šçš„æ–‡ä»¶ï¼Œè‡ªåŠ¨é€‰ä¸­ï¼ˆæ¥è‡ªè½¬å†™æ“ä½œï¼‰
        default_index = 0
        if "current_md_file" in st.session_state and st.session_state["current_md_file"] in md_files:
            # åªåœ¨é¦–æ¬¡è§¦å‘æ—¶è‡ªåŠ¨é€‰ä¸­ï¼Œç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©åæ¸…é™¤
            if st.session_state.get("auto_select_triggered", False):
                default_index = md_files.index(st.session_state["current_md_file"]) + 1
        
        selected = st.selectbox("é€‰æ‹©Markdownæ–‡ä»¶ï¼š", file_options, index=default_index)
        
        # å¦‚æœç”¨æˆ·æ‰‹åŠ¨é€‰æ‹©äº†æ–‡ä»¶ï¼ˆéé»˜è®¤é€‰é¡¹ï¼‰ï¼Œæ¸…é™¤è‡ªåŠ¨é€‰æ‹©æ ‡è®°
        if selected != "--- è¯·é€‰æ‹©Markdownæ–‡ä»¶ ---":
            if "auto_select_triggered" in st.session_state:
                # å¦‚æœå½“å‰é€‰æ‹©çš„ä¸æ˜¯è‡ªåŠ¨è§¦å‘çš„æ–‡ä»¶ï¼Œæ¸…é™¤æ ‡è®°
                if selected != st.session_state.get("current_md_file"):
                    del st.session_state["auto_select_triggered"]
                    if "current_md_file" in st.session_state:
                        del st.session_state["current_md_file"]
        
        # åªæœ‰ç”¨æˆ·é€‰æ‹©äº†å…·ä½“æ–‡ä»¶æ‰åŠ è½½
        if selected and selected != "--- è¯·é€‰æ‹©Markdownæ–‡ä»¶ ---":
            # æ‰¾åˆ°å¯¹åº”çš„æ–‡ä»¶æ•°æ®
            selected_file_data = next((f for f in md_files_data if f['name'] == selected), None)
        
            if selected_file_data:
                # è¯»å–æ–‡ä»¶å†…å®¹
                with open(selected_file_data['path'], 'r', encoding='utf-8') as f:
                    md_content = f.read()
                
                # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯
                file_stat = os.stat(selected_file_data['path'])
                st.caption(f"æœ€åä¿®æ”¹: {datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')}")
                st.caption(f"æ–‡ä»¶å¤§å°: {file_stat.st_size:,} å­—èŠ‚")
                
                # æ˜¾ç¤ºæ¸²æŸ“åçš„Markdownå†…å®¹
                st.markdown(md_content, unsafe_allow_html=False)
                edited = md_content
            else:
                st.error("æ— æ³•æ‰¾åˆ°é€‰ä¸­çš„æ–‡ä»¶")
                edited = ""
        else:
            # æ˜¾ç¤ºæç¤ºä¿¡æ¯
            st.info("ğŸ‘† è¯·ä»ä¸Šæ–¹ä¸‹æ‹‰æ¡†é€‰æ‹©ä¸€ä¸ªMarkdownæ–‡ä»¶è¿›è¡Œå®¡æ ¸å’Œé¢„è§ˆ")
            edited = ""
    else:
        st.info("æš‚æ— Markdownæ–‡ä»¶")

# å³ä¾§ï¼šé€‰æ‹©æ¨¡æ¿ã€HTMLé¢„è§ˆ
with col2:
    if not md_files:
        st.info("è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©Markdownæ–‡ä»¶")
    elif not selected or selected == "--- è¯·é€‰æ‹©Markdownæ–‡ä»¶ ---":
        st.info("ğŸ‘ˆ è¯·å…ˆåœ¨å·¦ä¾§é€‰æ‹©Markdownæ–‡ä»¶")
    else:
        template_files = [f for f in os.listdir(TEMPLATE_DIR) if f.endswith('.html')]
        
        # ä»æ–‡ä»¶åä¸­æå–é¢‘é“ä¿¡æ¯ï¼Œè‡ªåŠ¨åŒ¹é…é¢‘é“ç»‘å®šçš„æ¨¡æ¿
        default_template_idx = 0
        current_channel_name = None
        matching_channel = None
        
        if selected:
            # å°è¯•ä»æ–‡ä»¶åä¸­è§£æé¢‘é“åç§°ï¼ˆæ ¼å¼ï¼šæ—¶é—´æˆ³_é¢‘é“å_ç«¯ç‚¹å.mdï¼‰
            import re
            # åŒ¹é…æ ¼å¼ï¼š20241021_123456_{é¢‘é“å}_{ç«¯ç‚¹å}.md
            # ä½¿ç”¨è´ªå©ªåŒ¹é…ï¼ŒåŒ¹é…åˆ°å€’æ•°ç¬¬äºŒä¸ªä¸‹åˆ’çº¿ä¸ºæ­¢
            # å› ä¸ºç«¯ç‚¹åå¯èƒ½åŒ…å«ä¸‹åˆ’çº¿ï¼Œæ‰€ä»¥ä»åå¾€å‰æ‰¾æœ€åä¸€ä¸ªä¸‹åˆ’çº¿æ¥åˆ†éš”
            match = re.match(r'(\d{8}_\d{6})_(.+)\.md$', selected)
            
            safe_channel_name = None
            endpoint_name = None
            
            if match:
                timestamp = match.group(1)
                # å‰©ä½™éƒ¨åˆ†ï¼ˆé¢‘é“å_ç«¯ç‚¹åï¼‰
                remaining = match.group(2)
                
                # å°è¯•åŒ¹é…æ‰€æœ‰å¯èƒ½çš„é¢‘é“ï¼Œä»æœ€é•¿çš„å¼€å§‹åŒ¹é…
                # è¿™æ ·å¯ä»¥å¤„ç†é¢‘é“åå’Œç«¯ç‚¹åéƒ½åŒ…å«ä¸‹åˆ’çº¿çš„æƒ…å†µ
                best_match_channel = None
                best_match_endpoint = None
                
                for ch in channels:
                    ch_name = ch.get('name', '')
                    # å°†é¢‘é“åè½¬æ¢ä¸ºsafeæ ¼å¼ï¼ˆä¸ä¿å­˜æ—¶çš„é€»è¾‘ä¸€è‡´ï¼‰
                    safe_ch_name = ch_name.replace("/", "_").replace(" ", "_")
                    
                    # æ£€æŸ¥ remaining æ˜¯å¦ä»¥ safe_ch_name å¼€å¤´
                    if remaining.startswith(safe_ch_name + "_"):
                        # æå–ç«¯ç‚¹åéƒ¨åˆ†
                        potential_endpoint = remaining[len(safe_ch_name) + 1:]  # +1 è·³è¿‡ä¸‹åˆ’çº¿
                        
                        # å¦‚æœè¿™æ˜¯ç›®å‰æ‰¾åˆ°çš„æœ€ä½³åŒ¹é…ï¼ˆé¢‘é“åæœ€é•¿çš„ï¼‰
                        if best_match_channel is None or len(safe_ch_name) > len(best_match_channel.get('name', '').replace("/", "_").replace(" ", "_")):
                            best_match_channel = ch
                            best_match_endpoint = potential_endpoint
                            safe_channel_name = safe_ch_name
                            endpoint_name = potential_endpoint
                
                if best_match_channel:
                    matching_channel = best_match_channel
                    current_channel_name = safe_channel_name
            
            # å¦‚æœæ‰¾åˆ°åŒ¹é…çš„é¢‘é“ï¼Œä½¿ç”¨å…¶ç»‘å®šçš„æ¨¡æ¿
            if matching_channel:
                bound_template = matching_channel.get('template', '01_modern_news.html')
                if bound_template in template_files:
                    default_template_idx = template_files.index(bound_template)
        
        # ç¡®ä¿åœ¨é€‰æ‹©æ¡†æ¸²æŸ“å‰æœ‰æœ‰æ•ˆçš„ç´¢å¼•
        if default_template_idx >= len(template_files):
            default_template_idx = 0
        
        template_choice = st.selectbox(
            "é€‰æ‹©HTMLæ¨¡æ¿", 
            template_files,
            index=default_template_idx,
            key=f"template_selector_{selected}",  # æ·»åŠ å”¯ä¸€keyï¼Œç¡®ä¿é€‰æ‹©å™¨éšæ–‡ä»¶å˜åŒ–è€Œæ›´æ–°
            help="é»˜è®¤ä½¿ç”¨é¢‘é“ç»‘å®šçš„æ¨¡æ¿ï¼Œä¹Ÿå¯æ‰‹åŠ¨åˆ‡æ¢"
        )
        
        # æ¸²æŸ“HTMLé¢„è§ˆ
        if selected and edited:
            try:
                html_result = md_to_html(edited, template_name=template_choice)
                # å¼ºåˆ¶è¦†ç›–æ‰€æœ‰å®¹å™¨çš„é«˜åº¦å’Œoverflowï¼Œç¡®ä¿å®Œæ•´æ˜¾ç¤º
                force_css = '''
                <style>
                html, body, .container, .main-title, .content, .logo-badge {
                    min-height: 100vh !important;
                    height: auto !important;
                    max-height: none !important;
                    overflow: visible !important;
                }
                * { box-sizing: border-box !important; }
                </style>
                '''
                html_result = force_css + html_result
                st.markdown("**HTMLé¢„è§ˆ**", unsafe_allow_html=True)
                # heightè®¾ä¸º10000ï¼Œä¿è¯å†…å®¹å®Œæ•´æ˜¾ç¤ºä¸”æ— æ»šåŠ¨æ¡
                components.html(html_result, height=10000, scrolling=False)
            except Exception as e:
                st.error(f"HTMLæ¸²æŸ“å¤±è´¥: {str(e)}")
                import traceback
                with st.expander("æŸ¥çœ‹è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                    st.code(traceback.format_exc())
        else:
            st.info("è¯·é€‰æ‹©ä¸€ä¸ªMarkdownæ–‡ä»¶ä»¥æŸ¥çœ‹HTMLé¢„è§ˆ") 