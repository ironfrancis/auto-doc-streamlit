#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç¯å¢ƒå˜é‡é…ç½®ç®¡ç†å™¨
ç”¨äºç®¡ç†ç¯å¢ƒå˜é‡å’Œé…ç½®æ–‡ä»¶çš„åŠ è½½ï¼Œæ”¯æŒ.envæ–‡ä»¶å’Œç¯å¢ƒå˜é‡è¦†ç›–
"""

import os
import json
from pathlib import Path
from typing import Dict, Any, Optional
from dotenv import load_dotenv


class EnvConfig:
    """ç¯å¢ƒå˜é‡é…ç½®ç®¡ç†å™¨ç±»"""
    
    def __init__(self, env_file: str = ".env"):
        """
        åˆå§‹åŒ–ç¯å¢ƒå˜é‡é…ç½®ç®¡ç†å™¨
        
        Args:
            env_file: .envæ–‡ä»¶è·¯å¾„
        """
        self.env_file = Path(env_file)
        self.config = {}
        self._load_env()
        self._load_config()
    
    def _load_env(self):
        """åŠ è½½.envæ–‡ä»¶"""
        if self.env_file.exists():
            load_dotenv(self.env_file)
            print(f"âœ… å·²åŠ è½½ç¯å¢ƒå˜é‡æ–‡ä»¶: {self.env_file}")
        else:
            print(f"âš ï¸  ç¯å¢ƒå˜é‡æ–‡ä»¶ä¸å­˜åœ¨: {self.env_file}")
            print("ğŸ’¡ è¯·å¤åˆ¶ .env.example ä¸º .env å¹¶å¡«å…¥æ‚¨çš„é…ç½®")
    
    def _load_config(self):
        """åŠ è½½é…ç½®åˆ°å†…å­˜"""
        self.config = {
            # é¡¹ç›®è·¯å¾„é…ç½®
            'PROJECT_ROOT': os.getenv('PROJECT_ROOT', '.'),
            'APP_DIR': os.getenv('APP_DIR', 'app'),
            'CONFIG_DIR': os.getenv('CONFIG_DIR', 'config'),
            'TEMPLATES_DIR': os.getenv('TEMPLATES_DIR', 'templates'),
            'STATIC_DIR': os.getenv('STATIC_DIR', 'static'),
            'WORKSPACE_DIR': os.getenv('WORKSPACE_DIR', 'workspace'),
            
            # æ•°æ®ç›®å½•
            'MD_REVIEW_DIR': os.getenv('MD_REVIEW_DIR', 'workspace/articles/md_review'),
            'IMAGES_DIR': os.getenv('IMAGES_DIR', 'workspace/images'),
            'EXPORTS_DIR': os.getenv('EXPORTS_DIR', 'workspace/exports'),
            'ARTICLES_DIR': os.getenv('ARTICLES_DIR', 'workspace/articles'),
            
            # LLM APIé…ç½®
            'DEFAULT_LLM_API_URL': os.getenv('DEFAULT_LLM_API_URL', 'https://api.openai.com/v1/chat/completions'),
            'DEFAULT_LLM_API_KEY': os.getenv('DEFAULT_LLM_API_KEY', ''),
            'DEFAULT_LLM_MODEL': os.getenv('DEFAULT_LLM_MODEL', 'gpt-3.5-turbo'),
            'DEFAULT_LLM_TEMPERATURE': float(os.getenv('DEFAULT_LLM_TEMPERATURE', '0.7')),
            
            # å¤‡ç”¨LLMé…ç½®
            'BACKUP_LLM_API_URL': os.getenv('BACKUP_LLM_API_URL', ''),
            'BACKUP_LLM_API_KEY': os.getenv('BACKUP_LLM_API_KEY', ''),
            'BACKUP_LLM_MODEL': os.getenv('BACKUP_LLM_MODEL', ''),
            
            # å¾®ä¿¡å…¬ä¼—å·é…ç½®
            'WECHAT_TOKENS': self._parse_json_env('WECHAT_TOKENS', {}),
            'WECHAT_COOKIES': self._parse_json_env('WECHAT_COOKIES', {}),
            
            # ç¬¬ä¸‰æ–¹æœåŠ¡é…ç½®
            'IMAGE_SERVICE_URL': os.getenv('IMAGE_SERVICE_URL', ''),
            'IMAGE_SERVICE_KEY': os.getenv('IMAGE_SERVICE_KEY', ''),
            'DATABASE_URL': os.getenv('DATABASE_URL', 'sqlite:///workspace/data/app.db'),
            'REDIS_URL': os.getenv('REDIS_URL', 'redis://localhost:6379'),
            
            # å®‰å…¨é…ç½®
            'SECRET_KEY': os.getenv('SECRET_KEY', 'default_secret_key_change_in_production'),
            'JWT_SECRET_KEY': os.getenv('JWT_SECRET_KEY', 'default_jwt_secret_change_in_production'),
            
            # æ—¥å¿—é…ç½®
            'LOG_LEVEL': os.getenv('LOG_LEVEL', 'INFO'),
            'LOG_FILE': os.getenv('LOG_FILE', 'workspace/logs/app.log'),
            
            # å…¶ä»–é…ç½®
            'MAX_UPLOAD_SIZE': int(os.getenv('MAX_UPLOAD_SIZE', '100')),
            'SESSION_TIMEOUT': int(os.getenv('SESSION_TIMEOUT', '60')),
            'DEBUG_MODE': os.getenv('DEBUG_MODE', 'False').lower() == 'true',
            'DEBUG': os.getenv('DEBUG', 'True').lower() == 'true'
        }
    
    def _parse_json_env(self, key: str, default: Any) -> Any:
        """è§£æJSONæ ¼å¼çš„ç¯å¢ƒå˜é‡"""
        value = os.getenv(key, '')
        if not value:
            return default
        
        try:
            return json.loads(value)
        except json.JSONDecodeError:
            print(f"âš ï¸  ç¯å¢ƒå˜é‡ {key} çš„JSONæ ¼å¼æ— æ•ˆï¼Œä½¿ç”¨é»˜è®¤å€¼")
            return default
    
    def get(self, key: str, default: Any = None) -> Any:
        """
        è·å–é…ç½®å€¼
        
        Args:
            key: é…ç½®é”®
            default: é»˜è®¤å€¼
            
        Returns:
            é…ç½®å€¼
        """
        return self.config.get(key, default)
    
    def get_path(self, key: str) -> Path:
        """
        è·å–è·¯å¾„é…ç½®ï¼Œè¿”å›Pathå¯¹è±¡
        
        Args:
            key: é…ç½®é”®
            
        Returns:
            Pathå¯¹è±¡
        """
        path_str = self.get(key, '')
        return Path(path_str)
    
    def get_llm_config(self) -> Dict[str, Any]:
        """è·å–LLMé…ç½®"""
        return {
            'api_url': self.get('DEFAULT_LLM_API_URL'),
            'api_key': self.get('DEFAULT_LLM_API_KEY'),
            'model': self.get('DEFAULT_LLM_MODEL'),
            'temperature': self.get('DEFAULT_LLM_TEMPERATURE')
        }
    
    def get_backup_llm_config(self) -> Dict[str, Any]:
        """è·å–å¤‡ç”¨LLMé…ç½®"""
        return {
            'api_url': self.get('BACKUP_LLM_API_URL'),
            'api_key': self.get('BACKUP_LLM_API_KEY'),
            'model': self.get('BACKUP_LLM_MODEL'),
            'temperature': self.get('DEFAULT_LLM_TEMPERATURE')
        }
    
    def get_wechat_tokens(self) -> Dict[str, str]:
        """è·å–å¾®ä¿¡å…¬ä¼—å·Tokené…ç½®"""
        return self.get('WECHAT_TOKENS', {})
    
    def get_wechat_cookies(self) -> Dict[str, str]:
        """è·å–å¾®ä¿¡å…¬ä¼—å·Cookieé…ç½®"""
        return self.get('WECHAT_COOKIES', {})
    
    def is_production(self) -> bool:
        """åˆ¤æ–­æ˜¯å¦ä¸ºç”Ÿäº§ç¯å¢ƒ"""
        return not self.get('DEBUG', True)
    
    def validate_required_config(self) -> bool:
        """éªŒè¯å¿…éœ€çš„é…ç½®æ˜¯å¦å­˜åœ¨"""
        required_configs = [
            'DEFAULT_LLM_API_KEY',
            'SECRET_KEY'
        ]
        
        missing_configs = []
        for config in required_configs:
            if not self.get(config) or self.get(config) in ['', 'your_api_key_here', 'your_secret_key_here']:
                missing_configs.append(config)
        
        if missing_configs:
            print("âŒ ç¼ºå°‘å¿…éœ€çš„é…ç½®:")
            for config in missing_configs:
                print(f"   - {config}")
            print("ğŸ’¡ è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®è¿™äº›å€¼")
            return False
        
        return True
    
    def print_config_summary(self):
        """æ‰“å°é…ç½®æ‘˜è¦"""
        print("ğŸ“‹ å½“å‰é…ç½®æ‘˜è¦:")
        print(f"   é¡¹ç›®æ ¹ç›®å½•: {self.get('PROJECT_ROOT')}")
        print(f"   è°ƒè¯•æ¨¡å¼: {'å¼€å¯' if self.get('DEBUG') else 'å…³é—­'}")
        print(f"   LLM API: {self.get('DEFAULT_LLM_MODEL')}")
        print(f"   å¾®ä¿¡å…¬ä¼—å·æ•°é‡: {len(self.get_wechat_tokens())}")
        print(f"   é…ç½®éªŒè¯: {'é€šè¿‡' if self.validate_required_config() else 'å¤±è´¥'}")


# å…¨å±€é…ç½®å®ä¾‹
config = EnvConfig()


def get_config() -> EnvConfig:
    """è·å–å…¨å±€é…ç½®å®ä¾‹"""
    return config


def reload_config():
    """é‡æ–°åŠ è½½é…ç½®"""
    global config
    config = EnvConfig()
    return config
