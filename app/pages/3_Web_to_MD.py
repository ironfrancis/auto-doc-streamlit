import sys
import os
from asyncio import subprocess

# æ·»åŠ æ­£ç¡®çš„è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

from language_manager import init_language, get_text
import streamlit as st
import requests
from enhanced_web2md import extract_markdown_from_url
from utils import get_project_root
import json
from datetime import datetime
import time
import re
from pathlib import Path
import urllib.parse
from urllib.parse import urlparse
import hashlib
import base64
from path_manager import get_ori_docs_dir

# é¡µé¢è®¾ç½®
st.set_page_config(page_title="ç½‘é¡µè½¬MD", layout="wide")

# æ ‡é¢˜
st.title("ğŸŒ Web to Markdown")
st.caption("Extract content from web pages and convert to Markdown format")

# è·å–é¡¹ç›®æ ¹ç›®å½•
project_root = get_project_root()
from app.path_manager import get_ori_docs_dir
ori_docs_dir = get_ori_docs_dir()

# åˆ›å»ºè¡¨å•
with st.form("web2md_form"):
    # URLè¾“å…¥
    url = st.text_input(
        "Web URL",
        placeholder="https://example.com",
        help="Enter the URL of the web page you want to extract"
    )

    # åˆ›å»ºä¸¤åˆ—å¸ƒå±€ç”¨äºåŸºæœ¬é€‰é¡¹
    col1, col2 = st.columns(2)

    with col1:
        # æå–èŒƒå›´é€‰æ‹©
        scope = st.radio(
            "Extraction Scope",
            ["all", "viewport"],
            index=0,
            help="'all': Extract all content | 'viewport': Only extract visible content"
        )

        # ç­‰å¾…æ—¶é—´è®¾ç½®
        wait_time = st.slider(
            "Page Load Wait Time (seconds)",
            min_value=3,
            max_value=30,
            value=5,
            help="Increase this for pages with dynamic content"
        )

    with col2:
        # æ»šåŠ¨é€‰é¡¹
        enable_scroll = st.checkbox(
            "Enable Page Scrolling",
            value=True,
            help="Scroll through the page to load lazy content before extraction"
        )

        # æ»šåŠ¨æš‚åœæ—¶é—´
        scroll_pause = st.slider(
            "Scroll Pause Time (seconds)",
            min_value=0.5,
            max_value=5.0,
            value=1.0,
            step=0.5,
            help="Time to wait after each scroll action"
        )

        # å›¾ç‰‡ä¸‹è½½é€‰é¡¹
        download_images = st.checkbox(
            "Download Images to Local",
            value=True,
            help="Automatically download images from the webpage to local directory"
        )

        # è‡ªåŠ¨æ‰“å¼€æ–‡ä»¶é€‰é¡¹
        auto_open = st.checkbox(
            "Auto-open file after extraction",
            value=True,
            help="Automatically open the extracted Markdown file with default application"
        )

    # é«˜çº§é€‰é¡¹æŠ˜å åŒºåŸŸ
    with st.expander("Advanced Options"):
        # è§†å£é«˜åº¦
        viewport_height = st.slider(
            "Browser Viewport Height (pixels)",
            min_value=800,
            max_value=2000,
            value=1080,
            step=100,
            help="Height of the browser viewport in pixels"
        )

        # è¦ç§»é™¤çš„é€‰æ‹©å™¨
        remove_selectors = st.text_area(
            "Remove Elements (CSS Selectors)",
            placeholder="nav, .ads, #sidebar, .footer",
            help="CSS selectors of elements to remove before extraction (comma separated)"
        )

    # æäº¤æŒ‰é’®
    submitted = st.form_submit_button("Extract Content")

# å¤„ç†è¡¨å•æäº¤
if submitted and url:
    if not url.startswith(("http://", "https://")):
        url = f"https://{url}"

    with st.spinner(f"Extracting content from {url}..."):
        try:
            # å¤„ç†è¦ç§»é™¤çš„é€‰æ‹©å™¨
            selectors_to_remove = None
            if 'remove_selectors' in locals() and remove_selectors:
                selectors_to_remove = [s.strip() for s in remove_selectors.split(',') if s.strip()]
            
            # æå–Markdownå†…å®¹
            markdown = extract_markdown_from_url(
                url=url,
                scope=scope,
                wait_time=wait_time,
                scroll=enable_scroll if 'enable_scroll' in locals() else True,
                scroll_pause=scroll_pause if 'scroll_pause' in locals() else 1.0,
                viewport_height=viewport_height if 'viewport_height' in locals() else 1080,
                remove_selectors=selectors_to_remove,
                download_images=download_images if 'download_images' in locals() else True
            )

            if markdown:
                # æ˜¾ç¤ºæˆåŠŸæ¶ˆæ¯
                st.success("Content extracted successfully!")

                # æ˜¾ç¤ºå›¾ç‰‡ä¸‹è½½ä¿¡æ¯
                if 'download_images' in locals() and download_images:
                    static_dir = project_root / "app" / "static"
                    images_dir = static_dir / "images"
                    if images_dir.exists():
                        image_files = [f for f in images_dir.iterdir() if f.suffix.lower() in ('.png', '.jpg', '.jpeg', '.gif', '.webp')]
                        if image_files:
                            st.info(f"âœ… Downloaded {len(image_files)} images to local directory")
                            with st.expander("View downloaded images", expanded=False):
                                for img_file in sorted(image_files):
                                    file_size = img_file.stat().st_size
                                    st.markdown(f"- {img_file.name} ({file_size} bytes)")

                # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
                col1, col2 = st.columns([3, 1])

                with col1:
                    # æ˜¾ç¤ºæå–çš„å†…å®¹
                    st.subheader("Extracted Markdown")
                    st.code(markdown, language="markdown")

                with col2:
                    # ä¸‹è½½æŒ‰é’®
                    st.subheader("Download")
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"web_extract_{timestamp}.md"

                    st.download_button(
                        label="Download Markdown",
                        data=markdown,
                        file_name=filename,
                        mime="text/markdown"
                    )

                    # æ˜¾ç¤ºä¿å­˜è·¯å¾„
                    latest_file = max(
                        (f for f in ori_docs_dir.glob("*.md") if f.is_file()),
                        key=os.path.getmtime,
                        default=None
                    )

                    if latest_file:
                        st.info(f"Automatically saved to: `{latest_file}`")

                        # å¦‚æœç”¨æˆ·é€‰æ‹©äº†è‡ªåŠ¨æ‰“å¼€æ–‡ä»¶
                        if 'auto_open' in locals() and auto_open:
                            try:
                                # ä½¿ç”¨é»˜è®¤åº”ç”¨æ‰“å¼€æ–‡ä»¶ï¼ˆmacOSï¼‰
                                subprocess.call(['open', str(latest_file)])
                                st.success(f"File opened with default application")
                            except Exception as e:
                                st.warning(f"Could not open file automatically: {str(e)}")

                # æå–ç»Ÿè®¡ä¿¡æ¯
                st.subheader("Extraction Statistics")
                stats_col1, stats_col2, stats_col3 = st.columns(3)

                with stats_col1:
                    st.metric("Characters", len(markdown))

                with stats_col2:
                    st.metric("Words", len(markdown.split()))

                with stats_col3:
                    st.metric("Lines", markdown.count('\n') + 1)
            else:
                st.error("Failed to extract content. Please check the URL and try again.")

        except Exception as e:
            st.error(f"An error occurred: {str(e)}")
            st.exception(e)
elif submitted:
    st.warning("Please enter a valid URL")

# æ·»åŠ ä½¿ç”¨è¯´æ˜
with st.expander("Usage Tips"):
    st.markdown("""
    ### Tips for Better Extraction
    
    1. **Use 'all' scope** for most websites to extract complete content.
    
    2. **Enable page scrolling** to load lazy-loaded content before extraction.
    
    3. **Increase wait time** for complex pages with many dynamic elements.
    
    4. **Remove interfering elements** using CSS selectors to clean up the extraction:
       - Navigation menus: `nav, .navigation, .navbar`
       - Advertisements: `.ads, .ad-container, [class*="ad-"]`
       - Sidebars: `#sidebar, .sidebar, aside`
       - Footers: `footer, .footer`
       - Popups: `.modal, .popup, .overlay`
       
    5. **Adjust viewport height** if the page has unusual layout requirements.
    
    6. **Image Download**: Enable "Download Images to Local" to automatically download images from the webpage. Images will be saved to `app/static/images/` directory and paths will be updated in the Markdown content.
    
    7. If extraction fails, try opening the page in a regular browser first to ensure it loads properly.
    """)


