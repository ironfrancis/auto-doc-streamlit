import sys
import os
import json
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import streamlit as st
import numpy as np
from datetime import datetime, timedelta
import calendar

# æ·»åŠ æ­£ç¡®çš„è·¯å¾„
try:
    current_dir = os.path.dirname(os.path.abspath(__file__))
except NameError:
    # å¦‚æœ__file__ä¸å¯ç”¨ï¼Œä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
    current_dir = os.getcwd()
parent_dir = os.path.dirname(current_dir)
sys.path.insert(0, parent_dir)

# å¯¼å…¥ä¾èµ–æ¨¡å—
try:
    from language_manager import init_language, get_text
except ImportError:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„æ›¿ä»£å‡½æ•°
    def init_language():
        return "zh"
    
    def get_text(key, lang="zh"):
        return key

try:
    from path_manager import get_json_data_dir
except ImportError:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºç®€å•çš„æ›¿ä»£å‡½æ•°
    def get_json_data_dir():
        return os.path.join(os.getcwd(), "workspace", "data")

try:
    from utils.calendar_visualizer import CalendarVisualizer
except ImportError:
    # å¦‚æœæ¨¡å—ä¸å­˜åœ¨ï¼Œåˆ›å»ºä¸€ä¸ªç®€å•çš„æ›¿ä»£ç±»
    class CalendarVisualizer:
        def __init__(self, records, selected_channels, start_date, end_date):
            self.records = records
            self.selected_channels = selected_channels
            self.start_date = start_date
            self.end_date = end_date
        
        def create_heatmap_calendar(self):
            return None
        
        def create_monthly_calendar(self, year, month):
            return None
        
        def create_channel_timeline(self):
            return None
        
        def create_publish_pattern_analysis(self):
            return None

T = {
    "en": {
        "page_title": "Channel Publish History",
        "overview": "Publish Overview",
        "calendar_view": "Calendar View",
        "statistics": "Statistics",
        "detailed_records": "Detailed Records",
        "channel_filter": "Select Channel",
        "date_range": "Date Range",
        "all_channels": "All Channels",
        "total_published": "Total Published",
        "total_views": "Total Views",
        "total_likes": "Total Likes",
        "total_comments": "Total Comments",
        "total_shares": "Total Shares",
        "publish_frequency": "Publish Frequency",
        "performance_trend": "Performance Trend",
        "top_articles": "Top Articles",
        "article_id": "Article ID",
        "title": "Title",
        "publish_date": "Publish Date",
        "publish_time": "Publish Time",
        "status": "Status",
        "views": "Views",
        "likes": "Likes",
        "comments": "Comments",
        "shares": "Shares",
        "url": "URL",
        "tags": "Tags",
        "published": "Published",
        "draft": "Draft",
        "scheduled": "Scheduled",
        "no_data": "No Data",
        "export_data": "Export Data",
        "import_data": "Import Data",
        "add_record": "Add Record",
        "edit_record": "Edit Record",
        "delete_record": "Delete Record",
        "save": "Save",
        "cancel": "Cancel",
        "delete": "Delete",
        "confirm_delete": "Confirm Delete",
        "success": "Operation Successful",
        "error": "Operation Failed"
    }
}

# CSVæ•°æ®æ–‡ä»¶è·¯å¾„
CSV_PATH = os.path.join(os.path.dirname(os.path.dirname(current_dir)), 
                        "workspace", "data", "publish_history.csv")

def load_csv_data():
    """ä»CSVæ–‡ä»¶åŠ è½½æ•°æ®"""
    try:
        if os.path.exists(CSV_PATH):
            df = pd.read_csv(CSV_PATH, encoding='utf-8')
            
            # æ•°æ®é¢„å¤„ç†
            if 'å‘è¡¨æ—¶é—´' in df.columns:
                try:
                    df['å‘è¡¨æ—¶é—´'] = pd.to_datetime(df['å‘è¡¨æ—¶é—´'], errors='coerce')
                    df['publish_date'] = df['å‘è¡¨æ—¶é—´'].dt.strftime('%Y-%m-%d')
                    df['publish_date'] = df['publish_date'].fillna('')
                except Exception as e:
                    st.warning(f"æ—¥æœŸè½¬æ¢è­¦å‘Š: {e}")
                    # ä¿®å¤ï¼šç¡®ä¿publish_dateåˆ—å­˜åœ¨ä¸”ä¸ºSeriesç±»å‹
                    if 'publish_date' in df.columns:
                        df['publish_date'] = df['publish_date'].fillna('')
                    else:
                        df['publish_date'] = ''
            else:
                if 'publish_date' in df.columns:
                    df['publish_date'] = df['publish_date'].fillna('').astype(str)
                else:
                    df['publish_date'] = ''
            
            # è¿‡æ»¤æ‰æ²¡æœ‰æœ‰æ•ˆæ—¥æœŸçš„è®°å½•
            df = df[df['publish_date'] != '']
            df = df[df['publish_date'] != 'nan']
            
            if 'publish_time' not in df.columns:
                df['publish_time'] = '12:00'
            
            # é‡å‘½ååˆ—ä»¥åŒ¹é…åŸæœ‰ç»“æ„
            df = df.rename(columns={
                'å†…å®¹æ ‡é¢˜': 'title',
                'æ€»é˜…è¯»äººæ•°': 'views',
                'æ€»é˜…è¯»æ¬¡æ•°': 'total_views',
                'æ€»åˆ†äº«äººæ•°': 'shares',
                'æ€»åˆ†äº«æ¬¡æ•°': 'total_shares',
                'é˜…è¯»åå…³æ³¨äººæ•°': 'followers_after_read',
                'é€è¾¾äººæ•°': 'delivered_count',
                'å…¬ä¼—å·æ¶ˆæ¯é˜…è¯»æ¬¡æ•°': 'official_account_reads',
                'é€è¾¾é˜…è¯»ç‡': 'delivery_read_rate',
                'é¦–æ¬¡åˆ†äº«æ¬¡æ•°': 'first_share_count',
                'åˆ†äº«äº§ç”Ÿé˜…è¯»æ¬¡æ•°': 'share_generated_reads',
                'é¦–æ¬¡åˆ†äº«ç‡': 'first_share_rate',
                'æ¯æ¬¡åˆ†äº«å¸¦æ¥é˜…è¯»æ¬¡æ•°': 'reads_per_share',
                'é˜…è¯»å®Œæˆç‡': 'read_completion_rate',
                'å†…å®¹url': 'url',
                'è´¦å·åç§°': 'channel_name'
            })
            
            # ç¡®ä¿æ•°å€¼ç±»å‹æ­£ç¡®
            numeric_columns = [
                'views', 'total_views', 'shares', 'total_shares', 'followers_after_read',
                'delivered_count', 'official_account_reads', 'delivery_read_rate',
                'first_share_count', 'share_generated_reads', 'first_share_rate',
                'reads_per_share', 'read_completion_rate'
            ]
            
            for col in numeric_columns:
                if col in df.columns:
                    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)
            
            # æ·»åŠ ç¼ºå¤±çš„åˆ—
            if 'likes' not in df.columns:
                df['likes'] = 0
            if 'comments' not in df.columns:
                df['comments'] = 0
            if 'status' not in df.columns:
                df['status'] = 'published'
            else:
                df['status'] = df['status'].fillna('published')
            
            if 'title' not in df.columns:
                df['title'] = 'æ— æ ‡é¢˜'
            else:
                df['title'] = df['title'].fillna('æ— æ ‡é¢˜')
            
            if 'url' not in df.columns:
                df['url'] = ''
            else:
                df['url'] = df['url'].fillna('')
            
            # ç”ŸæˆID
            if 'id' not in df.columns:
                df['id'] = range(1, len(df) + 1)
            else:
                df['id'] = pd.to_numeric(df['id'], errors='coerce').fillna(0).astype(int)
                if (df['id'] == 0).any():
                    df['id'] = range(1, len(df) + 1)
            
            # ç¡®ä¿channel_nameå­—æ®µå­˜åœ¨
            if 'channel_name' not in df.columns:
                df['channel_name'] = 'AGIè§‚å¯Ÿå®¤'
            else:
                df['channel_name'] = df['channel_name'].fillna('AGIè§‚å¯Ÿå®¤')
            
            return df.to_dict('records')
        else:
            st.warning(f"CSVæ–‡ä»¶ä¸å­˜åœ¨: {CSV_PATH}")
            return []
    except Exception as e:
        st.error(f"è¯»å–CSVæ–‡ä»¶æ—¶å‡ºé”™: {str(e)}")
        return []

def create_engagement_analysis(records):
    """åˆ›å»ºç”¨æˆ·å‚ä¸åº¦åˆ†æå›¾è¡¨"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    
    # è®¡ç®—å‚ä¸åº¦æŒ‡æ ‡
    df['engagement_rate'] = (df['shares'] + df['followers_after_read']) / df['views'].replace(0, 1) * 100
    df['share_efficiency'] = df['share_generated_reads'] / df['total_shares'].replace(0, 1)
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("é˜…è¯»å®Œæˆç‡åˆ†å¸ƒ", "é€è¾¾é˜…è¯»ç‡åˆ†å¸ƒ", "åˆ†äº«æ•ˆç‡", "å‚ä¸åº¦åˆ†æ"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # é˜…è¯»å®Œæˆç‡åˆ†å¸ƒ
    fig.add_trace(
        go.Histogram(x=df['read_completion_rate'], name="é˜…è¯»å®Œæˆç‡", nbinsx=20),
        row=1, col=1
    )
    
    # é€è¾¾é˜…è¯»ç‡åˆ†å¸ƒ
    fig.add_trace(
        go.Histogram(x=df['delivery_read_rate'], name="é€è¾¾é˜…è¯»ç‡", nbinsx=20),
        row=1, col=2
    )
    
    # åˆ†äº«æ•ˆç‡æ•£ç‚¹å›¾
    fig.add_trace(
        go.Scatter(x=df['total_shares'], y=df['share_efficiency'], 
                   mode='markers', name="åˆ†äº«æ•ˆç‡"),
        row=2, col=1
    )
    
    # å‚ä¸åº¦åˆ†æ
    fig.add_trace(
        go.Scatter(x=df['views'], y=df['engagement_rate'], 
                   mode='markers', name="å‚ä¸åº¦"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="ç”¨æˆ·å‚ä¸åº¦åˆ†æ")
    return fig

def create_channel_performance_dashboard(records):
    """åˆ›å»ºé¢‘é“è¡¨ç°ä»ªè¡¨æ¿"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    
    # æŒ‰é¢‘é“èšåˆæ•°æ®
    channel_stats = df.groupby('channel_name').agg({
        'views': ['mean', 'sum', 'count'],
        'shares': ['mean', 'sum'],
        'read_completion_rate': 'mean',
        'delivery_read_rate': 'mean',
        'share_generated_reads': 'sum',
        'followers_after_read': 'sum'
    }).round(2)
    
    # é‡å‘½ååˆ—
    channel_stats.columns = [
        'å¹³å‡é˜…è¯»äººæ•°', 'æ€»é˜…è¯»äººæ•°', 'æ–‡ç« æ•°é‡',
        'å¹³å‡åˆ†äº«äººæ•°', 'æ€»åˆ†äº«äººæ•°',
        'å¹³å‡é˜…è¯»å®Œæˆç‡', 'å¹³å‡é€è¾¾é˜…è¯»ç‡',
        'åˆ†äº«äº§ç”Ÿé˜…è¯»æ€»æ•°', 'é˜…è¯»åå…³æ³¨æ€»æ•°'
    ]
    
    # åˆ›å»ºä»ªè¡¨æ¿å›¾è¡¨
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("å„é¢‘é“æ–‡ç« æ•°é‡", "å„é¢‘é“å¹³å‡é˜…è¯»äººæ•°", "å„é¢‘é“å¹³å‡é˜…è¯»å®Œæˆç‡", "å„é¢‘é“åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°"),
        specs=[[{"type": "bar"}, {"type": "bar"}],
               [{"type": "bar"}, {"type": "bar"}]]
    )
    
    # æ–‡ç« æ•°é‡
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['æ–‡ç« æ•°é‡'], name="æ–‡ç« æ•°é‡"),
        row=1, col=1
    )
    
    # å¹³å‡é˜…è¯»äººæ•°
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['å¹³å‡é˜…è¯»äººæ•°'], name="å¹³å‡é˜…è¯»äººæ•°"),
        row=1, col=2
    )
    
    # å¹³å‡é˜…è¯»å®Œæˆç‡
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['å¹³å‡é˜…è¯»å®Œæˆç‡'], name="å¹³å‡é˜…è¯»å®Œæˆç‡"),
        row=2, col=1
    )
    
    # åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°
    fig.add_trace(
        go.Bar(x=channel_stats.index, y=channel_stats['åˆ†äº«äº§ç”Ÿé˜…è¯»æ€»æ•°'], name="åˆ†äº«äº§ç”Ÿé˜…è¯»æ•°"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="é¢‘é“è¡¨ç°ä»ªè¡¨æ¿")
    return fig, channel_stats

def create_trend_analysis(records):
    """åˆ›å»ºè¶‹åŠ¿åˆ†æå›¾è¡¨"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    
    # æŒ‰æ—¥æœŸèšåˆ
    daily_stats = df.groupby('publish_date').agg({
        'views': 'sum',
        'shares': 'sum',
        'read_completion_rate': 'mean',
        'delivery_read_rate': 'mean',
        'share_generated_reads': 'sum',
        'followers_after_read': 'sum'
    }).reset_index()
    
    fig = make_subplots(
        rows=2, cols=2,
        subplot_titles=("é˜…è¯»äººæ•°è¶‹åŠ¿", "åˆ†äº«äººæ•°è¶‹åŠ¿", "é˜…è¯»å®Œæˆç‡è¶‹åŠ¿", "é€è¾¾é˜…è¯»ç‡è¶‹åŠ¿"),
        specs=[[{"secondary_y": False}, {"secondary_y": False}],
               [{"secondary_y": False}, {"secondary_y": False}]]
    )
    
    # é˜…è¯»äººæ•°è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['views'], 
                   mode='lines+markers', name="é˜…è¯»äººæ•°"),
        row=1, col=1
    )
    
    # åˆ†äº«äººæ•°è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['shares'], 
                   mode='lines+markers', name="åˆ†äº«äººæ•°"),
        row=1, col=2
    )
    
    # é˜…è¯»å®Œæˆç‡è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['read_completion_rate'], 
                   mode='lines+markers', name="é˜…è¯»å®Œæˆç‡"),
        row=2, col=1
    )
    
    # é€è¾¾é˜…è¯»ç‡è¶‹åŠ¿
    fig.add_trace(
        go.Scatter(x=daily_stats['publish_date'], y=daily_stats['delivery_read_rate'], 
                   mode='lines+markers', name="é€è¾¾é˜…è¯»ç‡"),
        row=2, col=2
    )
    
    fig.update_layout(height=600, title_text="è¶‹åŠ¿åˆ†æ")
    return fig

def create_heatmap_analysis(records):
    """åˆ›å»ºçƒ­åŠ›å›¾åˆ†æ"""
    if not records:
        return None
    
    df = pd.DataFrame(records)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    df['weekday'] = df['publish_date'].dt.day_name()
    df['hour'] = df['publish_date'].dt.hour
    
    # æŒ‰æ˜ŸæœŸå’Œå°æ—¶åˆ›å»ºçƒ­åŠ›å›¾æ•°æ®
    weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
    weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
    
    # å‘å¸ƒé¢‘ç‡çƒ­åŠ›å›¾
    publish_heatmap = df.groupby(['weekday', 'hour']).size().unstack(fill_value=0)
    publish_heatmap = publish_heatmap.reindex(weekday_order)
    publish_heatmap.index = weekday_cn
    
    fig = go.Figure(data=go.Heatmap(
        z=publish_heatmap.values,
        x=publish_heatmap.columns,
        y=publish_heatmap.index,
        colorscale='Viridis',
        text=publish_heatmap.values,
        texttemplate="%{text}",
        textfont={"size": 10},
        hoverongaps=False
    ))
    
    fig.update_layout(
        title="å‘å¸ƒæ—¶é—´çƒ­åŠ›å›¾",
        xaxis_title="å°æ—¶",
        yaxis_title="æ˜ŸæœŸ",
        height=400
    )
    
    return fig



def create_monthly_calendar(records, year, month, selected_channels):
    """åˆ›å»ºæœˆåº¦æ—¥å†è§†å›¾"""
    if not records:
        return None
    
    # è¿‡æ»¤æŒ‡å®šå¹´æœˆçš„æ•°æ®
    filtered_data = []
    for record in records:
        if record.get("channel_name") in selected_channels:
            try:
                publish_date = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                if publish_date.year == year and publish_date.month == month:
                    filtered_data.append(record)
            except (ValueError, TypeError):
                continue
    
    if not filtered_data:
        return None
    
    # åˆ›å»ºæ—¥å†æ•°æ®
    df = pd.DataFrame(filtered_data)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    
    # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
    daily_stats = df.groupby('publish_date').agg({
        'views': 'sum',
        'shares': 'sum',
        'title': lambda x: list(x)
    }).reset_index()
    
    # åˆ›å»ºæ—¥å†HTML
    cal = calendar.monthcalendar(year, month)
    month_name = calendar.month_name[month]
    
    # ä½¿ç”¨Streamlitçš„HTMLç»„ä»¶
    html_content = f"""
    <div style="font-family: Arial, sans-serif; max-width: 800px; margin: 0 auto;">
        <h2 style="text-align: center; color: #333;">{year}å¹´{month}æœˆå‘å¸ƒæ—¥å†</h2>
        <table style="width: 100%; border-collapse: collapse; border: 1px solid #ddd;">
            <thead>
                <tr>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨ä¸€</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨äºŒ</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨ä¸‰</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨å››</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨äº”</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨å…­</th>
                    <th style="border: 1px solid #ddd; padding: 8px; background-color: #f5f5f5;">å‘¨æ—¥</th>
                </tr>
            </thead>
            <tbody>
    """
    
    for week in cal:
        html_content += "<tr>"
        for day in week:
            if day == 0:
                html_content += '<td style="border: 1px solid #ddd; padding: 8px; background-color: #f9f9f9;">&nbsp;</td>'
            else:
                # æŸ¥æ‰¾å½“å¤©çš„å‘å¸ƒè®°å½•
                day_date = datetime(year, month, day)
                day_records = daily_stats[daily_stats['publish_date'].dt.date == day_date.date()]
                
                if not day_records.empty:
                    # æœ‰å‘å¸ƒè®°å½•
                    total_views = day_records['views'].sum()
                    total_shares = day_records['shares'].sum()
                    article_count = len(day_records)
                    
                    html_content += f"""
                    <td style="border: 1px solid #ddd; padding: 8px; background-color: #e8f5e8; position: relative;">
                        <div style="font-weight: bold; color: #2d5a2d;">{day}</div>
                        <div style="font-size: 12px; color: #666;">
                            ğŸ“ {article_count}ç¯‡<br>
                            ğŸ‘€ {total_views:,}<br>
                            ğŸ“¤ {total_shares:,}
                        </div>
                    </td>
                    """
                else:
                    # æ— å‘å¸ƒè®°å½•
                    html_content += f'<td style="border: 1px solid #ddd; padding: 8px;">{day}</td>'
        html_content += "</tr>"
    
    html_content += """
            </tbody>
        </table>
    </div>
    """
    
    return html_content

def create_timeline_view(records, selected_channels):
    """åˆ›å»ºæ—¶é—´çº¿è§†å›¾"""
    if not records:
        return None
    
    # è¿‡æ»¤æ•°æ®
    filtered_data = []
    for record in records:
        if record.get("channel_name") in selected_channels:
            filtered_data.append(record)
    
    if not filtered_data:
        return None
    
    df = pd.DataFrame(filtered_data)
    df['publish_date'] = pd.to_datetime(df['publish_date'])
    df = df.sort_values('publish_date')
    
    # åˆ›å»ºæ—¶é—´çº¿å›¾è¡¨
    fig = go.Figure()
    
    # ä¸ºæ¯ä¸ªé¢‘é“åˆ›å»ºä¸åŒçš„é¢œè‰²
    channels = df['channel_name'].unique()
    colors = px.colors.qualitative.Set3[:len(channels)]
    
    for i, channel in enumerate(channels):
        channel_data = df[df['channel_name'] == channel]
        
        fig.add_trace(go.Scatter(
            x=channel_data['publish_date'],
            y=channel_data['views'],
            mode='markers+lines',
            name=channel,
            marker=dict(size=8, color=colors[i]),
            hovertemplate='<b>%{text}</b><br>' +
                         'æ—¥æœŸ: %{x}<br>' +
                         'é˜…è¯»äººæ•°: %{y:,}<br>' +
                         'åˆ†äº«äººæ•°: %{customdata}<br>' +
                         '<extra></extra>',
            text=channel_data['title'],
            customdata=channel_data['shares']
        ))
    
    fig.update_layout(
        title="å‘å¸ƒæ—¶é—´çº¿",
        xaxis_title="æ—¥æœŸ",
        yaxis_title="é˜…è¯»äººæ•°",
        height=500,
        hovermode='closest'
    )
    
    return fig

st.set_page_config(page_title="é¢‘é“å‘å¸ƒå†å²", layout="wide")
st.title("ğŸ“Š é¢‘é“å‘å¸ƒå†å² - æ•°æ®å¯è§†åŒ–åˆ†æ")

# æ·»åŠ åˆ·æ–°æŒ‰é’®
col1, col2, col3 = st.columns([1, 1, 1])
with col1:
    if st.button("ğŸ”„ åˆ·æ–°æ•°æ®", help="ä»CSVæ–‡ä»¶é‡æ–°åŠ è½½æœ€æ–°æ•°æ®"):
        st.rerun()
with col2:
    # æ˜¾ç¤ºæ•°æ®æ–‡ä»¶ä¿¡æ¯
    if os.path.exists(CSV_PATH):
        file_size = os.path.getsize(CSV_PATH)
        file_time = datetime.fromtimestamp(os.path.getmtime(CSV_PATH))
        st.info(f"ğŸ“ æ•°æ®æ–‡ä»¶: {file_size:,} å­—èŠ‚ | æ›´æ–°æ—¶é—´: {file_time.strftime('%Y-%m-%d %H:%M:%S')}")
    else:
        st.warning("âš ï¸ æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")
with col3:
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    all_records_temp = load_csv_data()
    st.metric("ğŸ“Š æ€»è®°å½•æ•°", len(all_records_temp))

def get_all_records():
    """è·å–æ‰€æœ‰å‘å¸ƒè®°å½•"""
    return load_csv_data()

# åŠ è½½æ•°æ®
all_records = get_all_records()

# è·å–æ‰€æœ‰é¢‘é“åç§°
all_channels = []
if all_records:
    for record in all_records:
        if "channel_name" in record and record["channel_name"]:
            all_channels.append(record["channel_name"])
    all_channels = list(set(all_channels))

# ä¾§è¾¹æ è¿‡æ»¤å™¨
with st.sidebar:
    st.subheader("ğŸ” é¢‘é“ç­›é€‰")
    selected_channels = st.multiselect(
        "é€‰æ‹©é¢‘é“",
        all_channels,
        default=all_channels
    )
    
    st.subheader("ğŸ“… æ—¥æœŸèŒƒå›´")
    # è·å–æ•°æ®ä¸­çš„æ—¥æœŸèŒƒå›´
    if all_records:
        dates = []
        for record in all_records:
            if "publish_date" in record and record["publish_date"]:
                try:
                    if isinstance(record["publish_date"], str) and record["publish_date"].strip():
                        date_obj = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                        dates.append(date_obj)
                except (ValueError, TypeError):
                    continue
        
        if dates:
            min_date = min(dates).date()
            max_date = max(dates).date()
        else:
            min_date = datetime.now().date() - timedelta(days=30)
            max_date = datetime.now().date()
    else:
        min_date = datetime.now().date() - timedelta(days=30)
        max_date = datetime.now().date()
    
    start_date = st.date_input("å¼€å§‹æ—¥æœŸ", min_date)
    end_date = st.date_input("ç»“æŸæ—¥æœŸ", max_date)

# è¿‡æ»¤æ•°æ®
filtered_records = []
for record in all_records:
    if ("channel_name" in record and record["channel_name"] in selected_channels and
        "publish_date" in record and record["publish_date"]):
        try:
            publish_date = datetime.strptime(record["publish_date"], "%Y-%m-%d").date()
            if start_date <= publish_date <= end_date:
                filtered_records.append(record)
        except (ValueError, TypeError):
            continue

# åˆ›å»ºæ ‡ç­¾é¡µ
tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
    "ğŸ“Š æ¦‚è§ˆä»ªè¡¨æ¿", 
    "ğŸ“ˆ è¶‹åŠ¿åˆ†æ", 
    "ğŸ¯ å‚ä¸åº¦åˆ†æ",
    "ğŸ“… æ—¶é—´åˆ†æ",
    "ğŸ“… å‘å¸ƒæ—¥å†",
    "ğŸ“‹ è¯¦ç»†è®°å½•",
    "ğŸ” é«˜çº§åˆ†æ"
])

with tab1:
    st.subheader("ğŸ“Š æ¦‚è§ˆä»ªè¡¨æ¿")
    
    if filtered_records:
        # è®¡ç®—æ€»ä½“ç»Ÿè®¡
        total_published = len([r for r in filtered_records if r["status"] == "published"])
        total_views = sum(r.get("views", 0) for r in filtered_records)
        total_shares = sum(r.get("shares", 0) for r in filtered_records)
        avg_read_completion = np.mean([r.get("read_completion_rate", 0) for r in filtered_records])
        avg_delivery_read_rate = np.mean([r.get("delivery_read_rate", 0) for r in filtered_records])
        
        # æ˜¾ç¤ºç»Ÿè®¡å¡ç‰‡
        col1, col2, col3, col4 = st.columns(4)
        with col1:
            st.metric("ğŸ“ æ€»å‘å¸ƒæ•°", total_published)
        with col2:
            st.metric("ğŸ‘€ æ€»é˜…è¯»äººæ•°", f"{total_views:,}")
        with col3:
            st.metric("ğŸ“¤ æ€»åˆ†äº«äººæ•°", f"{total_shares:,}")
        with col4:
            st.metric("ğŸ“Š å¹³å‡é˜…è¯»å®Œæˆç‡", f"{avg_read_completion:.1f}%")
        
        # é¢‘é“è¡¨ç°ä»ªè¡¨æ¿
        dashboard_fig, channel_stats = create_channel_performance_dashboard(filtered_records)
        if dashboard_fig:
            st.plotly_chart(dashboard_fig, use_container_width=True)
        
        # æ˜¾ç¤ºé¢‘é“ç»Ÿè®¡è¡¨æ ¼
        if channel_stats is not None:
            st.subheader("ğŸ“Š é¢‘é“è¯¦ç»†ç»Ÿè®¡")
            st.dataframe(channel_stats, use_container_width=True)
        
        # çƒ­é—¨æ–‡ç« 
        st.subheader("ğŸ”¥ çƒ­é—¨æ–‡ç«  TOP 10")
        top_articles = sorted(filtered_records, key=lambda x: x.get("views", 0), reverse=True)[:10]
        
        for i, article in enumerate(top_articles, 1):
            with st.expander(f"#{i} {article.get('title', 'æ— æ ‡é¢˜')} ({article.get('channel_name', 'æœªçŸ¥é¢‘é“')})"):
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.write(f"**é˜…è¯»äººæ•°:** {article.get('views', 0):,}")
                with col2:
                    st.write(f"**åˆ†äº«äººæ•°:** {article.get('shares', 0):,}")
                with col3:
                    st.write(f"**é˜…è¯»å®Œæˆç‡:** {article.get('read_completion_rate', 0):.1f}%")
                with col4:
                    st.write(f"**å‘å¸ƒæ—¥æœŸ:** {article.get('publish_date', '')}")
                
                if article.get('url'):
                    st.write(f"**é“¾æ¥:** {article['url']}")
    else:
        st.info("æš‚æ— æ•°æ®")

with tab2:
    st.subheader("ğŸ“ˆ è¶‹åŠ¿åˆ†æ")
    
    if filtered_records:
        # è¶‹åŠ¿åˆ†æå›¾è¡¨
        trend_fig = create_trend_analysis(filtered_records)
        if trend_fig:
            st.plotly_chart(trend_fig, use_container_width=True)
        
        # æœˆåº¦ç»Ÿè®¡
        st.subheader("ğŸ“… æœˆåº¦ç»Ÿè®¡")
        df_monthly = pd.DataFrame(filtered_records)
        df_monthly['publish_date'] = pd.to_datetime(df_monthly['publish_date'])
        df_monthly['month'] = df_monthly['publish_date'].dt.to_period('M')
        
        monthly_stats = df_monthly.groupby('month').agg({
            'views': 'sum',
            'shares': 'sum',
            'read_completion_rate': 'mean',
            'delivery_read_rate': 'mean'
        }).reset_index()
        
        monthly_stats['month'] = monthly_stats['month'].astype(str)
        
        fig_monthly = make_subplots(
            rows=1, cols=2,
            subplot_titles=("æœˆåº¦é˜…è¯»äººæ•°", "æœˆåº¦åˆ†äº«äººæ•°"),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        fig_monthly.add_trace(
            go.Bar(x=monthly_stats['month'], y=monthly_stats['views'], name="é˜…è¯»äººæ•°"),
            row=1, col=1
        )
        
        fig_monthly.add_trace(
            go.Bar(x=monthly_stats['month'], y=monthly_stats['shares'], name="åˆ†äº«äººæ•°"),
            row=1, col=2
        )
        
        fig_monthly.update_layout(height=400, title_text="æœˆåº¦è¶‹åŠ¿")
        st.plotly_chart(fig_monthly, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab3:
    st.subheader("ğŸ¯ ç”¨æˆ·å‚ä¸åº¦åˆ†æ")
    
    if filtered_records:
        # å‚ä¸åº¦åˆ†æå›¾è¡¨
        engagement_fig = create_engagement_analysis(filtered_records)
        if engagement_fig:
            st.plotly_chart(engagement_fig, use_container_width=True)
        
        # åˆ†äº«æ•ˆç‡åˆ†æ
        st.subheader("ğŸ“¤ åˆ†äº«æ•ˆç‡åˆ†æ")
        df_share = pd.DataFrame(filtered_records)
        
        # è®¡ç®—åˆ†äº«ç›¸å…³æŒ‡æ ‡
        df_share['share_efficiency'] = df_share['share_generated_reads'] / df_share['total_shares'].replace(0, 1)
        df_share['share_engagement'] = df_share['shares'] / df_share['views'].replace(0, 1) * 100
        
        fig_share = make_subplots(
            rows=1, cols=2,
            subplot_titles=("åˆ†äº«æ•ˆç‡åˆ†å¸ƒ", "åˆ†äº«å‚ä¸åº¦åˆ†å¸ƒ"),
            specs=[[{"secondary_y": False}, {"secondary_y": False}]]
        )
        
        fig_share.add_trace(
            go.Histogram(x=df_share['share_efficiency'], name="åˆ†äº«æ•ˆç‡", nbinsx=20),
            row=1, col=1
        )
        
        fig_share.add_trace(
            go.Histogram(x=df_share['share_engagement'], name="åˆ†äº«å‚ä¸åº¦", nbinsx=20),
            row=1, col=2
        )
        
        fig_share.update_layout(height=400, title_text="åˆ†äº«æ•ˆç‡åˆ†æ")
        st.plotly_chart(fig_share, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab4:
    st.subheader("ğŸ“… æ—¶é—´åˆ†æ")
    
    if filtered_records:
        # å‘å¸ƒæ—¶é—´çƒ­åŠ›å›¾
        heatmap_fig = create_heatmap_analysis(filtered_records)
        if heatmap_fig:
            st.plotly_chart(heatmap_fig, use_container_width=True)
        
        # æ˜ŸæœŸå‘å¸ƒé¢‘ç‡
        st.subheader("ğŸ“Š æ˜ŸæœŸå‘å¸ƒé¢‘ç‡")
        df_weekday = pd.DataFrame(filtered_records)
        df_weekday['publish_date'] = pd.to_datetime(df_weekday['publish_date'])
        df_weekday['weekday'] = df_weekday['publish_date'].dt.day_name()
        
        weekday_counts = df_weekday['weekday'].value_counts()
        weekday_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']
        weekday_cn = ['å‘¨ä¸€', 'å‘¨äºŒ', 'å‘¨ä¸‰', 'å‘¨å››', 'å‘¨äº”', 'å‘¨å…­', 'å‘¨æ—¥']
        
        weekday_counts = weekday_counts.reindex(weekday_order)
        weekday_counts.index = weekday_cn
        
        fig_weekday = px.bar(
            x=weekday_counts.index, 
            y=weekday_counts.values,
            title="å„æ˜ŸæœŸå‘å¸ƒæ–‡ç« æ•°é‡",
            labels={'x': 'æ˜ŸæœŸ', 'y': 'æ–‡ç« æ•°é‡'}
        )
        st.plotly_chart(fig_weekday, use_container_width=True)
        
    else:
        st.info("æš‚æ— æ•°æ®")

with tab5:
    st.subheader("ğŸ“… å‘å¸ƒæ—¥å†")
    
    if filtered_records:
        # é€‰æ‹©æ—¥å†è§†å›¾ç±»å‹
        calendar_type = st.selectbox(
            "é€‰æ‹©æ—¥å†è§†å›¾ç±»å‹",
            ["æœˆåº¦æ—¥å†", "æ—¶é—´çº¿è§†å›¾"],
            index=0
        )
        
        if calendar_type == "æœˆåº¦æ—¥å†":
            st.subheader("ğŸ“… æœˆåº¦å‘å¸ƒæ—¥å†")
            
            # è·å–æ•°æ®ä¸­çš„å¹´ä»½èŒƒå›´
            if filtered_records:
                dates = []
                for record in filtered_records:
                    if "publish_date" in record and record["publish_date"]:
                        try:
                            if isinstance(record["publish_date"], str) and record["publish_date"].strip():
                                date_obj = datetime.strptime(record["publish_date"], "%Y-%m-%d")
                                dates.append(date_obj)
                        except (ValueError, TypeError):
                            continue
                
                if dates:
                    years = sorted(list(set(date.year for date in dates)))
                else:
                    years = [datetime.now().year]
                current_year = datetime.now().year
                
                # å¦‚æœæ•°æ®ä¸­æ²¡æœ‰å½“å‰å¹´ä»½ï¼Œæ·»åŠ å½“å‰å¹´ä»½
                if current_year not in years:
                    years.append(current_year)
                    years.sort()
                
                # é»˜è®¤é€‰æ‹©å½“å‰å¹´ä»½
                default_year_index = years.index(current_year) if current_year in years else 0
                
                col1, col2 = st.columns(2)
                with col1:
                    year = st.selectbox("é€‰æ‹©å¹´ä»½", years, index=default_year_index)
                with col2:
                    month = st.selectbox("é€‰æ‹©æœˆä»½", range(1, 13), index=datetime.now().month-1)
                
                calendar_html = create_monthly_calendar(filtered_records, year, month, selected_channels)
                if calendar_html:
                    # ä½¿ç”¨Streamlitçš„HTMLç»„ä»¶æ˜¾ç¤ºæ—¥å†
                    st.components.v1.html(calendar_html, height=600)
                else:
                    st.info("è¯¥æœˆä»½æš‚æ— å‘å¸ƒè®°å½•")
            else:
                # æ²¡æœ‰æ•°æ®æ—¶ï¼Œæ˜¾ç¤ºå½“å‰å¹´æœˆ
                col1, col2 = st.columns(2)
                with col1:
                    year = st.selectbox("é€‰æ‹©å¹´ä»½", [datetime.now().year], index=0)
                with col2:
                    month = st.selectbox("é€‰æ‹©æœˆä»½", range(1, 13), index=datetime.now().month-1)
                
                st.info("æš‚æ— æ•°æ®ï¼Œè¯·å…ˆæ·»åŠ å‘å¸ƒè®°å½•")
        
        elif calendar_type == "æ—¶é—´çº¿è§†å›¾":
            st.subheader("ğŸ“ˆ å‘å¸ƒæ—¶é—´çº¿")
            timeline_fig = create_timeline_view(filtered_records, selected_channels)
            if timeline_fig:
                st.plotly_chart(timeline_fig, use_container_width=True)
            else:
                st.info("æš‚æ— æ•°æ®ç”Ÿæˆæ—¶é—´çº¿")
    else:
        st.info("æš‚æ— æ•°æ®")

with tab6:
    st.subheader("ğŸ“‹ è¯¦ç»†è®°å½•")
    
    if filtered_records:
        # åˆ›å»ºæ•°æ®è¡¨æ ¼
        df_records = pd.DataFrame(filtered_records)
        
        # é€‰æ‹©æ˜¾ç¤ºçš„åˆ—
        display_columns = [
            "id", "channel_name", "title", "publish_date", 
            "views", "shares", "read_completion_rate", "delivery_read_rate",
            "share_generated_reads", "followers_after_read"
        ]
        
        # ç¡®ä¿æ‰€æœ‰åˆ—éƒ½å­˜åœ¨
        available_columns = [col for col in display_columns if col in df_records.columns]
        
        # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
        st.dataframe(
            df_records[available_columns],
            use_container_width=True
        )
        
        # å¯¼å‡ºåŠŸèƒ½
        if st.button("ğŸ“¥ å¯¼å‡ºæ•°æ®"):
            csv = df_records.to_csv(index=False)
            st.download_button(
                label="ä¸‹è½½CSVæ–‡ä»¶",
                data=csv,
                file_name=f"channel_publish_history_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
    else:
        st.info("æš‚æ— æ•°æ®")

with tab7:
    st.subheader("ğŸ” é«˜çº§åˆ†æ")
    
    if filtered_records:
        # ç›¸å…³æ€§åˆ†æ
        st.subheader("ğŸ“Š æŒ‡æ ‡ç›¸å…³æ€§åˆ†æ")
        df_corr = pd.DataFrame(filtered_records)
        
        # é€‰æ‹©æ•°å€¼åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ
        numeric_columns = [
            'views', 'shares', 'read_completion_rate', 'delivery_read_rate',
            'share_generated_reads', 'followers_after_read', 'total_views', 'total_shares'
        ]
        
        available_numeric = [col for col in numeric_columns if col in df_corr.columns]
        
        if len(available_numeric) > 1:
            correlation_matrix = df_corr[available_numeric].corr()
            
            fig_corr = px.imshow(
                correlation_matrix,
                title="æŒ‡æ ‡ç›¸å…³æ€§çƒ­åŠ›å›¾",
                color_continuous_scale='RdBu',
                aspect="auto"
            )
            st.plotly_chart(fig_corr, use_container_width=True)
        
        # åˆ†å¸ƒåˆ†æ
        st.subheader("ğŸ“ˆ æŒ‡æ ‡åˆ†å¸ƒåˆ†æ")
        if filtered_records:
            df_dist = pd.DataFrame(filtered_records)
            
            # é€‰æ‹©è¦åˆ†æçš„æŒ‡æ ‡
            metrics_to_analyze = ['views', 'shares', 'read_completion_rate', 'delivery_read_rate']
            available_metrics = [m for m in metrics_to_analyze if m in df_dist.columns]
            
            if available_metrics:
                fig_dist = make_subplots(
                    rows=2, cols=2,
                    subplot_titles=available_metrics,
                    specs=[[{"secondary_y": False}, {"secondary_y": False}],
                           [{"secondary_y": False}, {"secondary_y": False}]]
                )
                
                for i, metric in enumerate(available_metrics):
                    row = (i // 2) + 1
                    col = (i % 2) + 1
                    
                    fig_dist.add_trace(
                        go.Histogram(x=df_dist[metric], name=metric, nbinsx=20),
                        row=row, col=col
                    )
                
                fig_dist.update_layout(height=500, title_text="æŒ‡æ ‡åˆ†å¸ƒåˆ†æ")
                st.plotly_chart(fig_dist, use_container_width=True)
        
        # å¼‚å¸¸å€¼æ£€æµ‹
        st.subheader("ğŸ” å¼‚å¸¸å€¼æ£€æµ‹")
        if filtered_records:
            df_outlier = pd.DataFrame(filtered_records)
            
            # æ£€æµ‹é˜…è¯»äººæ•°çš„å¼‚å¸¸å€¼
            if 'views' in df_outlier.columns:
                Q1 = df_outlier['views'].quantile(0.25)
                Q3 = df_outlier['views'].quantile(0.75)
                IQR = Q3 - Q1
                lower_bound = Q1 - 1.5 * IQR
                upper_bound = Q3 + 1.5 * IQR
                
                outliers = df_outlier[(df_outlier['views'] < lower_bound) | (df_outlier['views'] > upper_bound)]
                
                if not outliers.empty:
                    st.warning(f"å‘ç° {len(outliers)} ä¸ªé˜…è¯»äººæ•°å¼‚å¸¸å€¼")
                    st.dataframe(outliers[['title', 'channel_name', 'views', 'publish_date']], use_container_width=True)
                else:
                    st.success("æœªå‘ç°é˜…è¯»äººæ•°å¼‚å¸¸å€¼")
        
    else:
        st.info("æš‚æ— æ•°æ®") 