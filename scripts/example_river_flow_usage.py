#!/usr/bin/env python3
"""
æ²³æµå›¾å¯è§†åŒ–ä½¿ç”¨ç¤ºä¾‹
æ¼”ç¤ºå¦‚ä½•ä½¿ç”¨æ–°åˆ›å»ºçš„æ²³æµå›¾å¯è§†åŒ–åŠŸèƒ½
"""

import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

def create_realistic_sample_data():
    """åˆ›å»ºæ›´çœŸå®çš„ç¤ºä¾‹æ•°æ®"""
    print("ğŸ“Š åˆ›å»ºçœŸå®ç¤ºä¾‹æ•°æ®...")
    
    # åˆ›å»ºç¤ºä¾‹è´¦å·
    accounts = ['AGIè§‚å¯Ÿå®¤', 'AGIå¯ç¤ºå½•', 'AIä¸‡è±¡å¿—', 'äººå·¥æ™ºèƒ½æ¼«æ¸¸æŒ‡å—']
    
    # åˆ›å»ºæ—¶é—´èŒƒå›´ï¼ˆæœ€è¿‘6ä¸ªæœˆï¼‰
    end_date = datetime.now()
    start_date = end_date - timedelta(days=180)
    
    # ç”Ÿæˆç¤ºä¾‹æ•°æ®
    data = []
    for i in range(200):  # ç”Ÿæˆ200æ¡è®°å½•
        # éšæœºé€‰æ‹©è´¦å·
        account = np.random.choice(accounts)
        
        # éšæœºç”Ÿæˆæ—¶é—´ï¼ˆåå‘å·¥ä½œæ—¥ï¼‰
        random_days = np.random.randint(0, 180)
        publish_time = start_date + timedelta(days=random_days)
        
        # å¦‚æœæ˜¯å‘¨æœ«ï¼Œå‡å°‘å‘å¸ƒæ¦‚ç‡
        if publish_time.weekday() >= 5:  # å‘¨å…­ã€å‘¨æ—¥
            if np.random.random() > 0.3:  # 70%æ¦‚ç‡è·³è¿‡
                continue
        
        # ç”Ÿæˆé˜…è¯»é‡ï¼ˆåŸºäºè´¦å·çš„åŸºå‡†å€¼å’Œæ—¶é—´è¶‹åŠ¿ï¼‰
        base_reads = {
            'AGIè§‚å¯Ÿå®¤': 1200,
            'AGIå¯ç¤ºå½•': 900,
            'AIä¸‡è±¡å¿—': 700,
            'äººå·¥æ™ºèƒ½æ¼«æ¸¸æŒ‡å—': 500
        }
        
        # æ·»åŠ æ—¶é—´è¶‹åŠ¿ï¼ˆå‘¨æœ«é˜…è¯»é‡è¾ƒä½ï¼‰
        time_factor = 0.7 if publish_time.weekday() >= 5 else 1.0
        
        # æ·»åŠ éšæœºæ³¢åŠ¨
        reads = int(base_reads[account] * time_factor * np.random.uniform(0.5, 1.8))
        reads = max(0, reads)  # ç¡®ä¿éè´Ÿ
        
        # ç”Ÿæˆå…¶ä»–æŒ‡æ ‡ï¼ˆä¸é˜…è¯»é‡ç›¸å…³ï¼‰
        likes = int(reads * np.random.uniform(0.02, 0.08))
        shares = int(reads * np.random.uniform(0.01, 0.05))
        
        # ç”Ÿæˆæ ‡é¢˜
        titles = [
            "AIæŠ€æœ¯çš„æœ€æ–°å‘å±•è¶‹åŠ¿",
            "äººå·¥æ™ºèƒ½åœ¨åŒ»ç–—é¢†åŸŸçš„åº”ç”¨",
            "æœºå™¨å­¦ä¹ ç®—æ³•ä¼˜åŒ–å®è·µ",
            "æ·±åº¦å­¦ä¹ æ¨¡å‹è®­ç»ƒæŠ€å·§",
            "è‡ªç„¶è¯­è¨€å¤„ç†æŠ€æœ¯è§£æ",
            "è®¡ç®—æœºè§†è§‰åº”ç”¨æ¡ˆä¾‹",
            "AIä¼¦ç†ä¸å®‰å…¨æ€è€ƒ",
            "äººå·¥æ™ºèƒ½æœªæ¥å±•æœ›"
        ]
        
        data.append({
            'å‘å¸ƒæ—¶é—´': publish_time.strftime('%Y-%m-%d'),
            'é˜…è¯»é‡': reads,
            'ç‚¹èµé‡': likes,
            'åˆ†äº«é‡': shares,
            'è´¦å·åç§°': account,
            'æ ‡é¢˜': np.random.choice(titles),
            'é“¾æ¥': f'https://example.com/article_{i+1}'
        })
    
    return pd.DataFrame(data)

def demonstrate_data_analysis():
    """æ¼”ç¤ºæ•°æ®åˆ†æåŠŸèƒ½"""
    print("ğŸ” æ¼”ç¤ºæ•°æ®åˆ†æåŠŸèƒ½...")
    
    # åˆ›å»ºç¤ºä¾‹æ•°æ®
    df = create_realistic_sample_data()
    
    print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   - æ€»è®°å½•æ•°: {len(df)}")
    print(f"   - æ—¶é—´èŒƒå›´: {df['å‘å¸ƒæ—¶é—´'].min()} åˆ° {df['å‘å¸ƒæ—¶é—´'].max()}")
    print(f"   - è´¦å·æ•°é‡: {len(df['è´¦å·åç§°'].unique())}")
    print(f"   - æ€»é˜…è¯»é‡: {df['é˜…è¯»é‡'].sum():,}")
    print(f"   - å¹³å‡é˜…è¯»é‡: {df['é˜…è¯»é‡'].mean():.1f}")
    
    # æŒ‰è´¦å·ç»Ÿè®¡
    print(f"\nğŸ“ˆ å„è´¦å·è¡¨ç°:")
    account_stats = df.groupby('è´¦å·åç§°').agg({
        'é˜…è¯»é‡': ['count', 'sum', 'mean'],
        'ç‚¹èµé‡': 'sum',
        'åˆ†äº«é‡': 'sum'
    }).round(1)
    
    for account in df['è´¦å·åç§°'].unique():
        account_data = df[df['è´¦å·åç§°'] == account]
        print(f"   - {account}:")
        print(f"     * æ–‡ç« æ•°: {len(account_data)}")
        print(f"     * æ€»é˜…è¯»é‡: {account_data['é˜…è¯»é‡'].sum():,}")
        print(f"     * å¹³å‡é˜…è¯»é‡: {account_data['é˜…è¯»é‡'].mean():.1f}")
        print(f"     * æ€»ç‚¹èµé‡: {account_data['ç‚¹èµé‡'].sum():,}")
        print(f"     * æ€»åˆ†äº«é‡: {account_data['åˆ†äº«é‡'].sum():,}")
    
    # æŒ‰æ—¶é—´ç»Ÿè®¡
    print(f"\nğŸ“… æ—¶é—´è¶‹åŠ¿åˆ†æ:")
    df['å‘å¸ƒæ—¶é—´'] = pd.to_datetime(df['å‘å¸ƒæ—¶é—´'])
    df['æœˆä»½'] = df['å‘å¸ƒæ—¶é—´'].dt.to_period('M')
    
    monthly_stats = df.groupby('æœˆä»½').agg({
        'é˜…è¯»é‡': ['count', 'sum', 'mean']
    }).round(1)
    
    for month in df['æœˆä»½'].unique():
        month_data = df[df['æœˆä»½'] == month]
        print(f"   - {month}:")
        print(f"     * æ–‡ç« æ•°: {len(month_data)}")
        print(f"     * æ€»é˜…è¯»é‡: {month_data['é˜…è¯»é‡'].sum():,}")
        print(f"     * å¹³å‡é˜…è¯»é‡: {month_data['é˜…è¯»é‡'].mean():.1f}")
    
    return df

def demonstrate_visualization_preparation():
    """æ¼”ç¤ºå¯è§†åŒ–æ•°æ®å‡†å¤‡"""
    print("ğŸ“ˆ æ¼”ç¤ºå¯è§†åŒ–æ•°æ®å‡†å¤‡...")
    
    # åŠ è½½æ•°æ®
    df = create_realistic_sample_data()
    df['å‘å¸ƒæ—¶é—´'] = pd.to_datetime(df['å‘å¸ƒæ—¶é—´'])
    
    # æ¼”ç¤ºä¸åŒæ—¶é—´ç²’åº¦çš„æ•°æ®å¤„ç†
    time_granularities = {
        'daily': 'æ—¥',
        'weekly': 'å‘¨', 
        'monthly': 'æœˆ'
    }
    
    for granularity, name in time_granularities.items():
        print(f"\nğŸ“Š {name}ç²’åº¦æ•°æ®å¤„ç†:")
        
        if granularity == 'daily':
            df['æ—¶é—´åˆ†ç»„'] = df['å‘å¸ƒæ—¶é—´'].dt.date
        elif granularity == 'weekly':
            df['æ—¶é—´åˆ†ç»„'] = df['å‘å¸ƒæ—¶é—´'].dt.to_period('W').dt.start_time.dt.date
        elif granularity == 'monthly':
            df['æ—¶é—´åˆ†ç»„'] = df['å‘å¸ƒæ—¶é—´'].dt.to_period('M').dt.start_time.dt.date
        
        # æŒ‰æ—¶é—´å’Œè´¦å·åˆ†ç»„èšåˆæ•°æ®
        flow_data = df.groupby(['æ—¶é—´åˆ†ç»„', 'è´¦å·åç§°'])['é˜…è¯»é‡'].sum().reset_index()
        
        # åˆ›å»ºé€è§†è¡¨
        pivot_data = flow_data.pivot(index='æ—¶é—´åˆ†ç»„', columns='è´¦å·åç§°', values='é˜…è¯»é‡').fillna(0)
        
        print(f"   - æ•°æ®å½¢çŠ¶: {pivot_data.shape}")
        print(f"   - æ—¶é—´èŒƒå›´: {pivot_data.index.min()} åˆ° {pivot_data.index.max()}")
        print(f"   - è´¦å·åˆ—è¡¨: {list(pivot_data.columns)}")
        print(f"   - æ€»é˜…è¯»é‡: {pivot_data.sum().sum():,}")
        
        # æ˜¾ç¤ºå‰å‡ è¡Œæ•°æ®
        print(f"   - å‰5è¡Œæ•°æ®:")
        print(pivot_data.head().to_string())
    
    return True

def demonstrate_chart_types():
    """æ¼”ç¤ºä¸åŒå›¾è¡¨ç±»å‹çš„ç‰¹ç‚¹"""
    print("ğŸ¨ æ¼”ç¤ºä¸åŒå›¾è¡¨ç±»å‹çš„ç‰¹ç‚¹...")
    
    chart_types = {
        "åŸºç¡€å›¾è¡¨": [
            "é¢ç§¯å›¾ (Area Chart) - æ˜¾ç¤ºè¶‹åŠ¿å’Œæ€»é‡",
            "æµå›¾ (Stream Chart) - å¹³æ»‘çš„æ²³æµæ•ˆæœ",
            "å±±è„Šå›¾ (Ridge Plot) - æ¯ä¸ªè´¦å·ç‹¬ç«‹æ˜¾ç¤º"
        ],
        "é«˜çº§å›¾è¡¨": [
            "é«˜çº§æµå›¾ (Advanced Stream Chart) - æ›´å¹³æ»‘çš„æ›²çº¿",
            "å¹³è¡Œç±»åˆ«å›¾ (Parallel Categories) - å¤šç»´åº¦å…³ç³»",
            "æ ‘çŠ¶å›¾ (Treemap) - çŸ©å½¢å¤§å°è¡¨ç¤ºæ•°å€¼",
            "å†°æŸ±å›¾ (Icicle Chart) - çŸ©å½¢å±‚æ¬¡å¸ƒå±€"
        ],
        "ä¸“ä¸šæ²³æµå›¾": [
            "æ²³æµå›¾ (River Flow Chart) - æ”¯æŒå †å ã€åˆ†ç¦»ã€æ ‡å‡†åŒ–ä¸‰ç§æ¨¡å¼",
            "å±±è„Šæµå›¾ (Ridge Flow Chart) - å±±è„Šå¼æ²³æµå›¾"
        ]
    }
    
    for category, charts in chart_types.items():
        print(f"\nğŸ“Š {category}:")
        for chart in charts:
            print(f"   - {chart}")
    
    return True

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸŒŠ æ²³æµå›¾å¯è§†åŒ–åŠŸèƒ½ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # æ¼”ç¤ºæ•°æ®åˆ†æ
        df = demonstrate_data_analysis()
        print()
        
        # æ¼”ç¤ºå¯è§†åŒ–æ•°æ®å‡†å¤‡
        demonstrate_visualization_preparation()
        print()
        
        # æ¼”ç¤ºå›¾è¡¨ç±»å‹
        demonstrate_chart_types()
        print()
        
        # ä¿å­˜ç¤ºä¾‹æ•°æ®
        sample_file = "workspace/data/publish_history_for_calendar.csv"
        os.makedirs(os.path.dirname(sample_file), exist_ok=True)
        df.to_csv(sample_file, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ç¤ºä¾‹æ•°æ®å·²ä¿å­˜åˆ°: {sample_file}")
        
        print("=" * 60)
        print("ğŸ‰ æ¼”ç¤ºå®Œæˆï¼")
        print()
        print("ğŸ“‹ ä½¿ç”¨å»ºè®®:")
        print("1. å¯åŠ¨Streamlitåº”ç”¨: streamlit run homepage.py")
        print("2. å¯¼èˆªåˆ°æ²³æµå›¾å¯è§†åŒ–é¡µé¢")
        print("3. ä½¿ç”¨ä¾§è¾¹æ è°ƒæ•´å‚æ•°")
        print("4. é€‰æ‹©ä¸åŒçš„å›¾è¡¨ç±»å‹è¿›è¡Œæ¢ç´¢")
        print("5. ä½¿ç”¨ç­›é€‰åŠŸèƒ½èšç„¦ç‰¹å®šæ•°æ®")
        print()
        print("ğŸš€ å¼€å§‹æ¢ç´¢æ‚¨çš„æ•°æ®å§ï¼")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
